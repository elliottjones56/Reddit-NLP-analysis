,compscititles,askcompscianswers
0,English Dictionary as a Directed Graph,"You may want to search for the isolated subgraphs (https://en.wikipedia.org/wiki/Component_(graph_theory) ) and choose some criteria for eliminating smaller subgraphs. I'm not sure what a reasonable elimination criteria would be, it's interesting."
1,Help needed for Max Flow Ford Fulkerson problem,"I think you mean > α not > 1

The idea is basically to have one nasty augmenting path that’s a really bad one (and in normal FF would have been cancelled by reverse flows) to block out many many different augmenting paths.

https://imgur.com/a/dGRcGZ9

In the image link I’ve attached, you can convince yourself that the max flow is 6, but if you take the augmenting path s-a-b-c-d-e-f-g-h-i-j-k-l-t then you’ll have blocked every other path that would have allowed the max flow and you’d only have a flow of 1. Now you can just add more vertices to get an even bigger α"
2,Order of learning Java Collection Framework?,"Read the documentation for the collection class itself first. That’s the list of buttons you can press on any collection. Order does not matter. Find out what Iterable means in this context, and learn about cursors. 

Don’t waste your time doing self directed study for internships. Nobody in the hiring office gives an F about your true understanding of concepts, they want you to be quick with canned answers. Go to leetcode and solve problems there. If you can solve 5 medium problems completely on your own, you’re good to go. Learn your data structures from an interview prep book not your college textbook. 

Let me also mention that Python is the lingua franca of programming interviews. It’s a lot less cumbersome to work with compared to java and a lot easier to learn."
3,Help two rats in maze problem,"Seems like you could do A* search of the joint state space, with the heuristic being the sum of the two Manhattan distances."
4,How to start from scratch.. legit base zero,"> build computers, create systems, programmes, softwares, codes etc all by myself

It's worth noting that building computers has little to do with computer science (confusing, I know), but there are plenty of video guides on YouTube [like this one](https://www.youtube.com/watch?v=BL4DCEp7blY).

As far as the fundamentals of CS, you can learn a lot from online resources. I'm partial to [freeCodeCamp](https://www.freecodecamp.org/). You can start at the top of their curriculum with web design, or you can jump ahead to the Python courses for something closer to the subjects typically covered in university.

I've also been through the [nand2tetris](https://www.nand2tetris.org/) course as well with the accompanying textbook, and it will make you learn how a computer works from the ground up. You will need to learn some programming language before completing the second half of the course, though."
5,Help in Automata Question,"One approach is to show that in general for any language L, we have L* = L+ ⋃ {ε} so if L contains ε then L* = L+

Now on the RHS, since L* contains epsilon, L\*+ = L\**

Clearly L** contains L+* (Because L* contains L+). Just remains to show that any string in L\** is in L+\*. Let w be a string in L\*\*. Since ε is in both sides we can assume w is not empty string. That means that w = s1s2…sn where si ∈ L*, si are not ε and n >= 1

But if si are not ε, then si ∈ L+ so w ∈ L+* which completes the proof"
6,Intersection of two regular expressions.,"In what model of Computation? As a DFA you just do a cross product construction, same with NFA but the epsilon transitions are a little tricky."
7,Intersecting regular expressions - stuck.,"> I tried to solve the question with this approach - the NFAs have 8 and 11 states respectively, and their cross product is too much to handle on paper. Is there a better way to do this?

I think you must be overcomplicating this from the beginning somehow, because when I draw out the NFAs for the two input regexes, I get 3 and 2 states, respectively.

So the cross product has 6 states. But of those 6, one is unreachable, and another one is a dead-end non-accepting state which can be discarded. Of the remaining 4 states, two are an equivalent pair and can be collapsed together. So you really only have to worry about 3 states.

(Or, if you prefer, you can solve this in a less formal way without explicitly constructing the NFAs. Hint: your second regex matches a string iff that string ends in 0. If a string matches the first regex and also ends in a 0, what can you say about it?)

If you'd like to check your answer, you can use http://phylactery.org/antimirov/ which will compute regex intersections for you. The answer it computes is much more complex than the one I derived by hand, but when I plug in its answer and my own, it confirms that they're equivalent."
8,Formal Automata and Theory (Need Study Guide),"[This](https://www.youtube.com/watch?v=14RLvkzbHFc) course is by Jeffrey Ullman , author of the famed Hopcroft- Ullman book. 

[This](https://www.youtube.com/playlist?list=PLUl4u3cNGP60_JNv2MmK3wkOt9syvfQWY) course is by Michael Sipser, author of yet another famed text."
9,Information systems textbooks for bachelors,"""Information Systems"" is a very general term. Are you interested in that very general topic, or something more specific?

Like, if you want to know about databases, that's one thing. Or computer networking is another.

Or, there are large sub-categories of Information Systems, such as ""[Management Information Systems](https://en.wikipedia.org/wiki/Management_information_system)"".

Could you elaborate on what you  mean?"
10,Could neural networks be built as physical circuits?,https://www.bittware.com/resources/fpga-neural-networks/
11,Help regarding the identification of the Forward Error correction Scheme of satellite signals.,"There's a straightforward machine learning solution which is to test the sending of some satellite data using FEC scheme number 1 and some from 2 and so forth, and train the system to classify which scheme was used when faced with a random sample.

Binary string seems to be the convention for satellite signals. For the purposes of the FEC detection binary representation would be best at least during debugging because error correcting codes work at the bit level.

Being able to accurately simulate the satellite's error prone channel will help tremendously with training. Otherwise there's a potential for the model getting trained on the channel's error profile more than on the error correction algorithm. It might even be advantageous before training to replace out all the bits that could pertain to the error profile and replace them with bits/flags that represent hypotheses, i.e. FEC scheme 2 was used, not 1. Error profile being, for example, all zeroes every minute due to a repeating noise source nearby, etc. Every imperfect channel has its own noise sources and its own special story."
12,Philosophy: big tech and petty crime,"I think there are a few reasons:

* Big tech and/or the government either doesn't have as much data as you think, or doesn't want to admit it has it, or actually follows its own rules about how the data can be used.
* The kind of data Big Tech has isn't the kind of data law enforcement can actually use, because of evidentiary standards, privacy laws, etc.
* Perhaps law enforcement _does_ use Big Tech data, but because it isn't admissible, prosecutors and LEOs must build a case using alternate evidence that _is_ admissible, so we don't hear about the Big Tech data."
13,Can we run out of storage space to save all the new data that is constantly generated?,"Storing data is cheaper than it has ever been and is becoming cheaper every day. In addition, we have many ways to store data in compressed formats (including lossy compression) that enormously increase the total amount of real storage capacity. A Bloom filter is a great example of this.. for its size, a BF can store an absurd amount of information about data that has been seen/created. I see no serious risks in this space."
14,How to get out of React hell and how do I teach myself Backend Engineering,Any backend language will do. Java and C# are titans that are here to stay. See which is more popular in your area. There's also Node that has something like NestJS and Python's Django.
15,What should I know to create my own 3d modeling software?,"To start with, you'll need to know the same kind of math you'd need for any other 3D graphics software: vectors, matrices, linear algebra, 3D geometry, trigonometry, and so on.

For the specific case of building 3D *modeling* software, you'll want to understand the data structures that are useful for representing meshes in a way that can easily be modified, such as the [half-edge](https://en.wikipedia.org/wiki/Doubly_connected_edge_list) or [winged edge](https://en.wikipedia.org/wiki/Winged_edge) structures."
16,BSC COMPUTER SCIENCE,"This is completely unrealistic to have a foundational headstart in a month. With that said, Python might be the easiest first language to learn just to get an understanding of how programming works. The con of it is python is the most different from common C styled languages.

On the other hand, you can learn Java or C#. the con of this is it's much harder to learn, especially for a beginner, but both are C like and it'll give you a good understanding of your first language course whether it's Java or C++. 

Finally, you can do C and C++. these are the hardest ones to learn (besides machine coding, assembly, and other outdated functional languages), but the trade off is you'll be fully prepared for any other language if you are already well versed in C.

&#x200B;

Then of course, there's math. You should really have a good sense of discrete math for computer science. You'll wanna especially keep track of mathematical logic, combinatorics, and number theory."
17,Would it realistically be possible to study Computer Science at University without any prior knowledge? No knowledge of Maths or Coding.,"Yes, the programs vary greatly depending on the university.  


You can get started now for free at Harvard [https://pll.harvard.edu/course/cs50-introduction-computer-science](https://pll.harvard.edu/course/cs50-introduction-computer-science)  
Why not test out if you can use your ADHD hyperfocus superpowers on that. See how fast you can smash through it."
18,Universities to do Phd in Type theory,"https://homotopytypetheory.org/2014/04/29/hott-awarded-a-muri/ has a list of some of the key folks working on homotopy type theory. It’s a bit old, so I’d find the sort of papers that you want to work on (or are heavily cited by the papers you want to work on) and check the authors’ institutional affiliation for something more up to date."
19,Could you recommend resources to cover basic of CS fast?,I think this guide was made with exactly you in the writer’s mind: https://teachyourselfcs.com/
20,How was your CS college experience?,"Has been awhile but in one, okay two, words, ""I survived"". 

The strictly computer architecture, data structures, algorithms were not so terrible, although challenging, but the stuff like ‘equivalence of deterministic and nondeterministic finite automata’, ‘non deterministic push down automata’, ‘pumping theorum for regular languages’, really  forcefully shaped, (warped?), my brain, which i have later concluded was part of the objective.

Edit - might depend on what school and degree focus. Also, apologies for not answering more of your thoughtful questions. Hopefully others with experience more from current century will better respond."
21,Should I choose Computer Science degree over Information Technology degree?,"Bachelors degrees in computer science are the gold standard for all CS & IT career fields. I would get it over the IT degree. You can work IT jobs with a CS degree, but good luck trying to work CS jobs with an IT degree"
22,Doesn't it make sense that wind would effect wifi?,"Wifi (and other radio signals) are not transmitted with electrons - they're transmitted by photons.  Radio waves are a form of light.  Does light get pushed by the wind?

One reason a fan might interfere is that if it's moved by an electric motor, then the electric motor is likely producing it's own electromagnetic radiation, interfering with the wifi signal"
23,"I am lost, where do I turn?","There's not necessarily anything wrong with learning concepts and pseudocode before getting distracted by all the implementation details of a particular language like Python.  But if you want to learn Python, there are any number of tutorials available online.  Georgia Tech's Introduction to Python Programming professional certificate might be of interest.  If you're interested in computer science more broadly (as opposed to just vocational training in programming), people here often recommend Harvard's CS50 as a good first step."
24,How to implement Sinusoidal Positional Embedding?,"The math is different, so it’s not surprising the results are different. The point of positional embedding is just to have something continuous and easily differentiable that is associated with the input position. Both satisfy that (though I didn’t read the code thoroughly enough to check e.g. numerical stability). I would evaluate the implementation based on how they effect your training experiments. I wouldn’t be surprised if they both work fine."
25,“Store the following value in EAX register: 12784569”,That's what that instruction does.  What's the question?
26,A Seemingly Impossible Cryptographic Magic,Transform returns a float - what do you do with it?  How do you use it to determine who wins?
27,cybersecurity,"Some regularly updated cybersecurity journals include ""Dark Reading,"" ""Cybersecurity Magazine,"" and ""CSO Online,"" offering up-to-date [insights](https://insights.blackhatmea.com/tag/cybersecurity//?utm_source=reddit&utm_medium=affiliate&utm_campaign=bhmea23) and information in the field."
28,What is the time complexity of this code,"Crossppst, already anseered [here](https://reddit.com/r/algorithms/s/4zDl7pWXc0)."
29,How do I teach myself cs?,"Good luck :)

[https://github.com/ossu/computer-science](https://github.com/mvillaloboz/open-source-cs-degree)"
30,Do I need math for masters CS,"Many bachelor CS degrees share some maths courses with the first year of the maths school. Typically, Calculus, Real Analysis, Stats and Differential Equations. This means that some Masters degrees will build on this. Typically you are mostly likely to see stats unless you do AI /u/Sinapi12 is unfortunately right on some subjects like AI, CV and some financial stuff.

Graphics can get maths heavy but a lot of the time, you work with frameworks that hide a lot of that from you.

Look carefully at the syllabus and don't be afraid to approach the school."
31,Like math better than computer science,Have you considered majoring in math instead? Everyone doesn't have to major in computer science.
32,Survey for master thesis regarding security advisories,"404\.  Escaped underscores?

https://user-surveys.cs.fau.de/?r=security_advisories_acs"
33,FAQ,Start with VBA macros.
34,"In the 60's when I got introduced to computers, ""Files"" had the most overhead - we tried to reduce the number of files we used to an absolute minimum. But most modern ""packages"" have hundreds of thousands of files. Seriously, what has changed?","Basically, filesystems and storage devices got better.  There used to be limits to the number of files that could be in a directory without killing performance.  In those days I recall that on a FIDOnet mail distribution server, sorting the mail was slower than defragmenting the drive and then sorting the mail, because a fragmented file was literally thousands of times slower to read.  But in the late 90s to early 2000s, HDDs started coming with significant amounts of on-device cache and the ability to serve multiple requests (scatter-gather), and operating systems started taking advantage of this (not to mention implementing caching strategies of their own).  Today nobody bothers defragging drives (even when they still have spinning drives where ""defragging"" is a concept), because it gives no meaningful performance benefit any more.  And for the same reason, if you have a million files, there's no longer much of a reason to split them into a thousand directories of a thousand files each - the single million-file directory isn't going to bog things down as it did in the past.  (Thoigh there's still \_some\_ limit - a billion files might still give you hiccups.  But the new limits are less likely to be reached in practice.)"
35,Triple encryption EDE vs DED,"Backwards compatibility with single DES. By making all keys the same in the EDE case, it's as if you are passing it through single DES. This allows a chip implementing 3DES with EDE to act as a traditional DES chip if needed."
36,What ought the ideal professor be like?,"In Electrical Engineering, the ideal professor is a 2 meter sphere."
37,Is this Finite State Machine diagram correct?,"That FSM works, but also allows for e.g. ""the good good good good good man swims well well well well well well well well"". Not sure if that's what you want."
38,Is dynamic programming related to dynamic programming languages or are they just false friends?,"Completely unrelated.

Dynamic programming (misleadingly named, I'd argue) is a technique for breaking a problem into smaller sub-problems.

Dynamic languages are basically ones that aren't compiled (e.g. Python and JavaScript as opposed to C++ and Java)."
39,Need help with algorithms class,"Schools like Harvard and MIT post lectures on YouTube, you can find algorithms lectures there. You can also adjust the playback speed on YouTube"
40,I am struggling in intro to computer programming,"It's probably not possible to memorize where to put each syntax element.  What you need to do is understand _why_ each element works as it does.  The only way I know to do this is to write some programs, and (hopefully) the logic of it will eventually become clear to you.

I agree it's hard to look at a blank editor and know what to type in an unfamiliar syntax.  So perhaps start by modifying existing programs.

It doesn't look like English because it is not English.  It's a programming language, not a human language.  Compared to human languages, it's extremely fussy about rigid rules of grammar.  So don't approach it like it's a human language.  It's closer to mathematical symbols."
41,How bad is this CS curriculum?,Is Data Structures and Algorithms usually that late? I took it my freshman year
42,"If I were dual boot a computer, what underlying mechanism prevents one OS from corrupting data in the other OS's partition?","Nothing. I can definitely reformat my Linux partitions from Windows, and sometimes access the files (DiskInternals Linux Reader, Ext2Read). I can (and do) access my Windows files from Linux. For a long time, NTFS write support was unavailable because it wasn't reliable. And of course, I could just reformat those Windows partitions from Linux anyhow."
43,Logic gate simulator,Perhaps you are looking for [nand2tetris](https://www.nand2tetris.org/)?
44,"Need help with data preprocessing, I am stuck here.","It'd be much easier for people to help if you posted the actual text of the code and error rather than a photo of your screen.

That said, 155 GiB is a **LOT** of memory. Perhaps you can divide the work up into bite-sized chunks?"
45,Math and computer science,Doesn't sound like a 'traditional' CS degree. Sounds more like IT.
46,How is mobile prioritization implemented technically,Happy to do your homework for you.
47,BIG-O...,"The *amount of steps it takes to run the function grows slower*, in the context that you're asking. That doesn't mean the function is slower; it actually means the exact opposite. You're taking ""slower"" to mean only one thing here, that being ""function run speed"", but actually we're talking about ""how the amount of time it takes to run the function relates to its input"". For that you definitely want slower, because ""the amount of time increases exponentially with respect to the input size"" is very bad indeed.

O(n!) isn't the fastest, either. You can get arbitrarily high, there simply is not fastest. Quick examples: n^n grows faster than n! and e^n^c grows faster than n^n where c>1."
48,Binary to character displaying on screen.,"As far as the computer is concerned, there's no fundamental difference between a byte of memory that stores the letter ""A"" and a byte that stores the number 65; they're both represented as the binary bit pattern 01000001. If it's in a region of memory that the software *interprets* as a character, then we say that location stores a character instead of a number. But at the level of machine code and logic gates, they're the same thing.

If something needs to actually draw that letter on the screen, then software is responsible for making that happen. 

For instance, if you're using a bitmap font, then there will be a table of pixel data stored somewhere in memory. Entry 65 in that table will have an image (originally drawn by a human font artist) that looks like the letter A. And the text-drawing code will do something like: ""for each character in the string, look up the corresponding character in the font, compute the screen coordinates it should be drawn at, and copy the character's pixel data into the framebuffer at the appropriate position.""

Your graphics card or GPU is responsible for taking that buffer, which stores the image that *should* be displayed on the screen, and sending it to your monitor one pixel at a time.

(In olden days, the graphics card was also responsible for converting character data to rendered images, because CPUs were so slow that it was worth off-loading that job to dedicated hardware. Nowadays, graphics cards still include that functionality for backwards compatibility, but it's only used during the early boot process. In modern operating systems, software is in complete control of the text rendering.)"
49,Is a computer science degree worth getting?,"1. If AI can replace software engineers, then it can also replace essentially any other white-collar job. In that case, you should not worry about “what job opportunities will I have?” because the world economy as we know it will become very very different.

2. Furthermore, a CS degree is not a professional training. It is not a “programmer” degree - instead, it enables you to become a Comouter Scientist. After that you can just as wel become a data analyst, consultant, middle-manager, sci-fi writer or karate master.

To conclude: it is worth getting if you are interested in CS. If you are not, then I would not recommend - if you are only doing it for “easy bucks”, then I would not recommend, because you might feel miserable."
50,Help Starting my CS PhD,"One of us! One of us!

I finished my PhD about 25 years ago, feeling stupid, overwhelmed and inadequate^1. It seems to have been OK. 

Mind you I felt stupid, overwhelmed and inadequate about different things to the ones I felt stupid, overwhelmed and inadequate when I started, so something must have changed. I now also feel stupid, overwhelmed and inadequate over different things to those. I do take comfort in the fact that one of my wife's students, who has just submitted and is a shoo-in for one of the world's most deserving PhDs, also regularly reports mild twinges of a similar sensation.

For how to start. What thing really makes you sit up and pay attention, every time it's mentioned? Start there. Your advisors aren't always going to be a perfect fit to what really interests you. They're there to help you be a researcher that passes the sniff-test as you do your apprenticeship. Not, necessarily, to enrol you in a project.

^(1 Story of my life, really)"
51,What high school topics should one have cleared before starting college-level CS mathematics?,"My advise is to not worry to much, the mere fact that you care and are perhaps intimidated to some extent puts you on top of many other people – I think it’s a good thing.

I would say try to go back to Calculus and grasp some of those ideas more carefully. Another thing could be linear algebra and discrete math, but these two are quite different from calculus in my perspective. There’s an interesting book that teaches you linear algebra but it’s like an anime (sounds dumb but it’s intuitive, I personally didn’t learn from there I can recommend it based on what I’ve heard). 

You should try to grasp some of the fundamental components of some high level programming language, like Java or C++. Python is quite nice but it sucks at asynchronous computing and it’s a burden of memory and not similar to other OOPs. It would be ideas to start with Java or C++, depending on what they offer at your institution. And don’t get me wrong I love Python, but it’s not a good idea to make it your first programming language (it’s very good for LeetCode but don’t worry about that).

In a nutshell, try to revisit calculus, try to read the book on linear algebra and learn the fundamental structure and semantics of a high level language. Learn GitHub while learning how to use your language if possible. Learn what’s a UML from YouTube and how to work with them. That should be it for now."
52,Sorting algorithm that performs fewest absolute number of comparisons?,"https://stackoverflow.com/questions/13092548/which-sorting-algorithm-uses-the-fewest-comparisons

> Merge-insertion sort is the sorting algorithm with the minimum possible comparisons for n items whenever n ≤ 15 or 20 ≤ n ≤ 22, and it has the fewest comparisons known for n ≤ 46.

---

I wonder if it makes sense to 

 - cache results `(id1, id2)` &rarr; `boolean` where id is a unique, quick ""id"" of the elements
 - exploit transitivity of these results (but I can't think of a data structure that does this effectively)

---

Alternatively, is it possible to represent the elements as another, easier-to-compare type with identical ordering?

e.g., each element could be represented as a string; while this would be an additional O(N) step, this might - in an extreme case - still beat O(N log N)."
53,"Are my interpretations of what ""Spurious failure"" mean and Bus arbitrage does, correct?","I read the first few paragraphs and realized I don’t have the energy for this right now, but I’m upvoting if for nothing else that this will be some serious deep dive stuff"
54,hash collision simple question(very simple one!),"I think you got a probability higher than 1 bc you actually sum up probabilities of having 2, 3 and more collisions

How I will count that:

1. the first value go into one of 1M buckets
2. the second value has 1e-6 probability to go into the same bucket
3. out of remaining 999,999 cases, the third value have a collision with 2e-6 probability
4. and so on

so, the probability of lack of collisions for 1000 values is 0.999999\*0.999998\*0.999997\*...0.999001"
55,"what share links to online cs lessons (the basis I'm starting from zero), lessons I'd complete within like a month I wanna know the basis before going to college to get my cs degree","Harvard's free CS50 course is a solid resource to go with.

I'm not aware of any alternatives that are quite as good, though I'm sure there are others out there.

Here's a link to Harvard's CS50 course: [https://cs50.harvard.edu/x/2023/](https://cs50.harvard.edu/x/2023/)"
56,Calculating the time it takes for a packet to transmit,"> N*((F/P)+H)/R - time taken for one segment to reach B.

So far so good.

> P\*(N\*((F/P)+H)/R) - time taken for all segments to reach B.

Nope. You're assuming that two packets take twice as long to transmit *end-to-end* as one packet, which would only be true if A waited to transmit packet 2 until the instant when packet 1 *was received at B*. But that's not what the problem says; it says A transmits the packets with no delays, which means it begins sending packet 2 as soon as it has finished sending packet 1 to the first router.

In fact, there's nothing in this problem to indicate that A even knows when B has received the packets. (In a real protocol, it would eventually find out by getting acknowledgements from B, but those acknowledgements would also have their own delays.)"
57,Lower bound of the channel capacity,"Wait, do those probabilities add up to 1?"
58,Structure that approximates large products,So these are not logic gates?  They're real-valued adders or multipliers or something?
59,"Why are modern encryption algorithms so ""complicated""?","I'm not a cryptography nerd, so my thinking on this might be completely wrong, but here goes...

Let's say I'm a hacker trying to break the encryption you just described. Like any good hacker, I have your encrypted message and your algorithm, but not your key.

I'd start by assuming that there are some 32-byte strings that have an anomalously high (by many orders of magnitude) probability of appearing in the original data aligned at indices that are multiples of 32 bytes. An obvious example would be `0x0000000000000000000000000000000000000000000000000000000000000000`, as many files will have a big block of all 0s somewhere. But I could also construct 32 bytes of standard HTML header or JPG header or whatever; I might have a library of thousands of these anomalously common strings.

Now I go through your encrypted message, and at each 32-byte block, I iterate through my 'guesses'. For each guess, I xor that guess with the encrypted block, apply your hash function to the result, xor *that* with the *next* 32-byte block, and perform some straightforward heuristic analysis on the result to see if it looks like meaningful data (of the sort that would follow my latest guess) or random garbage.

This attack isn't foolproof, it won't work all the time, and it may not provide the entire original message even when it does get a hit, but it may work often enough to represent a security concern. Let's say you've encrypted 200 photos as JPGs and that each JPG has a standard header 48 bytes long where bytes 16 - 19 represent the image width and height and the others are fixed. (I don't know if JPGs actually have that, but just assume they do; similar patterns do exist for some filetypes, so the concept is solid.) Even if each JPG header starts at a random position in your encrypted message, chances are at least one of the 200 will be aligned with the 32-byte encrypted blocks. I construct, let's say, 300 headers by using the standard 44 bytes and filling in bytes 16 - 19 with typical JPG resolutions like '4096x3072' or whatever. I iterate through your message xorring each encrypted block with each of my 300 guesses. Somewhere around the 42nd JPG (let's say), I get lucky, in that the JPG header aligns with the encrypted block and has bytes 16 - 19 matching one of my 300 guesses. When I hit that guess, I xor it with the encrypted block, hash the result, xor that with the next block, and (uniquely for this guess) notice that the first 16 bytes of the result match bytes 32 - 47 of the standard JPG header, something that has a very low probability of happening by accident. Now I know both the hash value and the original data at that block, *and* I know that I know them, so I can exit my guessing loop and just iterately apply the hash to decrypt the last 159 JPGs out of 200. I still can't decrypt the first 41 JPGs, but clearly I've found more than you wanted me to."
60,Hardware limitations of handling dynamic sparse tensors: do GPUs suck at handling changes in sparsity?,"How do you represent sparse arrays? Do you have to allocate billions of zeros, or is there a clever way to map the address into a compact address space? Can you use hardware memory mapping? 

Figuring out that data structure and make it efficient would be a lot of fun!"
61,Can someone help me understand this puzzle?,"the board is random BEFORE the coin is flipped, and it stays the same after the first prisoner changes a coin. So it doesnt matter it is random, if they have the same system they will get the same result.

Check this step by step solution here. Yo can even play some interactive boards: http://datagenetics.com/blog/december12014/index.html"
62,Eye have a question for you guys.,"the science of computation, i.e. that which you do with computers:  compute.

on a tangent your username somehow fits your spelling of ""I"""
63,Line simplification for time series (y/x-axis have different units),"I'm a little confused by your question. Presumably, what you care about is simplifying the *displayed* polyline, so why wouldn't you just convert both the x-axis and y-axis values into pixels, using the scale of each axis?"
64,How feasible would a modern remake of an IBM 1401 or other old mainframe computer be in 2023?,"Not very feasible. You’d have to bring back entire technologies that don’t exist any more. 

One example is core memory. Nobody has the facilities needed to produce core memory any more. The same goes for the type of transistors they used back then.

There are several youtube channels about restoring these first generation computers. Watch them to see the incredible challenges this poses."
65,What exactly is so hard about a hard disk drive?,"People were used to floppy disks which were soft, hence the term"
66,How are logical segments of a process created?,"The operating system has a facility called a loader which is responsible for taking the executable image output by the compiler and loading it into memory to actually be run.  The exact details of this are platform specific, but many platforms require a _relocating loader_.  On these platforms, the compiler produces an artifact containing not just the binary data of the program, but also a list of addresses that need to be ""fixed up"" by the loader.  This needs to be done at runtime because at compile time, it's not known at what address the program will be loaded.

The Motorola 6809 made a big deal of having fully relocatable instruction set, so compilers could output binary blobs that could just be loaded into memory and jumped to.  To accomplish this, the 6809 had separate user and system stacks.  In the days of 1Mhz (0.001Ghz) processors, the improvement in load time was noticable.  But as processors got faster, the architectural complexity required to support fully relocatable object files became more important than the loader speed, particularly once processors got fast enough that the fixup could fully happen in the time unavoidably taken by inter-sector gaps, head movement, etc, while loading the file.

As to your bonus question about malloc, a user process calling malloc only knows about addressing in the virtual address space of that process.  Malloc returns an address and the user process just uses it.  Any mappings between virtual and physical memory addresses happen only in the kernel."
67,Is it legal to webscrape data that I already have been given full access to?,"Not a lawyer. But there’s nothing fundamentally different from a web scraping script and a web browser. If you’re allowed to do it a web browser, you should be allowed to do it with a script. You noted one peripheral difference: it’s easier to do harm with a script. I think if you’re querying with the script at about the same rate a human would be doing, you won’t do harm."
68,What are the conditions necessary for a programming language to have no undefined behavior?,"It is certainly possible to have no undefined behaviors.  (For example, a Turing Machine itself is fully defined.)

Most languages choose to leave corner cases undefined to help compiler writers take advantage of hardware.  This is typically done in places where IRL there *wouldn't* be any difference.  For example, in scheme [a language which is pretty simple and pretty carefully defined], I was surprised to learn it is *not* constrained what order function-arguments get evaluated in:   when calling `foo(expr1,expr2)` it's not guaranteed that `expr1` is evaluated before `expr2` is.  That's because (a) it lets the compiler take advantages of multiple cores or other parallelism, and (b) it's uncommon in scheme to use mutation, so evaluating `expr1` rarely changes what `expr2` might evaluate to. 

...And I was about to write that C++ *does* require left-to-right evaluation, but I was [mistaken](https://en.cppreference.com/w/cpp/language/eval_order):
the snippet `int n=5;   foo(n, n++);` might end up calling `foo(5,6)` *or* `foo(6,6)` (undefined behavior).

Another example: consider the contents of a freshly-allocated array.
In C++ the initial contents could be anything, while in Java the initial contents are guaranteed all zeroes.  This means the Java compiler will probably add code that explicitly zero-initializes the array, even if the the programmer's code immediately proceeds to initialize the array in some other way themselves — wasting time.  But Java prioritizes consistency over efficiency.

(Note that the Java compiler is presumably allowed to skip zero'ing the contents, *if* it can look at the code and verify that the programmer's code initializes each location before ever using it.  That might be easy in many common situations, but it can't *always* determine when it's safe to avoid initializing — that'd be equivalent to the Halting Problem!  So the compiler would have to be conservative, and still perform the zero-initialization whenever it's not able to totally reason about the programmer's-initialization-loop.

To make things much much worse IRL, Java has to worry about having zero'd contents if an exception gets thrown (and caught somewhere higher up), like an Out of Memory exception.  So even

    String[] names = new String[2];
    names[0] = someFunctionThatWillReturn(""hi"");
    names[1]=""bye"";

it probably needs to set `names[1]` to `null` before it calls `someFunctionThatWillReturn(""hi"")`, and then only after that succeeds (without throwing exceptions) is it allowed to assign `""bye""` to `names[1]`.)

The C++ compiler's ""undefined behavior"" means it doesn't have to worry about any of this, and assumes the programmer has fully thought everything through [or more likely, that the programmer doesn't care about the array-contents if there's an out-of-memory error]."
69,Question about epsilon transitions in NFA to DFA exercises,"Yes, you are correct. epsilon transitions are basically free moves you can make without any inputs, so you can indeed go from a to b using epsilon transition, consume ""1"" and go to a, and then go from a to b again using epsilon transition.  


Cool thing is that epsilon transitions don't give any additional power to NFAs (other than being easier to draw)"
70,What's the relationship between the incompleteness theorems and undefined behavior in programming languages? Does the first incompleteness theorem imply that any Turing complete programming language must have undefined behavior?,"There's certainly a strong resemblance between Gödel incompleteness and Turing uncomputability.  But I don't think this relates to undefined behavior in programming languages.  For example, universal Turing machines themselves do not have any undefined behaviors, and neither do perceptron-based ANNs.

The reason real-world programming languages have undefined behaviors is not always just that the writers of the language specification didn't or couldn't find a way to avoid it.  Often, undefined behaviors are intentionally introduced, to make compilers or runtimes faster by not having to handle difficult parsing cases or make expensive runtime guarantees.  This has nothing to do with incompleteness and is just a choice made by the language designers."
71,Algorithms used in autonomous drone navigation [ research paper ],"Since you are writing your own research paper you should be searching IEEE, ACM or similar to get this information. The papers you select can then referenced and cited in your own work."
72,What are some good discussion assignments for an online CS intro course?,"If they're getting any actual programming experience, then perhaps some questions on types: ""what type should we use, to represent … #people in a room, time-remaining-in-soccer-game, name, zip-code""  [and then scale up for arrays/lists — a motel with 100 rooms; the time a certain player was on-field for each past game, etc.]"
73,Does lower bars mean less reliable,"Basically, yes. Packets ""degrade"" as the receive power decreases. You can think of it like an old TV where the picture becomes increasingly ""snowy"". Eventually, the error-correction code cannot correct all the errors and packets must be dropped. When a packet is dropped, it will need to be re-sent, so the receiver will send a request to re-send the corrupted packets..."
74,Logic Gate construction,It's just what you've written out.  There are three gates.  The NAND gate has inputs A and B and the NOT gate has input C.  Then the output of both the NAND and NOT gates goes to the input of the OR gate.
75,Answering some techie questions,You'll probably get a better response if you ask your specific questions in the comments.
76,Trying to understand asynchronous I/O,"Are you trying to understand what the various language frameworks do with this?  Or how it works at an OS or hardware level?

On Linux, if you want blocking I/O, you can call the normal I/O functions like `read` or `write`.  If you call `read` then your thread is taken off the ready queue and placed into IOWAIT until the system interrupt handlers and so on do their thing and the data is ready, at which point you are placed back on the ready queue and the `read` call returns.

If you want non-blocking I/O, you can call `aio_read` or `aio_write`, which do all of the above _except_ they don't put your thread into IOWAIT status.  So the function call returns immediately, and you can go off and do other things while the OS and interrupt handlers get the data for you.  You can call `aio_error` to find out if the data has finished reading, or if there was an error during the read.  Once `aio_error` returns success, then you can safely read the data from your buffer.

Using `select`/`epoll`/etc is just a nice way to wait for things to happen without explicitly polling.  It's not fundamental to how I/O (sync or async) actually works."
77,Is everything RPC?,"The term ""RPC"" has a broad and a narrow sense.  In the broad sense, it is anything on one computer that invokes a function on another.  In this sense, you are correct that HTTP is an RPC mechanism (at least, when used as such).  There are even specific protocols like XML-RPC and JSON-RPC that use HTTP as their transport mechanism.

However, there is also a narrow sense of the term ""RPC"" that refers to a specific protocol, sometimes called Sun RPC, documented in [RFC 1057](https://datatracker.ietf.org/doc/html/rfc1057), that includes the whole transport stack.  This protocol is actually older than HTTP and is heavily used by NFS, among other things.

So when someone talks about RPC, it's important to understand if they mean it in the broad or narrow sense.  (Assuming the person you're talking to is not _also_ confused on this point - a lot of people seem to be.)"
78,How long will digital computing last? (Speculation welcome!),"Quantum computers are analog, and may find real-world applications in solving optimization problems.  But analog (including quantum) computers don't really lend themselves to the kinds of things we do with digital computers, so there's no currently foreseeable future where digital computers are gone.  They just have analog (including quantum) coprocessors that get fed problems by the digital CPU."
79,Aren't a processes' PCB and TCB terminated when the process enters the Finished State?,What do you mean by terminated ? As in it's swapped back to the disk? If so then in most OS that would be the case as the page possesing the PCB in ram isn't used
80,Math knowledge and skills required to understand probabilistic data structures,"[I've written an illustrated explanation of HyperLogLog!](https://backdrifting.net/post/066_hyperloglog) (And another on [bloom filters](https://backdrifting.net/post/067_bloom_filters) if you're excited about more probabilistic data structures) The intuition behind the algorithm doesn't require any advanced math - it's true that solving for the bin compensation factor in closed form requires an integral, but you could approximation `a_m` experimentally, and production implementations of HyperLogLog use a table of approximated values rather than solving that equation directly. You _do_ need the harmonic mean to average bits across the bins, but I'd argue that this is not advanced math, just a little obscure. [The average speed example on Wikipedia](https://en.wikipedia.org/wiki/Harmonic_mean#Average_speed) makes the harmonic mean intuitive for me."
81,How do I select a subset from a set of objects by minimizing the sum of property values while also minimizing the number of distinct values of one property?,"Hmm - what's the weighting of the different criteria? You can only really optimize for one thing at a time (but you could define a ""score"" combining the criteria).

Treated separately, these problems are not difficult. For the minimum sum, you just take the 10 smallest elements. For the most unique elements, you take one from each distinct value (repeating as necessary).

A combination of the two gets trickier. You can certainly take the smallest of each unique value for property3, but depending on the relative weight, it might be better to swap one out for a lower value for property1 or 2. If your score function is linear, I think a greedy algorithm works - pick the 10 lowest distinct values, then consider swapping out a distinct value for a lower value if it's beneficial.

I will also note that there are variations of this problem you might encounter. If you can take fractions of an item, you may have a linear programming problem, which has its own techniques. If you must have integer values and you have other constraints (like the sum of property2 must be less than X), you have an integer programming problem (specifically the knapsack problem in that case), and the optimal solution is NP-complete (meaning brute force is the only approach), but you can get approximate solutions quickly."
82,Why can't email spammers be stopped?,"> Email server that received the request to send more than (let's say 50 emails) blocks the send and notifies the sender not to send the email and disables the account.

Plenty of people have legitimate reasons to send bulk email, but spammers also often connect to the receivers SMTP server to send the email, not their own, to avoid detection.

Also, some people intentionally setup/maintain SMTP servers for sending spam, and spammers can use these without getting blocked"
83,Seeking Advice for Navigating Theoretical CS Research as an Undergrad,"I know you think this is a dumb joke, but I'm serious. I never really grasped tensor calculus until I moved to a state where THC is legal. But it's undeniable: I can see functions and higher-order relations in predicate calculus, and mappings of very abstract objects clearly. Visually, kind of, but not pictures.

I'm just saying, if you tried it in college, you might want to try it again,  because it acts differently. Instead of making you goofy and shy, it gives you insight and the ability to see the relations between things and how they fit together. All the ""morphisms."" 

Like, I see equations, not as complex structures that I have to understand, but as simple components that slide over and under each other, their position telling the relation.

It also lets you visualize a 4D cube directly, rather than as a 3D shadow. All faces are on the outside surface.

It helped me when I was learning stuff for my masters in digital security. I imagine it would help a lot in graph theory!"
84,Should I go into computer Sciences?,"Pick up a class on Python online and try it. Then you'll have an idea if you enjoy it. I like udemy but there are other options. As far as the math goes, if you put in the effort to do it and learn it well you will be able to do it. Don't take shortcuts in it though because it all builds on each other."
85,Could a GPU work without TMUs or ROPs?,"GPU is turing-complete, so it can do any calculations

Earliest 3D accelerators replaced software (CPU) rendering with specialized rendering units that worked 10-100x faster, that's all."
86,Is there anyway to identify hard drives physically?,"A hard drive is usual like a thin brick. Some have a disk shown, some don't. It's like the size of a cell phone. If it's smaller like a credit card that's an ssd."
87,Any Educational Tool to Visualize CompSci Concepts? - Linux,I have no experience to add to this but I really like this idea
88,A question about the halting problem,"The key difference between the inversion problem and the halting problem is that the halting problem deals with algorithms that _read the source code_ of other algorithms.  H+ doesn't actually run H - it looks at it and through some process of analysis, decides whether it will halt."
89,What would have happened if Google bought open AI,I'm guessing it would be about the same.
90,lost,"Learning programming takes considerable time and focus.  If you're truly interested, then you need to write programs on your own, outside of the class assignments, because you want to.  If you don't want to, then honestly it's better that you go ahead and fail the class as a signal to the world that programming is not your thing.

If you want people on reddit to help you in this journey, try /r/LearnProgramming, which is focused on helping people with these kinds of questions."
91,"I made a Genetic Algorithm bit of software based on an mid2000s NN guide. I transliterated C++ to Typescript and it seems to work well except in one respect. They don't evolve they just get worse, so I'm wondering how to diagnose the issue",Use a debugger to step through the training schema you’ve implemented and cross check data types + value ranges from the original code.
92,How many nodes does a neural network need to run a very powerful AI like GPT-4 or Stable Diffusion?,Well the rumor is that gpt-4 has something like 1.7 trillion parameters. In this context a parameter usually means the weight attached to the edge between 2 nodes in the NN. The exact structure of the NN used isn't public but I wouldn't be surprised if it wasn't in the billions of nodes.
93,Universal Analogue Computing Principle,"So, at first glance this seems like nonsense.  Why should we imagine that the outputs of the harmony or dissonance operators must be ordinal for all possible systems?  Why should a weighted sum of these operations mean anything at all?  Assuming they _do_ mean anything at all, what values ought to be assigned to the weights and why?"
94,Getting started in the field of multiagent systems,"I don't know anything about multiagent systems, but I think what's going on here is just that you've found a topic to new and/or obscure to have much of a footprint in the superficial online world.  So, you have to put on your scholar hat and start using the tools of academia.

You know that Professor Wooldridge has done work you find interesting.  So visit his page at Cambridge - https://www.cs.ox.ac.uk/people/michael.wooldridge/ - and take a look at his bibliography, which is extensive.  Read the abstracts of his papers.  Read the ones that strike your interest.  Look for co-authors, particularly recurring ones, and see if they've written anything interesting.  Make sure to look at the citations, and follow the citations to find other papers and authors.  Google Scholar helps with this, but what you really want is online access to a good research library - if you're a student at a university, you probably already have this.

If at the end of this you still have questions that aren't answered by any papers you can find, congratulations - you've reached the frontier of human knowledge.  At this point you will know which authors are doing work closest to the kind of things your interested in, so it will be a fairly natural next step to reach out to them by email and ask if they know any papers or current work being done on some specific unanswered question.  The better your question, and the more work you've done beforehand, the more likely you are to get a response.  (Even from your own lecturer.)"
95,Desktop Circa 1997,"Rooms from Xerox was a way of switching desktops in Windows 3.x  It didn't visualize things as a cube, but the left and right and top were clickable to go to different desktops. 

If it was 1997 chances are the OS was windows 95.   I'd guess it was some 3P program to simulate virtual desktops, similar to rooms.  MacOS also had virtual desktop software that worked similarly.

Do you remember what the physical computer looked like?   Was it just a beige tower or desktop?  Blue/purple and toaster shaped?  Black cube?  A flat compact grey box? Keyboard and computer all one piece?"
96,Did you learn programming more from formal education or from self-taught/other methods?,"You could format it as a poll.

I'm self-taught. I think I read 50-100 books regarding computers, programming and CS since 12 till 17."
97,Time Complexity,"Let's start with some basics.  You have some input `X={x0,x1,...,xn}` and some algorithm `F` which, when run on `X`, produces some output `F(X)`.  You want to know how long it takes to run.

The obvious answer is to grab a stopwatch and time it.  This will tell you how long it takes to run for a specific input.  You can run it with many different inputs and write down the results, and for most algorithms, you'll likely notice that the running time mainly depends on is the number of items in `X`.  So you can imagine there being a function `t=T(F,n)` that returns the running time for the algorithm and input size.

These calculations are likely to be finicky, because they have to account for all the particulars of the implementation.  So for example, suppose you analyze a bubblesort algorithm, calculate the running time of each line, figure out how many times that line is executed, and come up with `T(bubblesort,n)=0.00037n(0.00173n+0.000074)+0.000731`.  You look at several other sorting algorithms and come up with even more complex functions.  And of course the constants are only valid for the particular computer you ran or analyzed the timings on.

These functions are interesting, but not particularly handy for a programmer or mathematician who wants to be able to talk in a convenient way about the running times of algorithms _in general_.  To make things easier, we make two simplifying assumptions: first, that the main thing we're interested in is how these T-functions behave _when n is large_, and second, that we're interested in how they behave _relative to each other_ (ie, not on any particular computer).

This brings us to big-O notation.  A big-O term like `O(n^(2))` represents a set of T-functions.  For the first assumption above, we choose specifically those for which the term `n^(2)` dominates in the limit as `n` goes to infinity.  Recall from calculus that in the limit of a polynomial, the highest power term dominates.  And for the second assumption, we eliminate all multiplicative constants.  This brings us to the formal definition:

`O(g(n))={f(n) : ∃c∃k∀n n>k⇒0≤f(n)≤cg(n)}`

This says that when we say `f(n)∈O(g(n))`, we mean that we can choose arbitrary constants `c` and `k` such that for all `n>k`, `f(n)` is always less than or equal to `c * g(n)`.  Less formally, for large `n`, `f(n)` differs from `g(n)` only by a multiplicative constant.

What does this actually mean when we make claims about algorithms?  Suppose we know some algorithm - let's call it slowsort - is `O(n^(2))`.  This means that if you went to the trouble of measuring and defining a T-function for slowsort on your computer, that this T-function would be in the set of functions which differ only by a multiplicative constant from `t=f(n^(2))` for large n.  Importantly, this says very little about small values of n.  If you're going to spend all your time sorting 10-item lists, then the big-O classification isn't useful to you.  But it does tell you something about the behavior as you scale up the input size.

Suppose we also know that another algorithm - let's say fastersort - is `O(n log n)`.  It's important to understand that this does _not_ tell us that fastersort is actually faster or slower for any specific value of n we might have in mind.  Perhaps fastersort takes an hour to organize its working memory before it even gets started.  But _in the limit_, as n goes to infinity, there will _eventually_ be some value of n above which the `O(n log n)` algorithm always dominates the `O(n^2)` algorithm.

Hopefully this is reasonably clear.  There are more complex situations, like when the running time doesn't just depend on a single value for the input size and we see things like `O(m*n)`.  But even then, the key points are that we're talking about what happens for arbitrarily large values, and that we're making a statement about what category the algorithm's T-function falls in to.

---

(Note that my use of set theory here is at odds with many standard CS textbooks.  Big-O notation was first used by Paul Bachmann in 1894, making it older than modern set theory.  The original big-O notation would write `f(n)=O(n^(2))` instead of  `f(n)∈O(n^(2))`.  In the original notation, the equals sign does not mean algebraic equality, but rather establishes a relationship of classification between the left and right sides.  This leads to endless confusion in a modern context since people can't help reading = as algebraic equality.)"
98,What will be the way for XR?,"I don't think it's a foregone conclusion that this technology will become a part of daily life in the short term.  Your questions are, to my way of thinking, getting it backwards: you observe that maybe the hardware will reach some threshold of miniaturization, and then ask which software platform might win.  But nobody is motivated to buy a software platform, or even a piece of hardware: they're motivated to buy an _application_.

What is XR going to actually do for people, that make them want it to be a part of their daily life?  Does it just do the things mobile phones do now, like take photos, make phone calls, communicate with people, etc?  If so, why is this experience better on your face than in your hand?  Or does it do something different, that mobile phones can't do, and if so, what?

After answering these questions and coming up with a thesis like ""people are going to use AR glasses to navigate when walking around as tourists in a strange city,"" it becomes clearer how the software and hardware would need to work.  For that use case, you need something like Google Maps, which inherently works better as an app than as a website; you need to give it camera access so it can figure out where you are; and you need to give the user an unimpeded view of the outside world, but with navigation arrows and labels imposed on it.  So do you still carry a mobile phone, and select your destination using its touchscreen?  Or is there enough of a UI within the glasses to eliminate the need for a phone, and if so, how do you interact with it?  Etc etc.

There's not really a conversation to be had until you have a specific use case in mind."
99,How much slower is an Efficiency core vs a Performance core in Intel architecture?,It's going to vary based on workload. The best way to find this out unfortunately is to benchmark it yourself.
100,How are computers smarter than us if we invented them?,How are cars faster than us if we invented them?
101,Why does restarting the computer fixes most of the issues?,"Because it returns the system to a known state.

The reason computers crash, other than actual hardware malfunction, is that the software enters a state that wasn't expected by the developer.  For example, the developer was expecting a particular memory allocation to be freed, but for one reason or another this doesn't happen, so the memory becomes unusable to the rest of the system.  Over time this kind of thing can build up and eventually cause problems.

Rebooting the system returns it to the state where nothing is allocated yet.  So even if there's buggy software that will slowly make the system worse, that hasn't happened yet at startup."
102,"If the speed of transmission of an electrical signal happens at the speed of light in the material, why would zero resistance increase computation speed?","The question isn't how fast they go, it's how often you can send one.  In a medium with resistance, sending an electron implies energy loss which appears as heat.  So you can only send electrons as fast as you can remove the heat created by their passage.  Electrons in a superconductor would produce far less (no?) heat, so you could send them more often.

Note that there's a big difference between a superconductor and a superconducting semiconductor.  The room-temperature superconductors currently in the headlines are more likely to be useful (if at all) for power distribution rather than for CPU chips.  They would let us send electrical power over long distances without wasting a lot of it unnecessarily heating the power cables."
103,Should I publish with De Gruyter?,"First, congratulations on presenting your work at a conference! That's some fabulous experience as an undergraduate.

Did De Gruyter reach out to you personally, or was the email automated? I get emails from publishers, conferences, and journals every time I publish a paper or a preprint, telling me they've seen my work on <paper title> and would like me to consider publishing in <their venue>. They've always been spam, often fishing for submissions to predatory journals.

Honestly, a publisher reaching out to an undergrad about their research sounds like a red flag to me, and doesn't add up. If a scientist sees your work, thinks it's great, and reaches out to offer to collaborate or suggests you submit to <conference/journal they're an editor for>, then that's one thing. But a publishing company reaching out to you? Why? Do they even have the background to judge the quality of your work? Do they run a journal where your work would be a great fit? Or is it just a pay-us-to-publish situation?"
104,"Resnick's ""Thinking Like A TREE"" -- AI relevance?","I would say it's a good analogy for understanding optimization, and optimization is definitely at the core of modern AI.

The TREE method he describes is essentially gradient descent, which is how neural networks are trained. Machine learning is just the creation of computer programs through optimization."
105,Maximum N value I can store in RAM?,"This approach looks reasonable as a textbook problem solution (all except 12,909 being approximately 10^(4) rather than 10^(3)).

In the real world, some of your 8GB will be taken up by other data like the operating system, math software, miscellaneous working data areas, etc.  Your matrices will also probably be stored in a format that includes some metadata in addition to the numerical content.  And so on.  So if your interest here is in determining the actual performance capabilities of your machine, this result should be looked at as a somewhat optimistic upper bound."
106,Confused about DFS,"Both 2 and 4 are children of 1 in the graph you showed. Normal graphs don't have a concept of order among their children, nor do they have a concept of left/right/top/bottom or straight lines. So 2 and 4 are both equally valid choices when deciding which child to visit first.

Of course, in specific contexts/use cases there can be a defined order among children and rules deciding which child you want to visit first, but in general it's a completely arbitrary decision."
107,Difference between horizontal scaling vs migrating to micro-service,"Scaling vertically is putting your app on a bigger box

Scaling horizontally is putting your app on MORE boxes - but still the same app

Microservices are splitting up your application into independent pieces.  This is ""outside"" of the notion of scaling, because each microservice can be independently scaled horizontally and/or vertically

Scaling microservices can sometimes be simpler, because say the problem is that your Login api is under huge load but everything else is not.  You need to make N boxes running your whole monolith

If you had microservices, you could make N Login service containers, and not scale the other services.  

This is simplified - often there are choke points like a database or a gateway."
108,Are the incompleteness theorems specifically about Turing complete systems?,"Yes, it can. The Turing machine formalism is equivalent to the formalism used by Gödel."
109,What exactly does it mean for a number to be uncomputable?,"Well, the answer to your question essentially boils down to the [Church-Turing thesis.](https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis)

Yes, computer scientists have collectively chosen to *define* ""uncomputable"" to be the same as ""uncomputable by a Turing machine"". This is because every remotely ""plausible"" computational scheme that has been considered is, at most, as powerful as a Turing machine.

For instance, with some relatively weak assumptions, you can show that any system whose behavior can be described by the laws of quantum mechanics can also be simulated to arbitrary precision by a Turing machine. (See, e.g. [this paper](https://arxiv.org/abs/1102.1612).) In theory, these assumptions might be able to be violated by things like closed timelike curves, but it's not known whether the real-world laws of physics allow for such loopholes.

So even though the Church-Turing thesis is not a rigorously-proven mathematical theorem, it serves as a reasonably strong *philosophical* justification for using Turing machines as the benchmark for what is and isn't computable."
110,Turing Machine Problem Help,"basically you want a state thta checks if you're in the b(1\^n)b case.

so when you read the first symbol, if it's 0 enter state q10 otherwise enter state q11 and move right (you  can name these states whatever you want later). these states will check for the 1\^n. So as long as you keep seeing 1, move right and stay on the same state.

if you reach a blank symbol, then if you're in q10 you can enter state q20 whose responsibility is to right 0 on the output. If you're in q11, then enter state q21 and write 1 on the output.

If you reach a 0 instead,-  if you're in q10, you need to check the next symbol is blank, so enter q30 and move right. if the next symbol is blank then enter q21 as before and write 1 else enter q20 as before and write 0.

\- if you're in q11, enter q20 and write 0 to the tape.

Lastly, from your starting state q0, if you read a blank, you need to enter q4 and write ⊥ to the output."
111,How comparable it is to play a video on its native resolution than playing it on a window with a different size?,"In principle, you're right: rescaling a video to a larger size does require more computation than just copying the raw pixels to display it at its native resolution.

But this problem -- taking each screen pixel coordinate, mapping it through some simple mathematical transformation, looking up the corresponding image coordinate, and interpolating smoothly between neighboring ""texels"" -- is exactly the same operation that is performed in 3D graphics rendering to apply textures to surfaces. GPUs have dedicated hardware designed to do exactly this operation, and as you can imagine, a lot of work has been put into optimizing and parallelizing it.

These days, even a low-end integrated graphics chip can perform billions of texture lookups per second. So resizing a video to 4000x2000 resolution at 60FPS shouldn't be particularly taxing."
112,How are closures supposed to interact with variable binding and resolving?,"/u/ghjm is correct. There is no ""supposed to"".

There are various ways to handle these issues in programming language design. We would prefer variable handling in closures to be done in a way that makes closures useful, easy to design correctly, and not prone to tricky bugs. I imagine that, in the passage you reference, Nystrom intends the reader to understand that the current way variables are handled is actually prone to tricky bugs and so ought to be changed.

And if JavaScript also does it the icky way, well, that's yet another not-so-great design choice in the specification of JavaScript.

In any case, Programming Language design is not easy. You'll find little glitches like this in every PL that is full-featured enough to be useful for writing real-world software."
113,Discrete Structures,Look up introduction to discrete structures on youtube
114,Can every computer program be represented as just a number?,Yeah. Everything on a computer is just a number. But it's a really big number.
115,"Is Turing completeness really important? Especially these days, when we're so abstracted from the hardware.","OP got an answer, and further discussion seems to be turning hostile, so I'm locking this thread."
116,Understanding the difference : coder|programmer|software developer|software engineer .,"As used in job titles, there's not much difference.  ""Programmer"" is no longer fashionable, and was part of an older scheme of job classification where a ""programmer"" just wrote programs to a spec, but someone called a ""systems analyst"" wrote the spec.  ""Coder"" is newer, but has the same sense of being less creative/consultative.

In academic computer science, some of these terms refer to different branches of the field.  Programming is the writing of computer programs, with a primary focus on data structures and algorithms; Donald Knuth's famous book ""The Art of Computer Programming"" is almost entirely about algorithms.  Software engineering, on the other hand, is about the structure and management of large software systems - how do we design large software projects to avoid complexity collapse; how do we make software bug-free and safe for the public; how do we staff these projects; how do we measure and report on their progress; and so on.  So if you followed the definitions of words used in academia, a ""software engineer"" would be quite a different thing from a ""software developer"" - but in industry, these terms are used completely interchangeably."
117,How much money has Don Knuth given away to people who found bugs in his writing?,https://en.wikipedia.org/wiki/Knuth_reward_check
118,What do I need to know to study computer forensics?,"I have a master's in Computer Security and Digital Forensics.

You definitely need to know about computers. You don't need to know computer science or math or programming at all. 

You do need to be  real familiar with operating systems and REAL familiar with PC and Linux file systems. They barely touched on Apple.

You dissect a highly-modular, extremely well written virus and rebuild  file headers that were altered to make porn vids unplayable.

The classes were online and I can't remember a single one that wasn't interesting. They give you a virtual machine (desktop in a Cisco window), and you have to find contraband or evidence hidden in the confiscated machine.

That means knowing where the emails are, knowing what formats are documents, and how to hide porn in rarely-used data structures in the hard drive file system. And yes, even how to find porn. Besides PornHub.

Forensic software helps you with that. One assignment was  to scan your own computer for porn with the scanner that the cops use. You didn't have to say what you found, just that you did it.

You also learn how to hack every *conceivable* device. One tool probes a remote system by interrogating it with various inputs before login, and tells you the version of the operating system based on the error messages it returns.

I mean, is that clever, or what!

You also learn about packet sniffing and reducing all the data in a capture file and stuff. I used it to spy on my housemates, but by that year, everything coming out of the browser was SSL encrypted.

Every week, you do research and report on topics like sync flooding, DNS attacks, and DDOS. The most interesting report I did was on detecting steganographic data hidden  in images.

I got to write a search warrant for computer equipment using the laws of my state. I was the only one in the class who thought to subpoena the keyboard to capture programmable macro strings.

And (as of 6 years ago), they actually had a USB stick that slid underneath ther running windows, virtualize the operating system, and capture all the internal windows tables and buffer memory.

For one assignment, we were supposed to find everything we could about a stranger (or anybody we could only access through the Internet).

I remembered a porn movie that was done in the condo of the  actress (Ava Taylor) and at her swimming pool. The production company was in Miami, and it didn't take long to identify the large buildings You can see through her window. Google found the swimming pool, and the view from her balcony gave me her floor. I got her condo number looking at the building's layout from the condo web site.

For some reason, it was creepy that the shape of her inner corner unit  in the condo office map was the same as the video taken from in her apartment. I also found her real name.

I felt like I was stalking her, which was weird because I was stalked myself once. Watching her be fucked on her bed only added to that feeling.

But it was all just an assignment for digital forensics!

And there's so much other cool stuff! The least interesting part was filling out all the on-screen forms required to document what you do and validate chain of custody.

I completed all the courses with a 3.8. I let one of the guys who lives here (M) take a class as me in Culture of the Southwest American Indians. He got a C in the class. Usually everyone in grad school gets A's because you only have to just do the work. But you can do that because it's interesting.

I never applied for the degree because I only took the classes to learn interesting stuff, kill time while waiting to die, pretend I have friends, and pocket the housing allowance and other money in the student loan that I have no intention of paying back because worthless, filthy prostitutes are officially unemployed. 

Yeah, I used to do nuclear engineering stuff and paid big taxes. But after I got treated the way I was by the normal people in the business world, I said fuck it. JUST FUCK IT.

If somebody would pay for it, I'd get a PhD, too. I have a whole lot of great ideas that nobody ever thought about. I bet it would be even more fun. As an undergrad, I figured I'd do a PhdD about simulating systems of neurons in software and getting them to recognize image patterns.  But like so many other cool things that other people got to do, I never got to do that. Somebody else invented neural networks.

But digital forensics was definitely fun!"
119,Need Assistance with Java Assignment: Building a Hash Table,"The goal of a good hash function is that it gives deterministic results, but that these results aren't predictable.  So you should always get the same hash for the same input data, but if you make even a slight change to the data, you should get a completely different hash.

One possible hash function is to get an integer value of the data, square it, and then choose some number of middle digits (so if the data is 3627 and n is 4, the square is 13155129 and the hash is 1551).  For a given piece of data, this always gives the same hash, but the hash is completely different even for adjacent or otherwise similar values.

As to what to do with collisions, it depends on what you're doing with the hash.  If you're using it to speed up retrievals in a key-value store, just have the hash table store a list.  If two items evaluate to the same hash, they'll wind up in the same bucket.  But during retrieval you have the real key, so just go through the bucket and compare each item.  It's still a _lot_ faster than having to do a brute force search of _all_ the items."
120,How do interpreted languages handle forward references?,"Each language is different, but often they're tokenized when read (or when entered for a REPL).  In the case of BASIC there's probably some kind of lookup table by line number, but it's been decades since I looked at a BASIC interpreter."
121,Do we really have to take infinite recursions so seriously?,"> Why is the incompleteness theorem anything more than a curiosity in the back page of Scientific American?

The reason we tell the man in the street about the Incompleteness Theorems is that they are *interesting*. It's a bit of highly theoretical mathematics that the average person can get a glimmer of understanding about. But, no, it isn't something that person needs to know in a practical sense.

The reason people who learn advanced mathematics and computer programming and whatnot are told about them is that there is an important philosophical point to be made, which these people need to know about: the ideas and procedures you are learning have absolute limitations. There are mathematical statements that cannot be proven or disproven. There are problems that no computer program can solve.

The reason computer scientists learn about them is that it's part of computer science. Studying computer science is what computer scientists do.

> Why can't we say arithmetic is complete except for statements involving infinite recursion?

> Yes, of course we could SAY it. And it would be true.

No, it wouldn't. The magic of Gödel numbering is that it allows us to show that a formal system that is powerful enough to talk about basic arithmetic is also powerful enough to talk about its own proofs.

In such a formal system, we can make a statement that says, effectively, ""I cannot be proven."" But if you say, ""Aha, that's recursion,"" then I must point out that if we *look* at the statement, then we don't see any recursion. It's just a statement about numbers and simple arithmetic. The fact that those numbers happen to be Gödel numbers is what allowed us to construct the statement, but we cannot see that just by looking at the statement all by itself.

> You'll downvote it

Why would I do that?

> but you can't answer the question!

I think maybe I did. What do you think?"
122,Flutter under the hood,Its uses skia wich is a cross platform drawing library. Basically draws on a canvas.
123,Is the CS:IP for first instruction address in 8086 is not consistent?,"Unfortunately, that page from MIT is **wrong.** Not only is its explanation incorrect, but the QEMU output that it quotes is **also wrong**.

First, pay close attention to the ""reset vector"" wiki page that you linked. Notice that the reset addresses are *different* for different generations of x86 processors. On the original 8086, the value of CS:IP after reset was FFFF:0000. On the 286 and later processors, this was changed to F000:FFF0. So that's part of the discrepancy that you're seeing.

However, there's more to it than that. On the original 8086, the physical address computation was basically just (CS * 16) + IP. But on the 286 and later processors, the segment registers are actually *selectors*, which point to segment descriptors that have their own ""base"" and ""limit"" fields. So the address computation is really (CS.base + IP).

This base/limit mechanism is always active, even though it's only really useful in protected mode. Protected-mode software can set whatever base address it wants, but we still need to maintain compatibility with real-mode 8086 software that doesn't know anything about those segment base addresses. So to preserve backward compatibility, whenever the processor is in real mode and you load a 16-bit value into CS, the processor creates a ""fake"" segment descriptor whose base is (CS * 16). Then that base gets added to the IP register and everything works as before.

Or at least, that's what happens whenever software loads a new value into the CS register... but when the processor is reset, something different happens! On a reset, even though the CS register is initialized to 0xF000, the hidden ""CS.base"" register is *not* 0xF0000; it's initialized to 0xFF0000 on a 286, or 0xFFFF0000 on a 386 or later, which is what QEMU emulates. (This, too, is described in the Wikipedia article that you linked.)

So in reality, the physical address that is first executed when you boot up QEMU is not 0x000FFFF0, as the MIT page claims; it's 0xFFFF0000 + 0xFFF0 = 0xFFFFFFF0. You can confirm this by typing `x/i $pc` at the QEMU monitor console to see the *actual* address of the instruction that QEMU is about to execute.

So why does the MIT course page show something different in the GDB output? Well, you can blame MIT for that, not GDB. The ""disassembly"" that it's showing you isn't coming natively from GDB; it's generated by a [`.gdbinit` script file](https://github.com/phlalx/jos/blob/master/.gdbinit.tmpl) that is included with the 6.828 course repository. That script adds a hook to GDB that shows the values of CS:IP (and the contents of the corresponding instruction) before every GDB prompt. But it has a bug: it *naively* computes the physical address that *would* be used in real mode -- if there were no selector shenanigans going on. This behaves correctly if the segment register has been loaded by software, but it gives you incorrect results immediately after a reset.

This bug is masked by the fact that QEMU maps the last 128KB of the emulated BIOS into memory *twice* -- once at linear address 0xFFFE0000, and once at 0xE0000. So even though the GDB output is technically showing you (and reading an instruction from) the wrong address, it still shows you the correct instruction (rather than garbage) because the same data is at both addresses."
124,"Are there any advantages to 32 bit software, or 64 bit software always better?","32-bit software is often a little smaller, because the code only needs to use 4 bytes for a pointer where 64-bit has to use 8 bytes.  Also, for tasks that don't require the extra memory space, and on certain CPU architectures, it's possible that 32-bit code might sometimes run a little faster because ultimately it is moving less data around.  But these are both pretty minor."
125,Does anyone know any youtube channels that teach operating systems in depth?,I suspect that learning in detail generally requires written material and exercises. Well-made videos and lectures are good for overall understanding but for details it's usually good to take one's time with reading books that go into those details and by doing exercises that require them.
126,AI Denial and the Threat of Job Displacement,"There's healthy skepticism and then there's pathological skepticism, and we see both in the CS/eng community.

My take is that the lower-lower-end of the hierarchy is in serious trouble. I mean the sort of exceedingly green and rote layer, like fresh grads and junior contractors (make this button green, spin up a shitty dashboard). I could see that part of the industry being effectively wiped out at some point. When? No clue, but I think LLMs will mostly get better at code generation, even if they seem to get worse at other things as they tune them for compliance. I don't know what that means in terms of general employment prospects but it seems not good.

But it seems unlikely that we'd get context windows or even the fundamental technology right for doing the sort of systems-level thinking that most mid-upper level engineers do until we have not just an AGI but a fairly well-developed and servicified AGI. And that's enough for most of them to proclaim loudly that there's nothing to worry about."
127,(Need help) Repeating Operating Systems course.,"OS is one of those courses that can be taught from either a strong theory basis (e.g. stochastic processes, queuing theory, etc)., heavily applied (write a shell!) or somewhere in between.  Which was yours ?"
128,Virtualization and emulation misnomer.,"None of these terms are strictly well-defined, but the way I think of it is that emulation and virtualization are two different ways to run a virtual machine.  If the VM runs using a software CPU - as in, there's a program on the host CPU interpreting the opcodes, and CPU state values like register contents are stored in memory locations on the host - then this is emulation.  If the VM executes instructions on the hardware CPU, with the MMU or other hardware features providing the isolation and only peripherals implemented in software, then I would call this virtualization.

So I don't see any conflict with PCSX2 being an emulator, and it also referring to a ""PS2 virtual machine.""  This is just the machine the emulator is emulating - the hardware PS2 that the game thinks it's running on."
129,"In neural networks, why not use per-connection non-linearities?",[deleted]
130,Should I switch from deploying directly to server to deploying to containers?,Containers shine for projects that involve more than one server. Then you just spin them up and down with docker-compose.
131,Is mimesis in nature more similar to GANs or Stable Diffusion algorithms?,"In terms of algorithms, it's probably most similar to genetic algorithms, since they are explicitly based on biological evolution.

The ""starting condition"" for Caligo butterflies isn't really random.  It's some prior species that was already surviving in the environment.  At some point some pattern appeared on proto-Caligo wings, which was slightly successful at reducing predation (if, in fact, that's what the markings do).  Over time, more successful patterns were selected for, and eventually we got the Caligo.

The problem with genetic algorithms is that they take many many generations and therefore a huge amount of time, just as biological evolution does.  The other algorithms you mention are designed to arrive at an answer much faster, but this makes them less similar to biological algorithms."
132,"How is my computer able to calculate factorial of 50,000 in a second?","The CPU has to do to more than 50,000 multiplications to calculate this result because the native operand-width is only 64-bits, and a 213k digit number is far larger than 2^64 . Some internal software library will convert the problem into a BigNum ... there is no universal standard of what a BigNum is, it's just some arbitrary-precision number format. One way to implement a BigNum is to calculate in ""base 2^64 "" which means that each register value is itself treated as a ""digit"". 

Some very sloppy envelope calculations gives about 650k bits width of the final result, which is about 10,000 of these BigNum ""digits"". Throwing in a couple other simplifying assumptions (ask if interested), this works out to about 250 million multiplies and adds. An add always completes in one cycle and multiplies can complete in 1 or 2 cycles on a typical modern CPU. So, 250 million multiplies and adds at 2 GHz works out to about 250 milliseconds (with some specialized optimizations [ask if interested], the speed might be cut in half or less). Note that this is assuming perfect pipeline conditions, no interrupts, no exceptions, perfect looping, etc. But yes, a large operation like 50,000! can easily complete in a fraction of a second on a modern CPU.

What is truly mind-boggling is when you translate that over to a GPU. You can do all the same operations on the GPU, but a modern SOTA GPU like the RTX 3090 can parallelize by a factor 10,000-fold or more. So, a modern GPU could perform 10,000 calculations of 50,000! (or a similar operation) in 250 milliseconds without breaking a sweat. And as impressive as that might feel, it really doesn't capture the full magnitude of what a modern GPU can do. If you have a modern desktop computer with high core-count and a recent GPU, you *really do* have a machine sitting on your desk that, 25 years ago, would have classed as a super-computer."
133,Is pursuing a PhD in IE worth it for my academic career?,"Normally this would be considered off-topic since it is about career advice rather than the topics of computer science.  However, I'm approving it because it's sufficiently different from the usual ""how can I start a software development career"" posts, and because it might lead to useful insights about the interface between CS and industrial engineering."
134,Zero Knowledge Proof,"A ZKP is sound (a lie is unconvincing), complete (the truth is convincing), and zero-knowledge (the prover's secret knowledge can't be discovered by the verifier through the protocol itself.) The protocol should be repeatable without violating the ""zero-knowledge"" property.

  
If we extend your example where you are a prover and I am a verifier and your statement is ""I have hacked your phone."" and I suspect you are lying, I could change my password and then ask you to prove your statement again and again for an arbitrary number of additional rounds of the protocol. The more times you prove your statement with the protocol, the less likely it is that your statement ""I have hacked your phone."" is false.

  
In general, examples in a ""real world"" context can be helpful to understand the idea of a theory, but those examples should be interrogated closely so that they do not become misleading. The theory of ZKP involves two participants, a prover and a verifier. Either they are honest or they are dishonest. The prover wants to convince the verifier that a given statement is true. A ZKP is sound, complete, and zero-knowledge. If the prover's statement is false, then the prover is dishonest. If the verifier abuses the protocol, then the verifier is dishonest. 

  
If we attempt to engage in a ZKP but the statement is vague (can have it's truth derived from means outside the protocol as you discuss in your last paragraph) or can't be verified, the protocol we're using is not a ZKP, it's just a flawed interactive proof. If you can get my password without hacking my phone, the protocol we've defined is not ZKP."
135,Need help impressing someone who likes computer science,"Ask if there's a problem he's stuck on and then when he inevitably replies yes, follow up by asking if he wants to rubber duck it with you. 

bonus, this requires absolutely no knowledge on your part."
136,Why this Code Editor does not exist yet?,"Sounds like a cool editor UI! But I don't think it'll save much navigation time.

Many IDEs and code editors have collapsible functions / methods / classes, or have a side bar listing the functions allowing you to jump directly to a definition. This eliminates the scroll time you're discussing. Since the underlying code is stored in a linear text file (at least for most languages), a circular or rectangular view abstracts the underlying text file without a clear advantage (except navigation speed, which the aforementioned strategies address)"
137,AskComputerScience is back on the air. What do you want from this subreddit?,I'd like to see the sub close in continued protest.
138,Solving a variant of the Maximum Coverage Problem,">the total number of subsets from B that are completely contained in these progressive subsets

Do you mean by this, for A is the set 

    { 1, 2, 3, 4 ... },

B might be the set

    { 1, 2, 3, 4, {1, 2}, {1, 3}, {1, 4}, {2, 3}, {2, 4}, {3, 4}, 
     [1, 3], [2, 4], [1, 4] ... } 

And P would be the set

    { 1, {1, 2}, [1, 3], [1, 4] ... }

So the first set in P contains only one set of B (1), and therefore scores 1 point, the second set of P contains 3 sets of B:

    {1, 2, {1, 2}}

, the third set of P contains 7 sets of B and scores 7 points:

    {1, 2, 3, {1, 2}, {1, 3}, {2, 3}, [1, 3]}

And the fourth contains all sets of B listed and scores 13 points?

Do you control both the order of A and the subsets of A which are contained in B?"
139,Books to learn about theoretical computer science and the basic concepts of programming languages?,"I'm not a CS major but I think Michael Sipser's Intro to Theory of Computation is a pretty well-known intro to theory of computation. I guess it does assume a bit of aptitude or experience with proofs, some basic set theory, etc., so I'm not sure how much of that gets taught in Applied Computing. I also haven't read his book in full but I like what I've seen and there's a nice online lecture series to go along w/ it"
140,Do Reddit apps actually need anything API related to function?,"The problem: I just downloaded the source code for this page (before my comment here) and it's 788,445 bytes (+ about 9.2M auxiliary file you don't need). The part of it that's your message is 1,129 bytes. Of course, there's additional information like what sub we're on, your username, when this was posted, etc, but that's nowhere near the difference.

I'm actually surprised reddit itself isn't concerned that people switching from API to scraping will hit the site's bandwidth hard"
141,Recommendation for data structures and algorithms resource,"We used Sedgewick & Wayne's *Algorithms 4th Ed.*, I thought it was rather good. There's a lot of content from it online at Princeton's site, look for ""algs4""."
142,Very obvious way to develop a Desktop/GUI application like a web app?,"Isn't that just a web browser? You've just described websites, or in particular [progressive webapps.](https://www.smashingmagazine.com/2016/08/a-beginners-guide-to-progressive-web-apps/)

It's very popular right now - half the apps on your phone work this way. And yes, the tradeoff is performance and memory footprint, but today's computers are so fast that they get away with it."
143,What % of your workflow is typing?,"I am a fullstack dev at a junior level at a company that offers its own Enterprise CMS product, serving large companies and organisations in the Netherlands.

This would be the breakdown of my 40 hour work week:

6-12 hours of meetings (scrum events, irregular meetings)

8-16 hours communicating outside of meetings, documenting, doing Git stuff, changelogs, updating the sprint board, that kinda stuff.

4-8 hours analysing an issue / thinking of a solution

4 - 12 hours actually typing

8 - 12 hours troubleshooting, devtesting, debugging, solving dependency hell, that kinda stuff


Typing is not actually a big part of software engineering, unless your job is to implement the design of a solution in code to the letter.

When you're just getting started, it may seem like the fun part, but it's actually not really. Now, administration and documentation is not fun either, but designing and planning and analysing is way much more fun than just typing.

Anybody can type. Thinking of how to solve a problem is a way more satisfying challenge to solve than just writing out hundreds of lines of code at a time. But maybe that's just me."
144,Can the minimum storage size of a 3D object be determined from an obj file?,"The .obj is stored as text. I'd expect the actual title screen geometry to be stored in some much more compact binary format.

I followed some info in the Mario 64 disassembly (which can be rebuilt into a matching ROM file), and went into the libutra library. It has this definition for vertex data:

    /*
     * Vertex (set up for use with colors)
     */
    typedef struct {
    	short		ob[3];	/* x, y, z */
    	unsigned short	flag;
    	short		tc[2];	/* texture coord */
    	unsigned char	cn[4];	/* color & alpha */
    } Vtx_t;
    
    /*
     * Vertex (set up for use with normals)
     */
    typedef struct {
    	short		ob[3];	/* x, y, z */
    	unsigned short	flag;
    	short		tc[2];	/* texture coord */
    	signed char	n[3];	/* normal */
    	unsigned char   a;      /* alpha  */
    } Vtx_tn;
    
    typedef union {
        Vtx_t		v;  /* Use this one for colors  */
        Vtx_tn              n;  /* Use this one for normals */
        long long int	force_structure_alignment;
    } Vtx;

    typedef struct {
    	unsigned char	flag;
    	unsigned char	v[3];
    } Tri;

It seems like a vertex definition is 16 bytes, and each triangle definition is 4 bytes.

Given 644 vertices and 1,212 triangles, I suppose that the binary representation might be about 15,152 bytes for the geometry, texture coords, and colors, but excluding texture images."
145,Encoding subset sum as cnf,"Design a Turing machine that solves Subset Sum -> cook levin theorem shows this can be encoded in a circuit (i. e., circuitSAT) -> reduce circuitSAT to 3SAT"
146,Graphical Representations of Algorithms? How to go backwards from a graph to an algorithm?,"Those don't look like graphical representations of an algorithm, they look like graphical representations of a binary search tree."
147,In coding what things you need to know abt math,"For programming in general you should know elementary algebra and boolean algebra.

For game programming (assuming involving graphics), you should have a basic knowledge geometry, trigonometry and linear algebra (vectors, matrices). You should understand complex numbers, and slightly more advanced, also learn about quaternions.

Mechanics and calculus are essential if you are doing any physics simulation.

Also learn about interpolation (and extrapolation) and bezier curves.

You don't need to be a mathematician, but you should have a firm grasp of the basics.

The rest is learning common algorithms on top of this existing knowledge. You never stop learning when you're programming."
148,what type of sorting algorithm is this?,"Everybody is telling you bubble sort, but they're wrong. 

What you have here is a variation of selection sort. A slightly less efficient variation than typical, since it performs more swaps than necessary. 

Usually when you see selection sort, there's a separate ""min_index"" variable. In your implementation, you're using processes[i] itself to keep track of the minimum value found among the subset processes[i..n].

Bubble sort only ever swaps *consecutive* elements. That's the key difference between the them, otherwise they're pretty similar and it's easy to confuse the two.

EDIT:

[This geeksforgeeks article](https://www.geeksforgeeks.org/introduction-to-exchange-sort-algorithm/) shows something similar to what you're doing - swapping the minimum element in place rather than keeping track of its index. The article refers to it as *exchange sort* if you're not satisfied with the ""selection sort"" answer. 

In reality though exchange sort and selection sort are almost identical algorithms since they work almost exactly the same way - the difference being how you keep track of the minimum element."
149,Need help on sorting front end or back end,"If, by any means possible, sorting and minimizing datasets, they should always be done on DB level to avoid sending unnecessary data across anywhere. If then you still need to sort, the sorting of data can be done wherever it feels best and what is needed. For example, if the sort is only once and not changed by params in the front-end, do it in the backend to not rely on user hardware. If it is changed by a selection in the front-end, it can be beneficial to do the sorting in the front-end so as not to send the same data sorted differently from the backend multiple times."
150,How does one optimize their functions?,[deleted]
151,What is going to happen in computer science 1 semester?,">Will they teach me statistics, probability theory and calculus from scratch

Yes. They will usually do placement testing and put you in the appropriate classes based on your incoming knowledge.

Don't worry about being bad at math. Computer science really isn't about math anyway."
152,2 short ML questions,">can too high of a learning rate cause an overfit?

For decision trees, yes. If you're experiencing overfitting one thing you can do is reduce the learning rate. 

>does a decision tree with maximum depth of 4 always have a greater variance than a decision tree with a maximum depth of two, provided they are trained on the same data?

It's going to depend on your dataset. 

Think of your model as a distilled representation of your dataset. More complex or larger datasets generally require a more complex or larger model, unless the model can find some hidden structure that represents it more neatly."
153,How do you keep focused with constant Slack/Teams messages from teammates?,Slack is asynchronous.  Don’t try to make it real-time.  Use a calendar integration and mark yourself as busy for large blocks during the day.  Have slack pause notifications when in a meeting.  Set a status of “heads down” Variations on all this.
154,‼️ 🚨 🙏 |Fresher| PLEASE HELP FASTEST WAY TO UNDERSTAND A PROJECT?,"With all due respect, you gain what you put in. You didn't put the effort in, and now you're experiencing the consequences of those actions. There's no shortcut, experience actually writing software and projects is the only way to gain knowledge."
155,Can i learn making AI without any computer science background at all?,"From what I know, your lack of mathematical and statistical training will hurt most, but you can try to look through online courses like Andrew Ng’s to see what knowledge you’re missing.

https://youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU

https://youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS"
156,Best web dev framework to learn?,You have frontend experience? Then you know JavaScript and [Express](https://expressjs.com/) is probably the easiest choice for you.
157,I am a self taught C++ programmer - is there a free test or exam online I can use to test how much I remember?,[Leetcode.com](https://Leetcode.com)
158,Weird Dock behaviour with external HDD Windows and Steam Deck,"Try posting to r/techsupport, r/windowshelp, or some other tech support subreddit. This sub is rather intended for questions about the academic and scientific field of computer science."
159,"The Paradox of Determinism: Gödel's Incompleteness, the Turing Problem, and Free Will","> the Turing problem demonstrates that no general algorithm can determine whether an arbitrary program halts or runs indefinitely. This undecidability challenges determinism's claim of complete predictability.

No. it doesn't. Computing the future state, at a specific time, given the current state doesn't require you to determine if some function terminates or not. In particular in a universe with a finite lifespan.


> Gödel's theorems establish that within a consistent formal system, there exist statements that cannot be proven within that system, implying the existence of undecidable aspects in the future state.

This one is a bit more complex. First you are missing the assumption that this holds for any formal system with a finite set of axioms. Perhaps the universe just has an infinite (non enumerable) set of axioms. Or is an inconsistent formal system.

Besides the observable universe only has a finite amount of information, so that throws a wrench into the whole equation.

> The introduction of a hypothetical halting oracle, proposed by Alan Turing, provides a potential resolution

It doesn't actually do that, since it just introdeces the second order turing problem.

> Such a paradox invites inquiry into the nature of free will.

Only if you can give a formal definition of free will, which I haven't seen anyone do. Otherwise I fail to see how this would have anything to do with free will."
160,Is this sub showing up as not having mods to you?,"I'm not seeing any moderators either.

> This subreddit is unmoderated.

> Visit /r/redditrequest to request it.

That's what I see."
161,Majoring in Computer Science or Business Analytics – advice for a 18 year old,"CS is going to be the most flexible and the most powerful degree of those three. It’s a well recognized and standardized degree program that is sought after in software engineering, business analytics, and data science alike. A CS major can do BA or DS but a BA major may have a much rougher time breaking into CS or DS jobs etc. BA and DS programs also vary in quality from university to university a lot, so some employers seem to be distrustful of them even within the fields they target."
162,Laravel video call with beyondcode/websockets,"er, is there any particular reason you're not using webrtc?"
163,"I got this plastic dog tag thing from a navy recruiter, it came apart and this was inside, what does it do?",RFID antenna so it can be scanned
164,DJ beat sync algorithm,"BPM = GetBPM()

Tempo = BPM

Beat = BPM"
165,"3 ciphers. One of them is RSA, one is transposition, and one is multiplicative or additive caesar cipher. How do I know which cipher belongs to which text?","Not sure about RSA or multiplicative but for transposition.

From my uni days I think you can use frequency analysis to even try decode it if you want.

https://www.101computing.net/frequency-analysis/
Basically count up how many times you see each character, plot it on a graph and shift the graph until it lines up ""roughly"" with what you'd see for a graph on plain text English. You can then also use your mapping to try to decode it.

From that I guess you could use your answer to work out additive/mult by seeing out of the remaining 2 answers which characters always have the same mapping. Since it's just the same function applied to every character.

A is always mapped to f. B is always mapped to -> g for example 

Then the last option would be RSA cause the mappings would be more random. I guess.

Hopefully someone else might be able to help!"
166,How big is the advantage of a non-blocking async backend over a 1-thread-per-request backend?,I looked at a benchmark [here](https://medium.com/@the.raj.saxena/springboot-2-performance-servlet-stack-vs-webflux-reactive-stack-528ad5e9dadc) and the basic gist I got was that if you have thousands of simultaneous requests that take a long time (like .25 second per request or longer) the async approach is better because you don't have to create and maintain thousands of threads where as if your API calls return instantly or your simultaneous load isn't super high it offers virtually no real benefit and makes the code harder for the developers to read and write. According to one Reddit commenter the async approach is immune to [Slowlorris denial of service attacks](https://en.m.wikipedia.org/wiki/Slowloris_(computer_security)) but there are ways to make a blocking one-request-per-thread backend Slowloris proof as well.
167,First website,"My most used web development learning tool was the odin project. 

Are you already familiar with programming?"
168,How to download wikipedia,"https://en.wikipedia.org/wiki/Wikipedia:Database_download

According to that page, the XML dump is about 19GB compressed and 86GB uncompressed. If any software seems to freeze opening that, you might just wanna give it some time, cause the I/O for that will take a bit depending on what kind of storage media you have it on."
169,Taking notes when reading a technical book?,"For me, note taking is more of a way to extract all the relevant points and concepts to incorporate them with the rest of my notes. If you want a summary, it’s usually there at the end of the chapter in a good book."
170,"I want to learn C# and ASP.NET Core, however I don't know if it's the right career choice for me at the moment...","You're not gonna lose anything by learning more languages. Also fwiw I've been in the industry for a little less than a decade and I can say it's not a huge deal if a prospective new hire doesn't know the exact language we use. Just try to be well rounded with a little front end, maybe a little more backend, and some shell scripting."
171,"What is a framework, how can it help me in programming ?","A framework is like an inverted library. With a library, you control execution flow -- you simply call the functions you want as you need them.

The key concept in a framework is [_inversion of control_](https://en.m.wikipedia.org/wiki/Inversion_of_control) -- don't call us, we'll call you! 

Frameworks build in certain entry points where you put your code, and the framework calls them based on some flow. A good example of this would be Unity, where you inherit the Monobehavior class and implement the Update method, which Unity calls once per frame. 

Frameworks are useful in a similar way to libraries, in that they give you certain common functionality built-in so you don't have to code everything from scratch. The advantage with frameworks is they give you more structure of a full solution, so you can get up and running very quickly. The drawback is that they're often less flexible and harder to customize."
172,Color calibration Iiyama G-master G2740QSU,"If you are looking for an easy and inexpensive monitor calibrator, try TruHu.  It uses your iPhone as the measurement device.   You can test it out for free.  In terms of settings, it should be able to calibrate on top of whatever settings your are using.  If the displays has settings that say ""video"" or ""sRGB"", that's a good starting point.  Being calibrated in more important than what OSD settings you choose."
173,How do I shard a 13b parameter LLM? And how do I get multiple users on the same LLM?,I have been wondering about this for a few days now and haven't been able to find much information on how to shard models. It would be amazing if someone could point us in the right direction!
174,Which subjects are interesting?,I don't think we all share the same interests
175,Navigating the Path to a Career in IT: Overcoming Challenges and Seeking Guidance,"So, what is the question?"
176,floating point numbers?? (from a cs beginner),"The tricky part is that because you are counting in binary, the floating part is binary too. 0.1 is not one tenth but one half. 0.011 is one quarter(0.25) + one eight(0.125) = 0.375.


This is the same with negative mantissa. Negative mantissa means you divide the number by two. 2^-1 = 1/2

When counting with the mantissa, you can think of it as number of spaces you move the delimiter. If your mantissa is -1, you move the delimiter one space left. If it's positive, it's the number of zeroes you add to the end.

Edit: fixed an inaccuracy"
177,What languages and what license should I use for this project?,Please like this comment.
178,Need Ideas for Projects,"When i was applying for internships and jobs in my studies it really did not matter what i made, as they just want some evidence that you have the capability to create something. So i ended up making whatever interested me. I made:


A visualiser for sorting algorithms in a game engine. 
Rewrote it to use webgl in stead of the engine

Made a sound synthesizer

It was endlessly easier and more fun to create something i needed/wanted"
179,About laptop requirements for Robotics and AI,Yes. In fact you could do well with less.
180,Job Applications,Now
181,New Computer Science Major,"you don't need to wait to learn languages with formal instruction. the main thing a CS degree teaches you is how languages are constructed and what is going on behind the scenes with parsers and optimizers. but you don't need to know that to knock out programs -- it just makes it easier to pick up new languages since they are mostly fundamentally similar. 

best is probably load one of the web frameworks like Rails or Django or something like that and do their Hello World exercises and move on to writing some javascript on the browser side to build web apps. there are tons of other ways to learn, but web stuff is ubiquitous and well supported. and put it on github so people can browse your code."
182,Cs degree for web dev?,"Very few of the courses taught in a CS degree will be useful for web development, but the degree itself will be critical for landing a job in the field. 

See if your university has any introductory CS courses about databases, or ""Human-Computer Interactions"".  These will be the most relevant courses for full-stack web development."
183,What happens when I don't close a file that I open via a program ?,"It depends. 

In C on Unix if your program keeps opening files and never closing them you will hit the open file limit and not be able to open more. 

In some cases, writes to an open file are buffered and you can lose data if the power fails. Closing forces it to write. 

In most OS it closes any open files when a program exits."
184,MERN or Other Stack for Personal Project?,"A task management app is simple enough that you can choose basically any language or framework and develop something in a reasonable timeframe. Hence the choice of stack is more about pragmatic and personal preferences than any technological requirements.

For most people, if their goal is to learn the specific technologies used for jobs, they just look at the local job market for an idea of which ones are in demand. The choice between expanding the breadth of your skillset vs strengthening your existing skills is also a factor."
185,First summer internship,"Err on the side of being annoying, at least at first.

Basically for the first 2 - 3 weeks, you're not going to know how to do ANYTHING. That's totally normal.

Yes, you should be resourceful. Try to find answers. Try to figure it out.

But...better to just ask your mentor / manager, rather than wasting too many hours being completely stuck. Trust me, they might be mildly annoyed if you interrupt them a lot but they'll be much happier than if you leave them alone and accomplish nothing.

As an intern host, nothing frustrates me more than finding out my intern was stuck all week and never reached out for help. Of course I check in frequently, but I'm not going to check multiple times a day. If you're stuck, tell someone!

Over time, you should need less and less help. Once you've gone through the process of building the code and making a change a couple of times, you should be able to accomplish a lot more on your own. Then if you're stuck on one thing, just find something else productive to do while waiting for an answer."
186,"I want to study every single thing about technology in general, so what should should I study?","You don't have anywhere near enough time in the world to develop high or even moderate proficiency in every field related to computers. 

If you truly want to know computers in an abstract sense then theoretical computer science and information theory are the most general and  fundamental topics. 

Like others have suggested you should pick a major focus and certain related topics to improve your understanding of lower priority interests."
187,Game Concept: Logic Gate Maker and Circuit Designer - Seeking Feedback and Input,"This is definitely not a unique concept. There have been videogames based around circuit design all the way back to [Robot Odyssey](https://en.wikipedia.org/wiki/Robot_Odyssey). Some newer ones are [Shenzen I/O](https://store.steampowered.com/app/504210/SHENZHEN_IO/) (most of Zachtronics' stuff has a programming feel), and [Turing Complete](https://store.steampowered.com/app/1444480/Turing_Complete/).

And, as you note, redstone in Minecraft is also clearly based on circuits.

That doesn't mean you shouldn't do it. Games are 1% idea, 99% execution. If the idea speaks to you, go for it.

If you've never made a game before, assume it will be ten times more work than you expect. Scope it based on that."
188,What is an app or website I can use with my iPhone that’s a search engine that lets me pick and favor search results from specific websites?,"You can do a [Google Advanced Search](https://www.google.com/advanced_search) and in the ""site or domain:"" field put in the URL of the website you want it to pull results from. Make sure to copy the full URL including the http/https part into that field."
189,Do certificates of online coding courses matter ?,"I can't think of a single institution or organization that accepts certificates. They'll test your knowledge in the tech interview and they won't care about any piece of paper you bought with your money.

The sole exception is if the job description specifically includes a particular certification."
190,Does Computer Science research help inform Software Engineering practice?,"Computer science and software engineering are two different disciplines. It's not just a theory and practice divide, it's more akin to the difference between physics and mechanical engineering - some clear co-influences, but asking different questions and using different methods.

For example, there's a lot of recent CS work on dimensionality-reduction - representing a complex and often sparse high-dimensional space using a denser low-dimensional space, as in PCA, LDA, and UMAP. This has applications in machine learning, data visualization, natural language processing, and signal processing, but it's a far cry from being directly applicable to how we write code in industry.

Or, to take another example, there's a lot of network science research concerned with how to handle noisy data. Given uncertain observations of interactions, can we reconstruct a graph using Bayesian statistics? Given an enormous graph, how do we remove spurious noise and get a smaller, more manageable graph, without pruning signals that we care about? Graphs are used widely in industry, not only in obvious areas like social networks, but as a relational data structure for recommendation algorithms like streaming-service suggestions or search engines - but again, this is quite a few steps removed from writing code.

There are other areas of computer science research that are more directly applicable to software engineering. Certainly there are algorithmic groups that develop new more efficient solutions to problems, whether that's new compression algorithms for particular scenarios, new data structures like HyperLogLog suitable for extremely large data, new cryptographic approaches to problems like zero knowledge proofs or shared computation through tools like homomorphic encryption. These findings are usually pretty ready to implement right out of the paper, but that's not quite what you're asking about, either.

Finally, there are computer scientists concerned directly with the development of software. They may work on compiler theory, or how to formally prove that software does not contain bugs, or they may analyze large version control histories to understand how software is developed, and what practices lead to success or failure, how to minimize developers stepping on each other's toes while also avoiding over-siloing. Some look at the open-source ecosystem, how to determine which projects are healthiest, what's 'safe' to use as a dependency for your own work, or what's in danger of collapse.

That's a start to an answer! Computer science research is a big umbrella! The disciplinary boundaries are also pretty fuzzy - how much of dimensionality reduction or probabilistic network theory are computer science, and how much is mathematics or statistics or data science? Is the theory of software development computer science, or is it more akin to a sociological or anthropological study where software engineers are the topic of inquiry? Interdisciplinary research is great, so in my experience computer scientists are rarely that concerned about drawing clear lines here."
191,What is the optimal period to start applying for apprenticeship / job?,You should ask this in /r/CSCareerQuestions.
192,Laptop for programming and gaming under $1300,"I would ignore the programming aspect of this. If the laptop can run the games you would like to play, it will certainly be capable of handling any programming you'll need. 

All that being said, I don't think this sub is your best bet at finding a laptop. Maybe give a look at /r/GamingLaptops instead."
193,Are these new AI techs mainly a result of new/recent discoveries or a result of advancement in hardware capabilities and amount of data available right now?,It's both. The math has been known but which parts turned out to be the important ones wasn't; the technology to test which parts were important in reasonable time only popped up somewhat recently.
194,How useful is CS degree without math?,"From what I hear, it depends on what type of job you're applying for.

Web dev? No one will event notice.

Cryptography or AI? You're in trouble."
195,Computer Science MD recommendations?,"Hi,

Try posting to r/cscareerquestions or some other sub that's more oriented towards questions about careers and studies.

Secondly, you'll probably want to mention at the very least which country you're in. Probably in which area as well, unless you're willing to relocate somewhere on the other side of the country."
196,"Looking for Resources on ""optimizing""?","Typically it’s better to use the built in language features and assume that the implementers chose the best way, internally building the loop if that’s the fastest. Get it working the easiest way available. 

If possible it’s worth profiling the code to see where the real hotspot is. 

Finally, a measurement is worth far more than my opinion. Time it."
197,How does a large application's search functionality work? ELI5,"Given a huge database of what people typed and what their eventual search query actually was, you can build a Markov chain - a data structure that gives probabilities for the next state given the current one.  You can then use this to predict the final search query given whatever has been typed so far.  The big sites then apply various kinds of ""special sauce"" to this - prioritizing things similar to what you've searched for recently, or products they're trying to unload, or what have you - so that ""preferred"" items (whatever that means) float to the top.

Doing this with a time budget of a few milliseconds at the scale of Google is an astounding exercise in distributed computation, of course."
198,My PC broke (I think),"Go to a tech support subreddit, this is not the place for that."
199,Base 2 subtraction,"If you know Base 2 addition, then just negate the subtrahend and add.  You negate in 1s complement by flipping each bit, or in 2s complement by flipping each bit and then adding one to the whole value."
200,Using hash to compare if two web pages is the same faster than doing individual comparison,"You are correct, calculating the hash values does require reading the entire webpage. Comparing hashes would not be faster without some additional context. For example, if you want to compare 100 webpages, and determine which match one another, that's 4950 pairwise page comparisons. Assuming they're long documents, comparing all the characters in each of those pairs would be slow - but if you hash each document, then you can compare (relatively short) hashes 4950 times instead.

Edit: Derped my mental-math (twice!), (100^2 - 100) / 2 = 4950"
201,How do web browsers read and interpret CSS?,https://web.dev/howbrowserswork/
202,Base 10 to base 2 conversion,"It's because each position in the digits of a base 2 number is a power of 2. Even the first one, it's 2^0. That's just how base 2 works. That's also how numbers in computers work, any integer can be made from a sum of powers of 2.

It's not related to bits or bytes in any way."
203,"When online gaming, how is the information synced across devices?","If it uses servers, its basically all the players receiving updates and resources from a server.


If theres no servers (GTAV), all the players PCs share resources with each other"
204,Question: Disabling Turbo Boost for Accurate Clock Cycle Measurements,"Clock cycles are inherently dependant on the CPU frequency. Blocking the frequency makes the measurement more predictable (aka less prone to inaccuracies due to a sudden, temporary, and unpredictable frequency increase due to boosting). Regarding your second question, you may want to disable the power saving features to avoid unexpected idle CPU times, as well as pinning your tasks to a set of physical cores."
205,English Major to CS Job?,I'll recommend going for masters in cs. There are schools that offer transition mscs to non stem undergrads.If you are young and afford it do join them. As for bootcamps i don't know much about them. As you said you have friends who did what you want to ask them they may be able to provide more personal take. Last thing remember to personalize your decision as much as possible
206,Any research into a linux UI for cloud computing?,"You should look at the command lines for [AWS](https://aws.amazon.com/cli/) & [GCP](https://cloud.google.com/sdk/gcloud).

They're not 1:1. AWS does a pretty good job of matching the semantics (see S3 copy) but they deliberately expose quite a bit more information & control than what you'd have with a unix-like CLI. For example - you want a cron-job, do you want it to run on a VM? what resources do you want to give it? do you want to run it serverless? etc. what permissions should it have? what VPC network should it be in? what region? etc.

You _could_ create a bunch of script aliases that would _mostly_ work, but you'd still have to make some decisions - and once you want to start using the more complicated parts, you'd either need to start introducing behavior that isn't present in unix scripts - or you'd need to switch to using the CLI directly."
207,Overclock,"The maximum boost speed stated by the CPU vendor is the clock frequency that the vendor (in this case Intel) states as the maximum the CPU will reach ever under factory configuration.

All modern PC CPUs have their clock speed dynamically adjusted on demand based on the workload they have at the moment. Lower clock frequencies consume less power and produce less heat, so it's generally beneficial to use a lower clock frequency when the workload is low and there are no performance-critical tasks to do. Higher clock frequencies consume more power and produce more heat but allow for faster computation. There's some kind of a latency in switching between frequencies so there's also a compromise to be made in how fast or often the CPU reacts to changes in the workload and is switched between frequencies.

Generally speaking, the base speed is what the CPU vendor guarantees the CPU will reach. The stated maximum boost speed is the maximum reachable under the factory configuration but it's not necessarily guaranteed that the CPU will sustain it under longer periods of time, or that the CPU will reach boost speeds under all circumstances, even if there's a constant workload or some other reason for the automatic frequency adjustment to maximize performance.

Generally, the maximum boost speed can be reached under ""simple"" workloads where the individual instructions for the CPU are simple and not especially power-intensive. More ""complex"" workloads where the individual instructions are more power-intensive might mean that the maximum boost clock frequency cannot be reached without power consumption and heat production going over the specified limits.

The boost speeds also aren't necessarily guaranteed to be sustained, so the CPU might reach the maximum boost speed for a brief period but won't necessarily stay at it constantly over a longer period of time.

Some people might call the boost speeds an automatic overclock that's supported out of the box by the vendor. Practically, what it really means is that CPU designers have noticed the opportunity to go safely over some kind of an always-guaranteed base speed under some circumstances (or actually in quite a lot of them). So, they have designed the automatic frequency adjustment to make use of that opportunity.

I don't know much about actual modern-day overclocking but I think actual overclocking would increase the maximum boost speed (and perhaps also base speed) over that provided by the factory default configuration."
208,"Compression is often a trade off of time against space. What would be some applications for an extremely high compression algorithm, but which takes a long time to compress/decompress","Don’t forget the Shannon limit. If you can compress something to a high degree, it wasn’t a very dense encoding to start with."
209,Verify information without revieling what information is?,"Is it what a teacher/prof said in class?

If so it's something like this. Let's say I have a two function A(n) and B(n) who takes n (integer)

it has the formula of B(A(n)) = n, as it is given.

A(n) is public, everyone knows it. 

I can show you I know B formula by making you put anything in A(n) and then giving you the n. 

It's very simplify but try to find ""zero-knowledge proof"" for more information."
210,Does it matter where I get my CS degree from?,Just make sure it's ABET accredited
211,Forced to go to college instead of Uni,"If it makes you feel better, being behind on Math is common.

I went to a 2 year school that only required Statistics for my associates, but offered the intro programming courses. Statistics did not transfer to my 4 year, but the programming ones did.

Discrete Math was required for the first few programming classes, but since I had them transferred, I was in some Junior / Senior level CompSci classes while also being is Math 100 lol.

And while feeling that being ""left behind"" from your classmates is a valid feeling, just remember that your degree is not a race, its a marathon.

I cannot even remember the last time I saw someone from my highschool at the same school I am attending. Whether they graduated super quick, or left before completion."
212,Can you recommend a book that introduces constraint satisfaction algorithms?,I think Artificial Intelligence: A Modern Approach should cover constraint satisfaction problems
213,Guys what major do you advice me to go into ? I know there is google and (based on what you liked) but what is the real deal? Nowadays we are hearing that AI is gonna take over most of the CS jobs and all what do you guys really think is the best way?,"Hi,

this sub is meant more for CS substance questions, kind of like r/AskBiology is for questions about biology itself rather than for questions about work life in biological fields.

If you can, try posting to r/cscareerquestions instead.

However, a couple of points just generally:

First, career choice can be confusing, but you'll need to try and feed a bit more into the discussion yourself in order to get any useful input from others. Career or major choices depend a lot on what kinds of things you're interested in or what you might be good at. People can recommend majors or fields that are generally expected to pay well or to have good job market prospects, but those recommendations aren't necessarily very useful if there's no personal consideration.

Medicine is in many objective ways a good field but it's not for everyone. People-oriented work such as psychology, nursing or management (even tech management) might be better protected from the effects of automation because people will still want actual human contact, but those fields are obviously better fits for social people persons. Machine learning can be a good field but not if you aren't at least somewhat mathematically oriented or if you don't like maths at all.

What the ""best"" way is (if there is such a thing) depends a lot on the person, and there's no one-size-fits-all recommendation.

Secondly, mid-level or higher-end software development work, or other tech work people with a CS background often end up doing, isn't the first or the easiest thing to actually be taken over by AI. Many other fields will suffer (or change and adapt) first. It sometimes seems like there's a widespread idea that programming or software development jobs specifically will become obsolete, but I honestly don't really know where that idea has come from.

Changes in the job market and even entire jobs being made obsolete are genuine and reasonable concerns. It's hard to project where we'll be in 10 or 15 years with the recent fast developments that have been made in the broad field of AI. However, there's an enormous amount of hype as well, and frankly most of the talk about AI taking over most jobs isn't really that well informed.

Computer science-y things such as software development or engineering will also change at least to an extent. Nobody can tell exactly to what degree that will happen, but there will very likely be some changes. However, programming or software development aren't going to be the first thing to be overrun by our new AI overlords. (And there are also lots of other stuff that's being done with CS knowledge rather than just software development -- CS is a broad field.)"
214,How does LZSS encode back references?,It seems the lzss algorithm doesn't define how you actually code the symbols (whether literal bytes or back references). But most implementations would use something like a Huffman coding (although newer stuff might use arithmetic coding). The details of how these are specified have to be defined for a compression format.
215,career question?,I'd say informatics with comp Sci but it depends on exactly what you want to do post grad. Look at the coursework differences and go with the one that you're more interested in. Either way you'll be employable with a CS degree if youre genuinely interested and learn how things work outside of just your courses.
216,Non-STEAM studying MSc in CS / AI in England,"Remember that in the UK the first year of a CS degree is often mostly shared with the Maths school and there are strong maths elements throughout. What this means is that the Masters assumes a certain level of competence. However, it really depends on what exactly is in the syllabus. Typically you would see statistics, maybe a bit of linear algebra but if you go in the AI/ML direction, then it may mean Calculus and Differential Equations. The best thing is to discuss what is needed.  You won't need everything so it is important not to take too much time on what isn't needed.

Anyway when you go on to a career, you will only see maths in specific areas. Have a look at some papers in the areas that interest you and see what kind of maths you think is needed to understand them."
217,"What's the difference between CS, CE and IT?","Theory, Implementation, Management."
218,"I'm confused: CPU caches, memory fetches, and data oriented design","I smell a bit of overoptimization. I smell a bit of shoving oneself in a deep diving suit when a snorkel will suffice. Nothing wrong with a deep dive if that's what you want, lots of good seafood down there.

If I was you I'd use the C++ boost libraries and use them properly and exactly as guided to get the best results in terms of instruction set usage (e.g. SSE where available), cache usage and compile time optimizations. I haven't used C++ in a while so there's probably a shinier toy in town. I'd rather rely on a library to deal with the lower level optimization than try to reinvent a shitty wheel. The only exception would be if I wanted better performance than the library can give me for a very specific section of code that gets called a lot or looks like a bottleneck when benchmarking performance.

If you can maintain a function footprint (i.e. stack + registers + overheads size) that can fit within your average CPU's L1 (or L2 or L3) cache, and your code is pipelineable, i.e. calculations don't rely on previous calculations as much as possible, and when they do they happen as late as possible, things should be good enough for your libraries + compiler + CPU to give you nearly the best performance.

For a deeper dive, I recommend a selective reading of Computer Architecture by Hennessey to understand how superscalar architecture, pipelining, loop unrolling, Tomasulo's algorithm, scheduling, etc work. The book is great cover to cover, but even reading the first half of every chapter will teach you what you need without getting too bogged down with details."
219,OCR API to convert an image to text and is extremely accurate?,"Even humans don't have complete accuracy translating images to text, we misread and make mistakes all the time. Some things are also just ambiguous: is that a lowercase l or an uppercaee I? Is that an a, or an o with a smudge at the side?"
220,Finite State Machine Question,"Here's a hint to get you started:

The FSM starts in state B, and in order to accept a string, it must end up in state D. The only transition leading to D is from B. So we can conclude that any accepted string must ""loop"" through B some number of times before finally transitioning to D. If the string is 12 characters long, these loops must account for the first 11 characters, followed by a final `a`.

There are (unless I've miscounted) exactly three different possible paths by which you can start out at B and return to B. Each of those paths through the FSM corresponds to a particular character string. What are they? What characters do they contain? How long are they?"
221,«Research grade» languages?,"For imperative programs, you can study Hoare logic, *e.g.*, as realized in the IMP language developed in volumes 1 and 2 of [Software Foundations](https://softwarefoundations.cis.upenn.edu/). For object-oriented languages, you can check out [Featherweight Java (FJ)](https://www.cis.upenn.edu/~bcpierce/papers/fj-toplas.pdf) and its variants. The final chapter of [Types and Programming Languages](https://www.cis.upenn.edu/~bcpierce/tapl/) also develops a FJ-like system to study pure objects."
222,How would a government put constraints on an AI like chatgpt?,People like Elon only want it to be restricted in the sense that they want to make it more difficult for competition to start up.
223,"In the fetch-decode-execute cycle, why are fetched instructions copied to the MDR before the CIR?","Well, it's defined that way. When a memory read is performed, it always reads into the MDR. Think of the MDR like a staging buffer for either instructions or data. It's a place to go very shortly after the instructions or data are available.

Could you save some time moving it directly into the CIR? Possibly, but you'd also complicate your memory interface by having to specify this is an instruction access vs data access so that it gets written back into the right place. The real world concern is that if you remove the CIR, your cycle time gets longer because the instructions now have to propagate farther in the machine to the CIR.

Keep in mind this is a toy architecture. The design tradeoffs that you see here do not necessarily correspond to the real world."
224,How does a computer generate gradients?,"How do you interpolate between two points in an xyz coordinate space?

Also, there's more nuance here.  Instead of interpolating in RGB space you might translate the points into HSV, do the interpolation there, then translate back when drawing on the canvas.  But that requires a little bit of special casing to handle greys properly.  There's quite a bit of literature on how to handle different color spaces for different contexts."
225,Is there a physical difference between ddr4 and ddr5 chips?,"Im not an electrical engineer, but I'm gonna say yes there is a physical difference. Particularly in the architecture of the silicon chips themselves, since the performance stats are markedly different and that can only happen if the chips were redesigned. Correct me if I'm wrong.

So no, ddr4 and ddr5 are not using ""the same chips"""
226,Conflicted on choosing a major: Computer Science or Intelligent Systems Engineering,"Personally I would do the CS degree and take the interesting classes from ISE as electives.  And probably specialize in theory of computation rather than AI - though, again, take the interesting AI classes as electives.  You'll want to understand gradient descent and the backprop algorithm, but honestly this is more a matter of having two or three semesters of calculus than anything else.  You'll find that artificial neural networks are not similar at all to a modern understanding of the brain, so if you're looking to develop a new paradigm of brain simulation that enables better or different AI, the main tool you'll need on the CS side is a strong math/theory background.  I can't help you on the biology side because I don't know anything about it."
227,"Is it ever necessary to use ""extern"" for C functions?","If you're using a C++ compiler to [compile code with C linkage](https://stackoverflow.com/questions/1041866/what-is-the-effect-of-extern-c-in-c), you'll use 'extern ""C""'."
228,Good graphic FlowChart drawing tool ?,"Thank you all for your kind replies, I will look into these !!"
229,Why do software updates need to reboot the computer ever?,"So the code your computer is using to run the operating system actively is imported to ram from storage when you boot up by the bios. This means the actual operating system that's running is stored in ram while the actual base instructions are stored on disc and only used when you boot up. This is actually why some of your ram will show as unusable or ""system reserved.""

Updating the operating system only changes the os code stored on your storage disc, so if the update makes a change needed for the active operating system, like many security related updates do, then the computer needs to first change the stored operating system, then shut down so it can load the new instructions into ram along with the rest of the operating system all at the same time."
230,Why does machine language cause a processor to work - how does the processor even listen and start sending electrical signals around?,"> Am I totally screwed unless I basically get a university grade education in this field?

No, but you will need a little patience and determination.

To understand modern, digital electronics, you need to understand several ""layers"" of technology, it's not just a single technology. Computers are more ""dumb"" inside than you think.

Start with the [Crash Course on Computer Science](https://www.youtube.com/watch?v=tpIctyqH29Q&list=PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo). It's a couple hours' worth of material but well worth your time. I particularly recommend the first 30 in the series. You do not need to understand everything it introduces you to in order to generally understand ""how a computer works"".

> Why does machine language cause a processor to work - how does the processor even listen and start sending electrical signals around?

Machine language written by software compilers (for example, as part of the operating system) is stored in a type of memory called RAM, which is *volatile*. Volatile means, when the power is removed, the memory is gone. In order for those bits to be loaded into RAM, there must be a program that runs ""before OS boot"". Where is that program stored? There is another class of memory called *non-volatile* and this includes ROM (read-only memory), Flash and others.

ROM is particularly important as it is usually the memory that will be first consulted by any processing system in your device as soon as power is applied. So, when the chip ""wakes up"", the first thing it does (mechanically), is start reading ROM and executing whatever instructions it finds there. Since these instructions are hard-coded, they never change. But whoever wrote those instructions also understood the circuits in the system board, and used that knowledge to write them correctly, so that the chip will be able to, for example, load the OS bootstrap program from disk into RAM, and begin executing it."
231,Web vs Internet analogy?,"I have been lately thinking of it like Amazon - the physical part. In this case, each warehouse would be a different web site.

You send out a request for a package. Amazon (your web browser) takes the request, does some stuff for you in the background (looks up the actual address where your package is, does some initial interactions with the warehouse to make sure your package is there, etc) and then the package is sent over the network of roads to your door.

The web isn't just the buildings - it's a certain types of buildings. FTP would have other buildings. Email would be others.

All use the network of roads to communicate."
232,Can your smartphone or laptop get malware from just walking around in public?,It's unlikely but [not impossible](https://www.cnet.com/news/privacy/bluetooth-devices-vulnerable-to-hack-blueborne-armis-labs/).
233,"Is parallel programming synonymous to multithreading, or is multithreading a subset of parallel programming? (I'm seeking to get a handle on what 'multithreading' is, exactly)","Here's a metaphor that might help.

Thread: Office-worker

Multi-threading: Many office-workers

Parallelism: Work being done by many office-workers simultaneously (not necessarily cooperatively)

Thread Concurrency: An office-worker working on multiple tasks by time-slicing

Concurrency: One or more office-workers working cooperatively on a set of multiple tasks (by time-slicing, message-passing or some other architecture)

Obviously, there is some overlap in these terms, which is why I think there is a lot of confusion about them."
234,Have any computers used vacuum tube diodes?,"er, there wasn't semiconductor anything early on so yes."
235,Is the industry really that bad?,"Job market is still strong.

New grad CAN be tough.  Still good to have an internship, Co-op even better.  When the job market was nuts grads were skipping coops to graduate quick.  Now it's slowing down but still strong.

Up to you if you want to go the quick route or get a co-op.  A lot of companies use co-ops as a way to evaluate potential new hires.  Get a decent co-op job and you'll have a guaranteed job out of college.

Edit: internship = summer 3 month job.  Coop = 8 months summer + semester off (delayed graduation).

Coop on your resume absolutely sets you apart to companies because that's 8 months they don't have to train you on the basics of functioning at a company."
236,Can you not use both readline() and readlines() in the same open file session?,"Your operating system uses a 'cursor' to track its position in a file. Any time you read or write to a file, the cursor moves - that's why calling `readline` repeatedly keeps giving you ""the next line."" Once you call `readlines` the contents of the file are all read into a list - so if you try to call `readline` after that, the cursor is already at the end of the file, and there are no more lines to read. You'd have to move the cursor back using `seek` for any `read` functions to return more data.

But I think the bigger question is _why_ you're using both methods to read the same file. Once you call `readlines` all the lines from the file are in a list, so why not consult that list instead of reading from the file again?"
237,What happens to the computing industry after the absolute ceiling of Moore's law has been reached?,Maybe we'll finally start optimising our code
238,How much computer architecture and hardware does an academic Computer Scientist know?,"I think the short answer is: the more the better.

Having knowledge of hardware has been helpful for me to understand why loading data isn't working as fast as I'd like it to. It's important for me to understand the data pipeline between disk / CPU / GPU."
239,IT or computer engineering,Thank you everyone for your advice.
240,Help help :^,"[Fully homomorphic encryption.](https://en.wikipedia.org/wiki/Homomorphic_encryption#Fully_homomorphic_encryption)  ""Able to perform arbitrary computations on encrypted data"" is basically the definition of FHE.  The ""how"" involves a ton of advanced math that will depend entirely on the specific scheme you are working with.

If you are seriously interested then grab one of the popular libraries implementing FHE, look up the papers the algorithms are based on, and start reading."
241,What's the use of pointers ?,"If you want to pass a data structure to a function without making a copy of it, you need to pass some way to access the data structure, and passing a pointer is a way to accomplish this. Languages like Java and Python use references instead of pointers to refer to objects, but the idea for this use case is the same there."
242,How to create a system to extract sports data,"1. Find a site or service that has that information
2. See if the service in question provides an API
3. If not, scrape the data, being mindful of any terms of service you may be breaching
4. Otherwise, contact the company and ask them about integration options"
243,How is a file permanently deleted?,"Usually the entry is just removed from the list of files in the filesystem and the space is marked as free. If you *securely* delete a file, then its storage location is usually overwritten with new random data, sometimes several times, before the entry is removed.

> Where does the data go?

When you turn a switch off, where does the ""on"" go?"
244,The Ultimate VPN Roundup: Reddit Users Select Their Top 5 for 2023,um r/lostredditors
245,Smallest Physical Units,"sector, word, word

edit: i'm pretty sure that sectors are a software concept though. for disks there are really tracks. for SSD's there are hardware dependent units that can written and erased. for ROM, the smallest unit for writing is the whole chip. so suffice it to say, the question is underspecified"
246,"Chord progression, can i use my spotify id and extraordinary chord just by giving song id or song name with artist","Are you asking if it's possible to identify a chord from music that is playing through spotify?

The answer is that it's not easy.  You may be able to do some signal processing and spot some of the notes in it, but musically the same chord can be played in various voicings."
247,Pushdown Automata,[deleted]
248,Are the data link and IP layers not included in this process?,"this is completely messed up and wrong.

2: is out of date. QUIC uses UPD so it's not just TCP

3: is out of order. it can't happen until the domain is resolved and the IP address is known

4: DNS doesn't store a database of URL's, it stores a database of domain resource records

6: the three way handshake should be the step before this

7: it's not necessarily HTML. http servers use MIME to tell the client what the data actually represents

8: it may not be displayed. things like javascript and CSS don't get displayed. and how it handles different MIME types is out of scope as it's completely browser dependent. 

is this actual instruction material? this is terrible."
249,Is the last statement wrong?,"If `loves(X, mia)` and `loves(franklin, X)` would indeed unify, what would `X` be bound to?"
250,Looking for programmers to help on projects,"What programming language are you guys coding in? Python right? I’m programming primarily on Java with a little bit of experience on C++, but Java is the one I’m most comfortable with right now, I’m not sure if that can possibly help you guys in any way…"
251,Difference between APIs and system calls with regards to operating system?,"A system call is a type of API. Where they differ is in where they run - is it a library provided by the operating system that runs within your own program, is it operating system functionality that runs in another process (a system service or daemon) that you speak to over IPC, or is it code within the operating system's kernel that you can trigger but does not run within your app? System calls are for the last category, and trigger code in kernel-space rather than user-space."
252,Does virtual memory refer only to the memory in SSD being used as RAM or RAM + memory in SSD being used as RAM?,"it doesn't work that way. virtual memory doesn't require disk backing it just makes it an option for swapping -- lots of things don't swap. virtual memory allows a mapping between the physical address space to a virtual address space for a process which is continuous as seen by the process and suitable for loading programs and stacks (ie, the entry point will always work since it the right place in the virtual mapping). the physical blocks of memory need not be contiguous to contain the whole process address space and indeed memory is allocated on an as needed basis so it can't be.

edit: i should clarify that ""load"" doesn't really mean load the whole program generally since it is paged in on demand."
253,"Why aren't radix sort, counting Sort, bucket sort, used for integers instead of the comparison sorts?",Because calling the general `List.sort` that takes a polymorphic comparsion function is just so much easier.
254,"In SR and JK logic circuits is Q the bit the circuit stores, whilst Q’ is there for it to be able to perform positive feedback?",Yes Q' has to exist anyways because of the feedback. We just declare it as an output as well cause its free and might as well spare ourselves an inverter if needed.
255,Can I apply de Morgan’s law on (A +B.C)’ ?( so different operators in an expression under the NOT),[deleted]
256,Boolean Logic General Purpose Constructor,"There is a lot of work under the category of “Electronic Design Automation” which is basically software to help in chip design. 

What you are describing sounds like logic simulation."
257,"Hello, I would like to ask you why do websites on my browser look like this? the display is screwed! How can I fix this?","Press Ctrl+Shift+I to invoke the developer tools. On top left of the developer tools window, click on the small tiny icon that looks like a mobile phone and a tablet."
258,Which research topics should I talk about for my engineering admission interview?,"so i would try to mention that you are already building websites. But do so in a different question unrelated to research.  

Also i would not name the words ""web/cloud development"" when asked for research interest.
The other topics you mentioned are fine though.  

Why? E. g.  
For web development i would rather tell about a certain problem related to it, which is an open research topic: eg ""User Experience"" and find one thing a professor/chair at this university is currently researching in that area. Then try to understand it a bit and summarize it in the interview.

Eg "". i think the topic user experience is interesting, because easy interfaces enable everyone to be more efficient with ever more complex modern technology. I saw Prof. XYZ is trying to use special audio ques to assist car drivers... and id be cool to participate there""

If you have a good idea you can suggest some improvements on the research! But dont pick something stupid here, if you do :D  

Do the same for whatever you are interested in. Find what Research is being done, understand it and tell them you want to participate there.

It shows you have interest, are able to understand them and pursue them. You might even help them in their own research. (Assuming the interviewee is also a Professor)

Also be very honest and dont try to bullshit them :D they would find out immediately if you tell them things which are not true.

If you don't know something that is fine, it is expected, since you want to learn."
259,Where should i start my computer science Joruney?,"on the web front it's pretty easy: load up Python and Django or Ruby on Rails and follow their Hello World tutorials. site design is far more complicated than these frameworks make it out to be, but they do give a pretty easy starting point. Java probably has an equivalent to them too (Spring?) 

on cyber security, getting to understand the basics of crypto like symmetric and asymmetric encryption, message integrity, authentication and the basics of on-wire attacks and how to avoid them (think Alice, Bob, Eve and Mallory). understanding the difference between authentication (who is this?) authorization (are they allowed to do this) is important too. 

as to what hackers do what they want to do, the Snowden dump from the NSA was pretty enlightening in that they are capable of recovering like 50% of communications. this was not through brute forcing crypto, but much more through social engineering. learning about social engineering attacks like phishing is really the bane of the internet."
260,Why does SIMD only store one copy of the program whilst MIMD stores multiple copies?,"First of all, the term ""MIMD"" is rarely used (in my experience) because it just describes the default mode of operation of multiple processors. People usually just call that ""parallel processing"".

And it is not true, in general, that MIMD stores ""multiple copies"" of a program. For example, in a typical multicore CPU, all of the cores have access to the same shared memory in which a single copy of the program is stored.

There may be multiple copies of *parts* of the program, because parts of it are cached during execution. And the smallest and fastest levels of the cache hierarchy are typically not shared between cores."
261,if you guys dont mind can you anwer our form for research purposes only,Im tired boss
262,Is Moore's Law dead or not ? And what's next ?,"Gordon Moore originally said that transistor density would double every year, and then revised it to every two years.  This has held true from about 1970 to today.  However, it has never been clear that it would continue to hold true.  When we say today that Moore's Law will fail unless new technologies like 3D chip technology succeed, this isn't really different from any other era - there have _always_ been limits blocking the path of Moore's Law, that have _always_ required innovative new technologies to advance beyond.

However, there has been one major sea change, that happened roughly around 2005.  From 1970 to 2005, transistor density increases were generally coupled with clock speed increases, enabled by shorter and/or narrower interconnect lines.  So before 2005 it was common to misquote Moore as having said that clock speeds would double every two years.  Post-2005, clock speeds have mostly stayed the same, and the increased transistor counts have been used to pack more ""stuff"" - multiple CPU cores, more cache RAM, on-chip GPUs and peripheral interconnects, etc - onto single chips.

So in terms of what's next, either Moore's Law will fail and the rate of generational improvement in microprocessors will slow down, or else we can expect more and more on-chip features and functions.  How about a single chip with twenty 200BOps/sec CPU cores, 128GB RAM, two 4090-class GPU cores and 64 PCIe lanes, allowing phones with multiples of the performance of current desktop computers.

So the question is, what will we do with all this power?  Most people aren't running into CPU or GPU limitations on their phones, and would rather for phones to get cheaper rather than more powerful.  This isn't the first time we've said this, and in the past we've always found new applications that give people reasons to want all this power.  If you can have eight or twelve 4090s in your pocket, do they just go 99.9% unused all day?  Or does this enable some new world where, I don't know, deep learning networks are constantly training themselves on your daily movements and activities and conversations, allowing Star Trek style digital assistants?  (""Hey Siri, did Bob sound insincere to you just then?"")

So, yes, it is a messy and confusing area, because it's not just some physical law to be followed.  It's really a bit self-fulfilling - each chip maker thinks their competitors are going to be roughly where Moore's Law predicts, so they invest in R&D to hit that target.  Hope this explanation helped rather than just made it more confusing."
263,Is low level it’s own programming paradigm? Isn’t it a subset of Imperative programming?,"""Programming paradigms"" aren't a strictly defined term, they're just ""broad ways of problem-solving and organizing logic."" So, yes, assembly languages are imperative, and they're also a pretty different way of thinking from higher-level imperative languages like Perl."
264,"When doing recursion, how do you usually come up with the base case?","When doing iteration, how do you usually come up with the loop condition? The two are very closely related. If your loop condition is ""while there are still elements in the list"" then your recursion base-case is ""when there are no further elements in the list, return."" If your loop condition is ""while the node in the tree has child nodes, add them to the list for processing"" then the recursion base case will probably be ""when there are no child nodes, return."""
265,Does this recursive algorithm have a base case?,"The base case of a recursive function is the case that doesn't lead to a recursive call. The function you posted contains exactly one recursive call, so the question is: Is that recursive call conditional on something? If so, the case where that condition is false is your base case."
266,"Hypothetically, would one ever need GPU's or multi-core processors if one magically had unlimited processing speed and memory?","No, those are just for making things go faster."
267,"Hypothetically, how powerful of an AI could someone create given a computer with 10^100 FLOPS and 10^100 bytes of memory and storage?","Firstly I would say the question is probably too vague. There are many different AI methods that are each suited to different problems, with no unified concept of 'power'. There are no General AI algorithms, so you're trying to come up with an answer for many different types of specialized AI. Perhaps the best you can say is how well it is measured to perform at its programmed task, and how fast it learns and operates. 

The degree to which the computer you describe will gain power depends heavily on the extent to which the algorithm you're using can process in parallel, and the amount of data they'd actually available. 

Let's consider the current trendy AI, ChatGPT. Until the Transformer network came along, the parallel processing power of the computer was not the limitation. NLP methods like RNNs were heavily sequential in nature. But with Transformers you can process much more in parallel, so your hypothetical machine will learn much much faster. Before the invention of the Transformer algorithm, you wouldn't gain much from your super powerful machine.

However, whilst its learning speed will be greater, it may not be any better at its task. The big issue that ChatGPT was attempting to solve was the lack of helpfulness in earlier models. You can have reams of text data, but handling enough text isn't the main limitation now. The main limitation is the scale of human feedback - the need to improve prompt reply quality with labelled samples. That's not a computer overhead, it's a human one. 

ChatGPT uses reinforcement learning to scale up its learning from samples, but the primary limitation on scale is not the computer running it but the amount of human feedback that can be provided. You can have all the storage in the world but if you need labelled data, someone's gotta label it and a better computer won't help.

So that brings up the question of output quality. The basic LLM will learn faster, but will still be bottlenecked by the generation of human input. 
Then the improvements to the output quality are not limited by the computer  hardware, but by the algorithms and ability to label data for training. To get a better ChatGPT you don't need a more powerful computer, you need a better NLP algorithm design. 

So to answer the question it depends. What problem are you looking at and where do the main bottlenecks in speed and accuracy come from? The ability to obtain sufficient data and the sophistication of the models may be more of a limitation than the hardware."
268,OPEN SOURCE!!!!,What research into open source have you already done? What do you know about it? And what about it is unclear?
269,is this preorder traversal ?,"
    func walk(node *html.Node) {
        fmt.Println(node.Type, strings.TrimSpace(node.Data))

        for c := node.FirstChild; c != nil; c = c.NextSibling {
            walk(c)
        }

    }

Does that look like it processes the node before traversing branches, in-between traversing branches, or after?"
270,Looking for a simple layman's explanation of the different applications of symmetric vs asymmetric encryption,"Asymmetric key:

you have two keys, one private and one public. You keep the private secret and put the public one on display for people to use.

Signing: you use the private key to create a digital signature of a document you want to circulate. People can use the public key to verify that the document was authored and signed by the owner of the matching private key. 

Receiving encrypted documents: anyone can use your public key to encrypt something that you will then be able to decrypt using your private key.

Sending encrypted documents: same as above, but you use someone else's public key.

Symmetric key:

Fast encryption/decryption: you have one key that can be used to encrypt and decrypt a document/ data stream. It's fast and efficient, but you have to make sure you are delivering the key and storing it securely where it's needed. 

In gneral public key infrastructure (asymmetric) works better at scale. Symmetric works under specific circumstances and requirements, but in general it's not good to communicate with other people as is. TLS includes both asymmetric and symmetric, the public/private part is used to exchange a secret over an insecure channel, and then once the two parties have a shared symmetric key that is used to encrypt/decrypt the data stream.

This is a simple, layman version. Hope it helps"
271,"What is the difference between Clock - cycle , Clock - Pulse and Clock - edge ?","In most digital electronics, a clock is a periodic signal (generally meaning, a voltage on a wire) called a [square wave](https://en.wikipedia.org/wiki/Square_wave). A square wave oscillates between two ""levels"" -- in this case, two voltages, something like 0.1 volts and 1.1 volts (for example). The square wave is a graph plot of the voltage on the wire at the output of the clock, over time. So, you can think of time as ""flowing left to right"" in the square wave graph (see diagram at link above).

The clock-cycle or ""cycle time"" is the amount of time from the beginning of one clock-cycle to the next. Often, we define the ""rising clock-edge"" to be the beginning of the clock-cycle. So, the time that passes from one rising-edge to the next, is the clock-cycle. Let's suppose that 1 microsecond passes between one rising edge to the next rising edge. Since frequency is 1/t (t typically denotes cycle-time), the frequency of the square-wave would then be 1 million cycles-per-second or 1 *megahertz*.

Another way of thinking of a square-wave is as a [pulse-train](https://en.wikipedia.org/wiki/Pulse_wave). In digital electronics, we call the flat part of a square wave a ""level"" and the vertical part an ""edge"". In a basic square-wave, there are two levels, and there are two kinds of edge (rising and falling). So, the clock-pulse would be the high-level of the clock. There are many more details involved, but I hope this gives you the basic idea."
272,i need help deleting things off of my windows 10 cool master pc,"You really need to take this to a tech support subreddit, not a computer science one.

> For general troubleshooting or tech support see /r/techsupport"
273,"In a lot of procedurally generated games, you’re able to specify what seed is used for the randomizer in order to guarantee you get the same random map, items, etc on any run with that seed. But doesn’t that also require every call to the randomizer happen in the exact same order every time?","> Do they have many different randomizers in use at once? Is the “seed” we input actually mixed with some string for a specific use case (e.g. “[seed]_[chunk coords]”) before use to better ensure consistency?

You're exactly right. In order to ensure map generation is consistent regardless of exploration order, developers need to either make all random number draws up front (works fine for generating a Civilization map, not so much for procedural generation), or make sure the random number draws are independent from user actions. One easy solution to ensuring consistency is to seed a new RNG every time we need to generate another map area, where the seed is a combination of a global random value and the chunk coordinates.

Note that this may only be necessary in open-world style procedural generation - if you're procedurally generating dungeon levels, then the order in which players explore rooms might not require any random number draws, and the order in which they explore dungeon levels may be fixed, so you might get away with a single global RNG. If you want the maps to be consistent while also supporting random user effects, maintaining two RNGs for map generation and ""other stuff"" is a great idea."
274,Is 2’s complement only the negative version of the binary or are they both in 2’s complement form and the second one is negative?,"It feels like you're asking if a number can observed to be in 2's complement format when no other context is provided. The answer to that is no. If you're given a number and told it's in 2's complement format, then you can determine positive/negative from the Most Significant Bit. If you're given a number with no context, you can't determine positive/negative from the MSB."
275,Do I have to create a new sequential file every time I make an addition to it?(ordered according to primary keys),"er, what? not sure what a sequential file is, but databases, for example, deal with the file structure of their database files using the same file generally. they do the same sorts of memory management that other components do (eg, heap, OS file system..)."
276,I have a scenario where I need valid conditions existing in my database on the fly,"What kind of indices are you using? Are you able to set these rules as constraints before inserting any data? Do you need to keep your data as json, or can you expand to columns to make better use of postgres?

In a worst-case scenario, if all your data is stored as json inside a table column, and the rules are applied individually and after the fact, then every rule will require iterating over _all_ your data, and for each row de-serializing the json before the rule can be evaluated. That's going to be abysmally slow.

If you write the rules as constraints then they'll be evaluated as data is inserted, rather than requiring `r*n` deserializations and evaluations after the fact. If you use proper database columns and indices, then you won't need _any_ deserializations, and table lookups will be ~ `O(log n)` to find relevant data instead of `O(n)`.

tl;dr ""rule engines"" aren't slow, this just sounds like an antipattern"
277,Do you get payed for uni placement years?,"yes, well you normally have to apply to the placements yourself so that’s something you control. I haven’t seen any unpaid ones in the UK at least."
278,"If a file is a collection of records, where are the records in a simple text file(I.e a homework assignment that is saved on the computer) ?","A file is not generally regarded as a collection of records.

If it *is* considered a collection of records for some reason (e.g. it's a database file, or JSON, or some other format), then the person who tells you that it's a collection of records is also responsible for telling you how the records are delineated."
279,What makes Telegram the go-to for shady messaging?,"Telegram's the most popular messaging app in many countries, so it's already got momentum on its side. Add to that limited moderation, everything's in DMs or group chats, so there's no public visibility like posting on Reddit/Twitter/Facebook, etc. Accounts don't require sharing your phone number with others like on Signal. There's optional end-to-end encrypted messages (but not enabled-by-default). The protocol is open-source, so it's relatively easy to make spambots. Plenty of appealing aspects for that crowd."
280,How to develop Windows Application ?,"As the people where you work.  You are doing an internship, you are there to learn."
281,Tool or platform with 3D model for tattoo visualization,"dude same, how is there not already a thing like this?"
282,Need computer career advice,"u need to learn basics anyway if you want to do programming. how a computer works, how a program is executed, branching, loops, etc. after that, you'll be able to understand some algorithms and data structures. and ofc how to run your program 

AIs are doing great but noone knows what will be automated in say 5 years. AI that generates 99% of code correctly still needs human observation since the last 1% can prevent the whole thing from even starting up."
283,Is anyone else fresh out of college and ALREADY disenchanted?,"yeah, test people are their own breed. there is that type that likes figuring out how to break things and that is  their reward. maybe that's not you. maybe you should try dev or work your way up to manager. managers obviously need to deal with people and good dev managers know both how to be part of the engineering as well as wily enough to protect their group from useless meetings, etc. good dev managers are also good at gaming out process and timelines and that requires input from their group."
284,How can an algorithm with 0(n^4)) time complexity run faster than 0(n)?,"If you want to prove that fact, just plug and chug n=2, as the answer stated.

If you want to see why it does not contradict asymptotic complexity.... Asymptotic complexity (big-O) only tells you about which one is faster *eventually*, for large enough n.

Sometimes algorithm which is slow asymptotically is preferred over fast one, just because in practice the n is too small for the asymptotically fast algorithm to be useful."
285,"I need some guidance to tackle the following topics ( computer systems, computer architecture, computer organization, and operating systems ) & Books to starts with","https://www.google.com/url?sa=t&source=web&rct=j&url=https://pdos.csail.mit.edu/6.S081/2020/xv6/book-riscv-rev1.pdf&ved=2ahUKEwic9oqqk_X-AhVcIjQIHc4LCMEQFnoECBAQAQ&usg=AOvVaw0R8ObxBIILVcUq1hkvXlll

Amazing read for ooerating systems. You can find this OS on git hub, set up some emulators and get to pkaying. In one class I took we gutted it piece by piece and re wrote most of it again."
286,Do you normally use an interpreter for programming/debugging and then transfer this code to a compiler to produce an exe file ?,"Not really, no.

Generally speaking, programming languages are *designed* to either be efficiently compiled, or to be interpreted. It's rare (but not impossible) for the same language to have both a high-quality compiler and a high-quality interpreter.

(EDIT: I should add that Haskell, mentioned by /u/lgastako in another comment, is one of those rare exceptions.)

(Some languages use sophisticated techniques where *behind the scenes*, any given chunk of code might be either interpreted or ""just-in-time"" compiled. But this is not normally something that you need to worry about as a developer, and it doesn't affect the way you run your code.)

And generally speaking, even if you're using a language that has multiple implementations, you don't want to use one implementation for development and then switch to a completely different one for the final version of your program. Any slight differences between the two versions might cause unexpected effects that you didn't test for."
287,Resources To Learn About Online Algorithms,"I actually think there might not be a book on this. You can find some lecture notes by searching ""online algorithms"", such as https://www.cs.cmu.edu/~avrim/451f13/lectures/lect1107.pdf

You can also look for specific problems such as online matching, online bin packing, k-server. Of course, the secretary problem counts.

A very specific book I know of is ""The Design of Competitive Online Algorithms via a Primal-Dual Approach"" by Buchbinder and Naor.

A popular category is online ""sketching"" and ""streaming"" algorithms, which is more about data structures. For example, Bloom filters, count-min sketch, hyperloglog.

Wikipedia references a 1998 book by Borodin and El-Yaniv. https://en.wikipedia.org/wiki/Online_algorithm"
288,Is a masters in CS worth it,"Personally, I don't think it's a bad idea, but you could probably just as easily spend time self-studying and doing projects to build your resume, and it would save money if that's a factor. The biggest upside to going back to school for CS would be internships as you can't get them without being a student. 

Getting a master's in CS is perfectly valid if you're wanting to switch careers, it's really only not worth it if you already have a CS degree or experience. 

I do have one friend who majored in bio and minored in CS who got a dev role right out of college, but they had connections. Do you have any connections that would give you a foot in the door?"
289,SQL Injection Prevention C++,"The question doesn't really make sense. You should not be trying to ""detect"" SQL injection, using a query or otherwise. You should *construct* and execute your queries correctly, so that SQL injection is impossible.

This means using [prepared statements](https://stackoverflow.com/questions/8263371/how-can-prepared-statements-protect-from-sql-injection-attacks) or parameterized queries, instead of building query strings by concatenating user-provided strings. The details of how to do this will depend on what database and client library you're using"
290,What are the names of these hackers?,"Top row, left to right:

 - Richard Stallman - https://en.wikipedia.org/wiki/Richard_Stallman
 - Nicholas Allegra (Comex) - https://en.wikipedia.org/wiki/IOS_jailbreaking#Spirit_and_JailbreakMe
 - Linus Torvalds - https://en.wikipedia.org/wiki/Linus_Torvalds

Bottom Row, left to right:

 - Jake Davis (Topiary) - https://en.wikipedia.org/wiki/Topiary_(hacktivist)
 - Jeremy Hammond - https://en.wikipedia.org/wiki/Jeremy_Hammond
 - Kevin Poulsen (Dark Dante) - https://en.wikipedia.org/wiki/Kevin_Poulsen"
291,What should I do to make it not stand out and normally write between the lines?,Insert key on your keyboard
292,Best way to search for a portion of an image on the internet?,"Are you sure you'd want to only search for exact matches for a group of pixels? That could be fooled if someone were to:
- stretch or shrink the image
- change the alpha values
- recolor a single pixel
- transcode, like png -> jpeg
- apply a filter

I'm sure there's a bunch more things I'm not aware of too"
293,Two's complement arithmetic - Abelian group,"The point is that `x+y-x==y` and `x+y-y==x` are preserved under twos complement arithmetic, even when an overflow does occur.  So this code does nothing to tell you if there was an overflow or not."
294,I’m having some cpu performance issues and I’m wondering whether if it’s time to upgrade? Using a 2017 MacBook Pro 13inch.,"Files disappearing on you isn't just ""your computer isn't powerful enough."" That sounds like something more serious is wrong, and I'd ask on /r/techsupport 

> I'll usually have chrome, slack, and vscode running

All three of these are web browsers (slack and vscode are built on electron) that are notoriously RAM-hungry. If you don't want to buy new hardware, switching to using the slack web-app or using a third party client like [Ripcord](https://cancel.fm/ripcord/) will remove one of those browsers, and using an IDE that isn't a web browser would take out another. You may also find that another browser like Firefox uses less memory than Chrome.

> Just curious if it’s something I can fix or do I need to just bite the bullet and get a newer more powerful computer?

You can certainly still do software development on a decent 2017 laptop if you use memory-light software and maybe get an external hard drive to free up some storage space. I do my work on a 2011 MacBook Pro, and it's still chugging along well enough (with Linux now that Apple doesn't provide updates for the hardware). But if you want to use a big stack of browser-apps like Chrome, Slack, Discord, VSCode, MS Teams, Spotify, etc, then software development has moved in an incredibly hardware-hungry direction that expects you to replace your computer every couple of years."
295,Is there anything in Windows that makes it better for Gaming than Linux other than its market share?,"1.) The Linux kernel vs the nt kernel have very little to do with what makes an os good for gaming.  The biggest factor in the os options is what graphic apis are available.  On the Linux side you have opengl or vulkan, in the windows side you have opengl, vulkan, and directx.  Traditionally games were written for directx however quit a few have switched to vulkan as it tends to have better performance than directx all other things being equal.  That all being said valve has effectively taken the directx advantage away from windows.  Directx still doesn't run on Linux, and since it's proprietary code no one can modify it to do so other than Microsoft, so valve funded a project called dxvk which translates directx to vulkan and it works so well that on some hardware configurations certain games translated to vulkan perform better than they do natively in directx.  It also has the advantage of outside of game shader caching since there is a hit to shader compilation performance, this is an advantage because modern games try to compile their shaders at runtime instead of pre-compiling them.  This leads to games run through dxvk to have less shader stutter.  For example elden Ring performed significantly more smooth with less stuttering on Linux day one than it did on windows.


2.) Linux can be highly optimized for gaming, but honestly most vanilla setups games just as well as windows it's not really a matter of performance anymore, as windows and Linux will be pretty close to performance.  Some distros will need newer GPU drivers but that's about it.


3.) This already exists.  It's called steamos3 and it runs in the steamdeck.  That being said no the distro alone and any other distro for that matter would make very little difference here.  The real reason steamos3 has helped Linux gaming a ton is because valve put in the work with dxvk and proton to make it so game devs don't have to port their games to Linux, odds are it'll just run.  The other reason steamos3 has helped Linux gaming is it's become a major platform in the steamdeck, companies want to hop in on this PC gaming handheld market and windiws in gaming handhelds is a much worse experience than steamosis.  Hell valve even contracted with battle eye and easy anticheat to get wine/proton support built into the anticheats.  These days it's not really a Linux can't play x game issue, it's a Linux can't run x game's anticheat issue.  EAC and battleeye support is great, however devs do have to enable this support by including a library file and checking a box in their anticheat management console... And some devs won't even do that (looking at you epic games for Fortnite).  The other thing you'll run into is games that roll their own anticheat that don't care about Linux support like the newest cod and battlefield games, as well as vanguard.  



All this being said I primarily game on Linux, but do have a secondary gaming PC set up with windows for the literally one game I like to play who's anticheat won't let me on linux


Tldr:  the only reason windows is better than Linux for gaming is because of market share... If you want reasons you can read my full post... Mainly if more anticheat supported Linux (and they currently don't because of market share) gaming in Linux would be even better, and especially when it comes to handhelds like the steamdeck would be way better than windows."
296,How whatsapp know if I'm from mobile or desktop?,"Same way reddit does. Device fingerprinting etc. 

There's a website you can look at ""am I unique"" think it's called. And it'll show you what your fingerprint looks like. This includes OS, your screen resolution, etc."
297,Does a CPU know about a stack and a heap? Or are they higher-order abstractions?,"A typical CPU has a stack register and machine language instructions for push, pop, call and return.  So the primitives for stack allocation are CPU level concepts.  Heap allocation typically doesn't involve any special CPU hardware, although depending on how it's implemented, it might use some MMU features."
298,What soft skills are valued when applying to computer science jobs?,"1. initiative -- taking the initiative saves me time so i don't have to do it for you
2. thinking several steps ahead to be prepared for what you figure is inevitable is useful. you don't have to completely flesh it out, just know how it ultimately will fit in with the framework you set for it -- Google's 20% time is really good on this account.
3. asking questions -- if you don't understand something like with requirements or functionality, etc more likely than not nobody else does either
4. being too deferential to more senior engineers. we fuck up too
5. don't let marketing and sales droids do the software architecture. they want to. don't let them. tell them to tell you what they want, not how to design the software. this is especially critical when they are customer facing and can box you in to a design that is bad
6. taking time to make tools. back before the internet i was tasked to design the software for a [laser printer controller](https://rip-van-webble.blogspot.com/2020/12/how-to-build-laser-printer-from-nothing.html) that we had contracted with another company. it was a collaborative affair (they did the printer languages, i did pretty much everything else), and they had never dealt with hardware. i purposefully took a good deal of time to write a symbolic debugger for it. i am convinced that the project would have been either extremely late or failed altogether had i not done that. not ever tool is going to score a home run, but being in the habit of making them is a good one. your manager will probably freak out but don't let them cow you.
7. Google-fu is your friend. get good at. this is especially true as everybody expects documentation especially for weird errors to be complete crap."
299,Timing changes when running python scripts in parallel vs. serial,"Sounds like a data race (process A has to wait for process B to release a page of memory before it can continue, for example), do the processes use any shared memory? Can't really say much more without the code, debugging parallel stuff is extremely challenging."
300,Can I easily make a 'cluster'?,"A ""cluster"" is not a formal or precisely-defined term. It just means a collection of computers that are networked and all being collectively used for some purpose. If you have a database server on one computer, and a webapp on another computer that talks to it, then you're well within your rights to call that a cluster.

*Usually*, the term ""cluster"" is applied in situations where the management of individual computers is somewhat automated. For instance, you might have a system that monitors all the computers, decides which tasks should be run where, acts as an intermediary for communication between nodes, and alerts you if something goes wrong somewhere.

[Kubernetes](https://kubernetes.io/) is by far the most popular modern ""orchestration system"" for managing large, general-purpose clusters. It's kind of complex and probably overkill for just two computers, but you could certainly set it up as a learning experience. 

(Note that you will have to deal with some extra complexity if your cluster nodes have different CPU architectures. Kubernetes is designed around running applications in *containers*, and containers contain binary programs compiled for a particular architecture. If you want a container to be runnable on either one of your computers, you'll need to build container images for both architectures.)

In any case, the most important question is: why do you *want* a cluster, and what do you plan to use it for?"
301,Need help understanding use case diagram,">What I don't understand is that in this particular example, how come there isn't a connection for the ""cook food"" use case to the waiter  Since he has to receive the cooked food in order to serve it?

Because serving the food and cooking the food are different activities. A use case diagram only tells you who does what in terms of discrete tasks, it doesn't have anything to do with ordering of tasks relative to one another.

>Finally how come the ""eat food"" use case isn't connected to the waiter? 

Because the waiter does not eat the food."
302,Have a hard time find machine learning job as new grad,"I think the first question is not really a technical one but a careers one - what does your CV look like? Good CV design is an important part of job searching - efficient design and easily accessible relevant information. These days some companies also use AI resume scanners, so it may help to look into how your CV will read to one of those."
303,Is a CS Degree Still Worth It with the Rise of AI? Which Areas of CS Might Reduce or Increase in Demand?,"The only kind of IT jobs current automation will be able to replace will be the ones requiring low amounts of knowledge/skill. Jobs that require degrees.are safe from this.

If anything, once AI is able to replace highly skilled computer science people, then it's safe to say society would already be in a serious crisis, as that would imply tons of other jobs would be automated as well.

In short, no, I do not think you need to worry about this. And even if you think it's correct to worry, there's not exactly anywhere else to go."
304,"Is there a reason not to use optocouplers (a.k.a. solid-state-relay, optoisolator, and photocoupler) in logic circuits?","Optocouplers are generally much slower, bigger, more power-hungry, more expensive, and less long-lasting than ordinary transistor switches, so they are only used in situations where you *need* electrical isolation between different circuits. For instance, to provide feedback signals between the high-voltage and low-voltage sides of a switching power supply.

There would be no benefit to using optocouplers in an ordinary logic circuit where everything is already sharing the same set of power and ground connections."
305,Hey guys I had a question on my mind if I graduated with a computer science degree what business can I do in that field ? Like for example doctors can open clinics and hospitals and can computer science graduates do?,"A computer science degree does not give you any kind of ""license"" to do anything that you couldn't do otherwise, in the way that a medical degree is a requirement to be a doctor. It's just a credential that looks good if you're trying to get somebody to hire you.

Many software companies will require job applicants to have CS degrees, or at least strongly prefer them. Others don't care as much, as long as you can pass their interview process and/or have a track record of successful projects.

If you want to, for instance, develop a web site or software package and sell it directly to users, you don't need any kind of degree -- as long as you know what you're doing."
306,Do computer viruses work similarly to biological ones?,"Yes-ish. Computer viruses typically only target one operating system (most often Windows), and won't work on other hosts. There's your species analogy. It may also target specific software (for example, a malicious .pdf that triggers code to run when you open it in a vulnerable version of Adobe Acrobat), which I suppose is analogous to targeting specific features within an animal host. It's a clumsy analogy, but there are some very superficial similarities."
307,I landed my first Coop job as an application developer for an auto insurance company,"From Wikipedia: 

Gosu is a statically typed general-purpose programming language that runs on the Java Virtual Machine. Its influences include Java, C#, and ECMAScript.

You probably won't ever use this language ever again unless you go into app development for insurance companies... but that doesn't mean learning it and doing a coop job with it is completely useless. Over your career you're going to have to learn a lot of different technologies including different programming languages. There will always be a learning curve and growing pains when going through this but the more you do it the better you get. What you will soon discover is that the underlying principles of application development and problem solving are really independent from what language you're using. 

To be sure, truly understanding a language and how it really works under the hood allows you to properly optimize your code and create very mature and sophisticated applications, but you don't really have to start down that road until you've got a job and you know what type of technology you're going to be using for the next few years. Unless you've already decided what kind of tech you really want to use and want to pigeonhole yourself into jobs just for that. 

All this being said, if you feel like you can find a better coop that will expose you to more relevant technology that you are interested in, there's nothing wrong with that and it will probably be a more valuable experience for you. But if you can't, then make the best of your 4 months and see how it turns out, you might learn a lot!"
308,"What to do to Achieve the Knowledge and Expertise of Top Stanford/Berkeley/Harvard CS Students: What are their daily Routine, Book List, Habits, Problem-Solving Techniques, and Time Management Strategies?","The books that are used in the CS curricula for those schools is not a secret; you can go to the department web site, look up the course list, and find the books used for each course. They are common books used at many schools. They are not special.

I've known top students at Berkeley. Their study habits were not much different from those of other students. In some cases, their study habits were *worse* because these students were so smart, they didn't need to spend as much time on their assignments, so they could party harder."
309,Confused about a Big(O) worst case simple question true or false,"The time complexity of A3 *is* O(n^3), but the question wasn't about A3, it was about P. And the time complexity of a problem is determined by the time complexity of the most efficient algorithm that solves the problem."
310,So is Windows XP extremely easy to hack now?,"To my knowledge, if you have the firewall on and are not exposing any ports, there aren't any kernel RCEs or anything like that.

However, if someone is using Windows XP for web browsing, they are almost certainly using an unsupported browser with significant vulnerabilities.  So if you can control a web site the user is accessing, you can probably find a good attack vector.

And of course, of the Windows XP installation _doesn't_ have its firewall enabled and is running open services, many of those services do have RCEs in them."
311,Analysis for union-find data structure,"What have you tried so far? Where are you stuck? Conceptual questions are fine, but no one's going to do your homework for you."
312,Where to Start? Finance Edition,"There have been ""AI systems"" implemented in finance for decades. Literally any algorithm that predicts stock price (or other financial asset values) based on historical trends is a machine learning statistical model.

There's a lot of hype surrounding AI right now, because large language models like ChatGPT have made a large breakthrough in how human they sound. This does _not_ mean that LLMs are a breakthrough in cognition, or that they're likely to transform fields like finance any day now.

An LLM predicts ""the next word"" based on the context of your conversation so far, and its training data, which consists of an enormous body of human-written text. This makes it very good at generating text that sounds reasonable and person-written and contextually appropriate for what you've prompted. It does not mean that LLMs understand anything they're saying. Ask ChatGPT to solve math problems, ask it questions about finance that require reasoning that can't be quoted from a book it's read, and you'll see very quickly that its ""intelligence"" is a thin veneer.

Now, are finance firms likely to adopt LLMs for helping write emails and reports? Entirely possible, language models are good at writing language. But are they going to be put in charge of making financial decisions? You'd better hope not, all they're going to do is blindly paraphrase economists they've read before."
313,Help with catch up!,"There's no substitute for time in the saddle.  You just have to do the work.  It's normal to struggle a bit, and you're correct that getting help too soon (ie, never struggling) will short-circuit your learning.

Go do all the exercises in the textbook.  It will take a long time, but there's no help for this.  If I knew a shortcut I would tell it to you, but to my knowledge there isn't one."
314,Creating a searchable database on a server?,"Assuming your employer's IT and Cyber security departments sign off on it...

Entirely feasible. Perhaps the largest hurdle would be determining how the search function would work. Having a website that's essentially a front end for a website is trivial enough today. 

I would actually consider bringing this to your college's Computer Science department and perhaps pitch it as a potential student project, if possible. It seems to be to be of sufficiently limited scope for a semester or year long project."
315,exit with status code 0 in assembly,"Both will work. The former saves you two bytes and doesn't have any null bytes in it.

`xor rdi, rdi` assembles to `0x4831ff`

`mov rdi, 0` assembles to `0xbf00000000`

But outside of fairly contrived scenarios (binary exploitation and shellcode, writing assembly for tiny microcontrollers where literally every byte counts) the difference is negligible."
316,What knowledge is required to undertake a masters in computer science.,Whatever math you took for your undergrad CS degree is plenty.
317,ChatGPT and Turnitin,what do you mean by caught using chatGPT
318,What do I do?,Is any of this your fault?
319,The Ultimate Python Dictionary Comprehension Handbook,"/u/Imaginary_learner is a click-farming spam bot.  Please downvote its post and click the `report` button, selecting `Spam` then `Link farming`.  

With enough reports, the reddit algorithm will suspend this spammer."
320,Stony Brook University vs. Binghamton University for Computer Science,"Apply to both. It’s pretty hard to get into SB’s program.  In the unlikely event that you get accepted by both, then you have a decision to make, but you might only get accepted by Bing."
321,Should I get a master's in computer science or bachelor of arts?,You'll probably get more helpful feedback in r/csCareerQuestions
322,"Falsely accused of using AI for speech notecards, looking for the best possible defense against it.","Say you need to audit the source code and chain of custody for the detector they used.

Point out that 85% is only a five-in-six chance. That means that for every 6 people they accuse, one is innocent, even if the accuracy is justified.

Ask them for false negative false positive rates for the detector at well as how those rates were determined."
323,how is TCP reliable given 2 general's problem ?,"The Two Generals problem is about the impossibility of being _certain_ that both parties know what messages the other party has received. In the real-world we can often relax the _certainty_ constraint to a _confidence_ constraint.

I send a bunch of packets to you, and then wait for acknowledgement. You send an acknowledgement to me, and wait for more data. If you don't hear back for a while, you assume the acknowledgement packet didn't arrive, and send another. If you send several more acknowledgements and no more data arrives, you assume the connection has failed and close it. You don't know for certain that the acknowledgements have reached me, and you can't differentiate between your packets getting lost en-route to me, my packets getting lost en-route to you, or my computer choosing not to send any more packets to you. But in practice, all three scenarios result in ""something has gone wrong with the connection, we should close it."""
324,Myspace??,Probably not the right sub. Maybe try r/RBI
325,Where do I learn computer networks?,"I think you should learn it in uni. At least that's where i learn it. You could also check out Cisco academy. Afaik their basic classes should be free.

In basic networking you should learn stuff like what's a router, a switch, all the different Internet protocols. How internet and local networks work.

If by ""putting stuff on the internet"" you mean web pages, that is web development. I think that should also be taught at uni, although i don't know about your specific one."
326,What is the order of items being popped and pushed from a stack?,"> and that push added elements to the end of a stack. 

Look at a [reference](https://docs.oracle.com/javase/7/docs/api/java/util/LinkedList.html#push\(E\)). 
>Pushes an element onto the stack represented by this list. In other words, inserts the element at the front of this list. 


Push adds to the front - which is why you would use it if you are wanting to treat a LL as a stack.

Pop also pulls from the front, again the idea being you can simply use push/pop to add items and take them off in a FILO order.

Think of it like a PEZ dispenser.

Since your stack is built [40,30,20,10], when you pop you get first 40, which you add to the END of your q.
> add(E e)
Appends the specified element to the end of this list."
327,Finding the Largest Base Using Binary Search for Converting a Number with Constraints and a Lower Bound,"You can certainly tackle this problem using a simple iterative approach. Here's a method that should work for your assignment:  
  
Initialize a variable max\_base to store the largest base b that meets the constraints.  
Set max\_base to 10, as it is the minimum possible base for our problem.  
Iterate through all possible bases from 10 to x (inclusive), and for each base, do the following steps: a. Convert the number x to the current base. b. Check if the converted number meets the constraints (only contains decimal numbers 0-9). c. If it does, interpret the converted number as a base-10 value. d. Compare the base-10 value to y. If the base-10 value is greater than or equal to y and the current base is greater than max\_base, update max\_base to the current base.  
After iterating through all possible bases, max\_base will hold the largest base b that brings the converted number as close to y as possible without going below y.  
This approach ensures that you check every possible base and find the largest number b while adhering to the constraints mentioned in the problem statement. It's not as efficient as a binary search but will work for this assignment."
328,What's this add-on called?,"This isn't the right sub to ask these questions, but it's probably Microsoft's Power Toys."
329,What is the chance of two people with the same phone number but with different area codes meeting?,"I think this is the same as the [birthday problem](https://en.wikipedia.org/wiki/Birthday_problem), only with [number of area codes] instead of [number of days in a year]."
330,Time it takes for a signal to pass through ALU’s,"From an electrotechnical perspective, what you're looking for is the worst case time it takes for the outputs of the circuit to be guaranteed to have stabilized after applying an input. This is limited by the longest path, as in, the path with the most transistors, between input and output (also known as ""critical path"").

So depending on how the actual circuitry of your ALUs looks like (specifically the amount of parallelism that's going on), the critical path might not just mulitply in length like that."
331,Help understanding solution to clrs question - MST,"The solution is poorly phrased. I understand your confusion.

Basically, the idea here is that if we start with a tree but then add a vertex with a bunch of edges to it, it'll likely no longer be a tree. Those extra edges will likely have formed a cycle somewhere.

DFS is used to search for such cycles. Once you've found a cycle, you break it up by removing the highest-cost edge from it. Keep doing this until there are no more cycles.

What you'll end up with is a new minimum spanning tree which includes the new vertex."
332,How would I make a neural network to calculate the probability of covid infection?,"It's a big ask and not really explainable within a page. It's only fair to start some reading on machine learning &neural network resource, then some research on predicting spread of disease with neuralnetwork(the nature of the disease is unimportant as its only the input data you train from)

It sounds like you're starting of from 0 background knowledge and asking for assignment help?

If u want to take a shortcut buy a gpt4 subscription for some halfbake answer/quick access to related literature and start from there, though I don't recommend doing this for learning.

Or better go on kaggle and study a few dataset examples(popular one comes with notebook w/code). The code ur looking for will be identical to popular heart disease/kidney disease ones, for your report ull need alot of reading and references."
333,What in your opinion does 'Beautiful' programming look like?,"I don't think I could generalize anything, but `:(){ :|:& };:` is rather beautiful to me.

Edit: Don't run this anywhere unless you want to have to hard shut-off your machine."
334,Explain like I'm 5: what is computer architecture?,Computer architecture is about how microprocessors (the brains of the computers) are designed.
335,How do logic gates transform into a set of instructions that computers can use to perform tasks?,"Check out NAND to Tetris, or the video game Turing Complete. They go through all the steps. 

Tl;dr is that NAND gates can be combined to do boolean logic, which can then be used to do basic math and MUX, and a few other components like memory and repeaters combined with that let’s you do more complicated instructions."
336,Are any substrings of an RSA key correlated?,huh? RSA keys (which one?) aren't strings.
337,I heard a weird ringtone followed by a voice coming from my laptop. What could it have been?,Another tab/browser in the background with another youtube video. Happens to me a lot of times.
338,Help with broadcast address and subnets.,"Your ""[192.168.255.255](https://192.168.255.255)"" address is a network-layer (Layer3) broadcast, which gets received by everything on the network residing in the same subnet range ([192.168.0.1](https://192.168.0.0) through [192.168.255.254](https://192.168.255.254)) and is supposed to be ignored by devices on the network whose interfaces aren't configured within that subnet range.   This is different from [255.255.255.255](https://255.255.255.255), which results in a link-layer (Layer2) broadcast.  Most IP stacks translate icmp or udp packets for [255.255.255.255](https://255.255.255.255) into link-layer broadcasts, where the destination MAC address is FF:FF:FF:FF:FF:FF (or similar), regardless of what IP address is assigned to the interface, so that the datagram gets flooded across the broadcast domain the sending interface resides in.  It's a way to get broadcasts out before you assign a ""real"" IP address to the interface.  Other systems on the network, like dhcpd/bootpd, listen for those broadcasts and respond directly to the sender's MAC address.  The response would then have information the original sender needs in order to tack up a ""real"" IP address to its network interface (like when dhclient/dhcpcd makes a lease request)"
339,How would one go about training a ai to solve captcha?,"> To start out I’d like it to simply be able to tell apart a dog from a cat or something

This is usually done using [convolutional neural networks](https://en.wikipedia.org/wiki/Convolutional_neural_network)"
340,Are there problems that are proven to have exponential worst case time complexity?,"The k-step halting problem (whether a deterministic Turning machine halts within k steps for a given problem) is the best known example.  To solve this you just run the problem in a simulator for k steps and see if it halts; this is O(k) and it is relatively easy to prove that no shorter solution is possible.

This is called pseudopolynomial since the running time is polynomial in the magnitude of the input.  But the time complexity is in terms of the _size_ of the input, not the magnitude.  If you want to count to binary 11 it takes 4 steps; to count to 111 is 8 steps, and so on.  Each time you add a bit, you double the running time.  So if n is the number of bits in k, the running time of the k-step halting problem is O(2^(n)).

The complexity class of exponential time problems is called EXPTIME.  The fact that the k-step halting problem is in EXPTIME but not P proves that EXPTIME is larger than P.  Also, the k-step halting problem is EXPTIME-complete.  For any given decision problem p in EXPTIME, we can just add ""if accept then halt else goto infinite_loop"" at the end, and we can always calculate the maximum possible steps a solution could take.  This reduces an instance of p into an instance of the k-step halting problem.  So if we had a magic box that solved the k-step halting problem instantly, we could use it to solve any problem in EXPTIME in polynomial time.

This is also a good example of how asymptotic time complexity doesn't necessarily say anything about how hard smaller problems are.  For n=15, the k-step halting problem only takes 32768 steps; an O(n^(4)) problem, despite being in P, is potentially harder than O(2^(n)) at n=15."
341,Is there a difference between the best and worse case space complexity?,"Ask yourself the following questions for each algorithm:

What would you say the best case and the worst case for the algorithm looks like? Do you have an idea what its worst case space complexity is? What is the space used for? Does it seem like the best case would need less of that than the worst case?"
342,MST - Question about answer on stack exchange,If a graph is connected what can you say about the relationship between |V| and |E|?
343,How will we do this: Devise an argument that shows order-limited perceptrons are also incapable of recognising connected figures (from the New Turing Omnibus),[removed]
344,Why Isn't a Timer Capable of Preventing Brute Force,"I think the brute force attacks are mostly successful on data breaches.

So basically, they have the hash of your password, they’ll just brute force that, on their own system. 

The timers would prevent them from brute force-ing passwords on the hosted website."
345,How do you think AI will affect human relationships?,[removed]
346,I want to learn C# on the side of my current summer job. What website do you recommend?,/r/learnprogramming
347,"Given the recent layoffs in the industry, what is your outlook on the future of software engineering? How do you see it evolving in the future, and what advice would you give to young professionals entering the field? lets say will support your children to choose this field.","Layoffs are compensating for companies overlevering. I am not worried about the industry losing traction, given how much there is yet to do when it comes the software I don't think the bubble is close to bursting. I am worried about the entry level gateway problem. Everyone needs a developer but no one wants to train them, how fucked up will the industry have to be till companies realize that if no one trains developers then there will be no trained developers to hire eventually?

My advice is build a portfolio and network. Talk to any and all professionals you know and get to know them, and if you don't know any start moving around in communities. Do personal projects that can look shiny in a CV. Build experience and open doors to yourself. Good university environments are also wonderful places to get to know people with lots of experience in the field and therefore lots of contacts (this depends on the university and it's a hir or miss, but the programmers I have got to know during my masters in Gothenburg have been by far the most invaluable contacts I have had for getting jobs and opportunities)"
348,Need help with the New Turing Omnibus,[removed]
349,Is Lenovo IdeaPad Slim 3i 15 good for programming?,"Programming what? If just for learning some basics in Python or Java, it should be fine"
350,Php MySQL hosting recommendations?,Dreamhost checks all 5 buckets.
351,Pro & Cons of Cyber Security,"I would challenge the assumption that you ""always have to be on-call"". Mature, well-run security programs intentionally avoid this because it's a well-known bad pattern that leads to burn out. In fact, NIST even upgraded their incident response standards a few years to explicitly include providing adequate downtime for responders as a critical element of an IR program.

Many teams at larger companies, for instance, have ""follow-the-sun"" models of oncall, so that you're only oncall during your local daytime. In my case, our org has folks located in the US, Australia, and Switzerland. So there's expertise available 24 hours a day, but no one has to be bothered after local working hours.

As for pros and cons:

Pros:

* The work is always interesting. The cat-and-mouse nature of security as well as the fact that attacks only ever get better mean there's always new stuff happening in the field.
* It's broad enough that anyone can find a niche. I have friends who are cryptographers, malware reversers, hardware security engineers, red teamers, etc. Each area of security is a whole domain unto itself with different challenges.
* It's very well compensated. I've consistently found that I'm paid 10 to 15% better than my comparably-leveled engineering peers.
* It's recession-resistant. Attackers don't get laid off, so it's rarer for defenders to get the axe as well. In fact, during hard times, the industry in general sees more attacks.
* The security and hacker communities are incredibly supportive and some of the consistently coolest people I've ever known. (Seriously, go to DefCon some time and just hang around. The density of incredibly rad people is just notably higher than the general population.)

Cons:

* Hyper-vigilance. If you are an anxious person, cyber security can absolutely exacerbate that tendency. I'm the kind of person that looks around corners and obsesses over risk normally. This makes me an excellent security engineer, but the security engineering work reinforces that part of my character. I combat this with a mix of therapy and remembering to take plenty of time off.
* The industry has some perverse incentives that can frustrating or downright dangerous. This is especially true with companies like Managed Security Services Providers. They have an incentive to make everything sound worse than it is so that you'll buy their tools or services. They can largely get away with this because of the next Con:
* Measurement of risk is a notoriously hard problem, which means it's hard to know when you or your team are doing a good job. We have only indirect measures to rely on most times and even those aren't often under our control. For example, let's say we want to roll out a new control like channel-bound tokens. We're pretty sure that this will reduce our number of account compromises. But by how much? Often we don't have good details about how an account was compromised. And this control only effects some account compromises, not others. So how many will we actually stop by rolling this out? Is it a good use of our time? Will attackers just shift to other methods of account compromise instead? Etc.
* As a result, showing your worth and moving up in your career can be a challenge. Especially as you get more senior. I spend a lot more time now gathering metrics than I used to and part of that is to gauge efficacy of controls, but part of it is to be able to justify my existence to leadership. Not ideal, but it's part of the game.
* Imposter syndrome is real and so much worse in security than in other tech fields. Remember what I said about it being a broad, fast-moving field? Well that means that you will always be at least a little behind and definitely be ignorant about most security. And that's kind of a shitty feeling. Combine that with the fact that attackers occasionally just straight up stunt on us, and it's a recipe to feel like a failure, at least occasionally."
352,Advice on open-source,"Choose something you use or are interested in or is related to a domain or language you want to specialise in. This is real life, not high school. There's no homework."
353,"Which is less stressful and takes less effort on average, software engineering or cybersecurity?",[deleted]
354,What should I learn before starting first year of uni?,[deleted]
355,Advice,"Whether it's fair or correct or not, most employers see a BS Information Systems as basically a weak-sauce BS CS.  So from their point of view, a double degree in CS and Information Systems is like ordering mashed potatoes with extra mashed potatoes - the BS IS doesn't add anything.  You'd be better off taking the minor in Business Administration because at least that shows two different skills.

And yes, if you're going to do 10 more classes, _absolutely_ do an MS CS rather than screwing around with adding a BS IS to your BS CS."
356,Google drive download acces,"Can you copy/paste from it? Or print the page as a PDF, and if the text isn't preserved, run OCR on that?

You need the Google Docs code to download the document as a .docx or .odt or whatever - they're doing the translation for you, and if the download option is disabled then there's probably nothing you can do about that - but if you can view the content on screen then there's no way to prevent you from extracting the content, it might just be in a less-convenient format."
357,Trying to pick between CS and Education as majors,"You’ll make a hell of a lot more in software engineering than you ever will with education, if that matters to you at all. 

If you enjoy coding, and are willing to put the time in, you will be rewarded after school with a great job. The learning curve is pretty steep and it is easy to get discouraged, but if you like it, then you’ll have a good time.

Just my two cents"
358,Using a web app on a transatlantic plane,"This question would probably be more on-topic in /r/LegalAdviceUK or /r/LegalAdviceEurope.

I'm no expert, but [this page from the European Commission](https://commission.europa.eu/law/law-topic/data-protection/reform/rules-business-and-organisations/application-regulation/who-does-data-protection-law-apply_en) says:

> **When the regulation does not apply**

> Your company is service provider based outside the EU. It provides services to customers outside the EU.  Its clients can use its services when they travel to other countries, including within the EU. Provided your company doesn't specifically target its services at individuals in the EU, it is not subject to the rules of the GDPR. 

So if you wouldn't otherwise be required to comply with the GDPR, then I don't think one of your users getting on a plane to Paris changes anything."
359,Apparently not many know of a new datatype for our computers.,"I skimmed this and the part I read seems valid, but I'm not sure exactly what benefit it provides over current forms of number encoding. We've always had the ability to encode numbers and lists in unary, but it takes a lot more space than binary. Since you allow for leading 0's you could even argue your encoding has three characters: 0, 1, and blank.

I agree with your statement ""Dynamic Unary Encoding introduces new choices of how binary data is represented"" and some of the other statements you make in your conclusion, but I don't see how Dynamic Unary Encoding provides more functionality than any existing system of encoding data"
360,Self Study : Theoretical computer science,"The subjects you mentioned need a lot of effort to grasp and understand . For automata theory , the book by peter linz is really good for solving problems. Good luck"
361,Slang Term for Dual-Booting?,"Maybe I’m out of touch but is it really that common that it gets a slang term?

Back in the 90s we would use the LiLo bootloader to reboot into windows or into Linux. Boot menu?"
362,My cs book sucks and I have to learn Memory Management,"Ooh, ooh, [I wrote a blog post about this!](https://backdrifting.net/post/032_allocation_and_relocation)

But the tl;dr,

**Internal fragmentation:** we can only allocate an integer number of blocks of memory, so if your program needs 1.2 blocks then we assign it two, and just wasted 0.8 blocks

**External fragmentation:** when memory has been allocated to several programs already, and there's enough memory left to fit our new program, but it's split all over the place, so we either need to shuffle existing programs around to defragment and combine the empty spaces, or use a more complicated solution like virtual memory so we no longer need to allocate continuous blocks

An offset has to do with translating memory addresses between your program and the locations of variables in RAM to allow relocatable code. If your program's assembly instructions included hardcoded absolute memory addresses, like `0x0802FF0A` then it'd conflict with any other program that wants to use that memory address. To avoid these conflicts, we add a (determined at program start) offset to all memory addresses to shift the program into an unused memory region. This is only one solution to memory address conflict problems; modern operating systems solve the same problem using virtual memory (but we also still use relocatable code for security reasons in ASLR)"
363,How reliant is the Android Ecosystem on Google?,"I reckon every phone outside of Apple relies completely on Google (except the excellent Pine Phone 64 and a very few other Linux-only phones). In a World where Ubuntu Touch exists this is amazing to me. Purely down to business inertia.  
Samsung, however, are still pushing Tizen pretty hard and that uses no part of Google:

[https://www.trustedreviews.com/explainer/what-is-tizen-4255483](https://www.trustedreviews.com/explainer/what-is-tizen-4255483)

https://www.tizen.org/about

It's very close to the metal Linux-baed OS so ditches all of the Java nonsense that is the slow-as-treacle top layer of Android.

Co-supported by Intel and the Linux Foundation I think it may become the sleeping giant in the phone world. It's already made its way onto TVs, smartwatches and set top boxes. They recently ported Vulkan to it using SDL and for games that could be huge. A .NET layer and an HTML5 layer are available so developing for it looks pretty straightforward, no special tools, IDEs or daft languages required.

We could well reach the point where every manufacturer has had enough of Googles binary blobs and is fed up with paying the licensing fees to them so any alternative that frees up this chokehold could get traction."
364,Why do all the college prep videos completely discount computer science as not being an engineering profession?,"Construed narrowly, computer science plainly isn't an engineering discipline.   It's the academic study of computation.

Construed broadly, there are some jobs in computing that might reasonably be described as engineering, but not most of them.  Compounding the problem, academic computer science has oddly decided to use the term ""software engineering"" to refer to the study of organizational behavior  with regard to software projects, which has little to do with what a mechanical engineer means by ""engineering.""

People sometimes talk about putting computing on an even footing with other white collar fields by developing a code of professional ethics and maybe even a set of design minima like the National Electric Code.  The problem is that developing such instruments is difficult, and getting people to follow them is even more difficult.  But without someone like this, computing workers _are_ ""just a technician on staff.""  There is no recognized allegiance to anything beyond their immediate job."
365,How would I clone a Physical Win 10 PC (With all it's contents) into a Virtual Machine (Hyper-V)?,"UPDATE:

Using Sysinternals Disk2VHD tool. I was able to do everything I needed to.


Running the tool and copying the System Hardrive and any other hardrive I needed (Shadow copy enabled). I was able to simply create a new Virtual Machine on Hyper-V and attach the new virtual hardrives (.vhdx) to the new VM.

Just like that the entire OS is copied over and all the files. Everything was working perfectly other than I needed to add a new Windows License Key."
366,How does the computer science field evolve with the advent of GPT-like systems?,"People always seem to mix up the academic field called computer science, and the commercial activity of writing profitable computer programs.  ChatGPT may affect the latter, but it is unlikely to do anything at all to the former.

The theoretical breakthrough that enabled LLMs, aside from just the sheer hardware resources we now have access to, was the ""transformer"" architecture, which allows a neural network to more finely control what it pays attention to and what it doesn't, including dynamically controlling its attention based on inputs or internal states.  Large neural network architecture is still an active research area likely to generate more published work, and some of this work may have immediate application in making LLMs better.  LLMs aren't driving computer science - computer science research is driving LLMs.  The more commercially valuable LLMs become, the more likely it is that research dollars will continue to flow to this subfield of computer science.

People at the bottom end of the software development food chain - people who up to now have mostly been copy-and-pasting from Stack Overflow and Reddit - will now start to copy-and-paste from ChatGPT.  This will mostly affect the relative fortunes of Prosus and OpenAI, I think.

It's possible that a future LLM might be able to do the job of a programmer at some point in the future.  We're not there is, but it's hard to predict how fast these things will arrive.  It was already possible for pre-OpenAI NLP systems to do the job of writing bottom-tier SEO copy.  ChatGPT is likely to eat into this market.  I'm not sure how soon an LLM will be able to produce an opinion article of comparable quality _and insight_ to the Washington Post or New York Times.  But I'd be more worried about writers jobs than programmers, at least for now."
367,steam showed a different ip and location when i logged in,"Having a static or dynamic IP shouldn't affect anything here.

Location can be inaccurate for various reasons, so I'll ignore it for now.

What do you mean it showed an IP you didn't recognise? Is the IP shown by Steam different to what your computer reports? That would be expected since your computer has a private address assigned by the router via DHCP. It could be static or dynamic, doesn't matter. It's unique to your local network and different from your public IP address assigned by the ISP. Your router translates between the two, it's called Network Address Translation.

If the IP address shown by Steam is different to the IP address your router tells you it has, your ISP might be using CG-NAT. (When an ISP uses NAT to share a single IP address with multiple customers, it's called Carrier Grade NAT).

On the other hand if Steam shows you an IP address that doesn't match what a site like eg. [WhatIsMyIp](https://www.whatismyip.com/) is showing you at the same time, then it's probably a bug or something on Valve's side, there isn't any reasonable explanation for them to differ."
368,Not sure if allowed but desperate. Ive placed a green barrier where i get confused. How did the tutour get 9 if X and C is both 3? Very confused. Im not asking anyone to solve this im just wanting to be corrected and know how.,The pic is so blurry I can't read it
369,Intro to AI or Intro to ML?,"You should look at the curriculum of these courses, ask people who have taken them, or just check out the lecturers.

That said, I would guess that Intro to ML does exactly what it name tells you - it introduces you to ML. This is probably a useful course, where you learn a lot of what goes on right now in the field of AI, which currently very much relies on machine learning.

Compared to this, Foundation of AI is probably a more broad course, with less clear practical applications. It might cover non-ML AI techniques (such as computational intelligence (genetical algorithms, swarm intelligence) or ""good old fashioned""/symbolic AI techniques). It will probably focus on the philosophical foundations of AI (Turing test, Chinese Room Argument, etc) and the ethical dilemmas that come with the field. 

These are all assumptions of course - you can verify by checking out the curriculum."
370,"What is the difference between assymetric encryption, private and public keys, digital signatures and digital certificates? Digital signatures are a way of validating the authenticity of a document but doesn’t asymmetric encryption already do this as the public key only works with its private key?","These seem like vocab terms that you could Google. Everything you've described is a component of asymmetric encryption. Asymmetric encryption is the technique, which utilizes public and private keys. Digital signatures authenticate the source and lack of tampering of a document, but the term is often used for _detached_ signatures, while asymmetric encryption also includes encrypting the entire file with a private key as a form of signing. Digital certificates are a type of digital signature; the term is sometimes used to describe a file containing a digital signature, like a public key certificate issued by a certificate authority."
371,"What online resources do you prefer for research, such as websites, forums, or online communities that you find helpful?","For basic how-to usually stack overflow, or the Unix stackexchange. More complicated application would be whatever documentation I can find. For actual research [arxiv.org](https://arxiv.org) researchgate, etc. I recently found [algorithmica](https://ru.algorithmica.org/), which is quite a bit better quality than most ""computer science"" oriented websites, but it's nothing groundbreaking (I don't actually use it, it just struck me as unusually good)."
372,If a language model like chatgpt wasn't talking to anyone can it think to it's self?,"No, it's a model which needs inputs. 

you know those escalators that only moves when you move thru the sensors. its like that. u gotta give it something.

so when there is no input, it does nothing"
373,Can text Mining be used to convert unstructured data into structured data that can be used to train a machine learning algorithm?,"You should look into Self-Supervised learning if you haven't already, I believe that's what's you're looking for. It's a huge deal, e.g. it's the main technique used for training Llama.

If you're looking for something else/something more specific, please elaborate, since you're question is very vague."
374,How do port checkers work without compromising my computer?,"In a traditional home network all of your computers, phones, and other network-connected devices share a single external IP address. By default, your router blocks all incoming connections to your network, unless something within your network has explicitly told it ""I'm expecting incoming network connections on port 1234, please forward those to me.""

A port checker just tries connecting to various ports to see if there's any software listening. An open port means there _is_ some piece of software running and expecting network connections. A closed port means the router rejected the connection, because it's not configured to accept connections there.

Therefore, an open port doesn't imply that you can be compromised, it just means you've got some kind of software running that people on the Internet can talk to."
375,"What takes longer, testing a deep learning system or a machine learning system?","Deep learning is a type of machine learning, so this question seems ill-formed"
376,Windows Power Automate license question,r/MicrosoftFlow
377,Would it be possible to train LLM models like GPT peer-to-peer style?,"Probably not on the consumer level, at least right now. Each training step relies on building on the latest model to improve it so if the training requires sending the large model to all the peers it ends up taking more time and bandwidth than it's worth. This is especially true for LLMs where the model size can be a few gigabytes.

There are some ideas to parallelize multiple training processes and then merge them together and if you have connections like Infiniband, it definitely is possible, but then you're no longer in the realm of consumer hardware.

This is on top of the intrinsic challenge of running the model on consumer grade GPUs in the first place. Training requires more VRAM than inference so even fewer GPUs can actually power it.

[https://petals.ml/](https://petals.ml/) is a project to do distributed inference if you're interested."
378,I offer you the enigma that is the question the computer science field has been seeking since the dawn of time,"This isn't a CS question, it's an IT question and hence is off topic for this subreddit.  You should post on a tech support sub instead."
379,Are these definitions correct?,"No, absolutely not. I've seen ""narrow AI"", but ""general AI"" doesn't mean ""any intellectual task"", it means ""*all* intellectual tasks"", i.e. it's an AI that is at least human level. We do not have any of these, and including manufacturing robots in this category is bizarre."
380,Infinite looping between systems,"1. Solve the problem as far up the data pipeline as possible.  The best way to solve this is to add a validation/transformation library on all of your publishers so that you ensure that the messages are all consistent.

2. If you can't avoid data transformation on the subscriber side, I would strongly recommend establishing a one way pipeline with the transformation steps you need.  Some publishers may publish to the most upstream topic (if they need the most amount of data transformation), some publishers may publish to an intermediate topic, and some may publish directly to a ""clean"" topic if you can guarantee validation on the publishing side."
381,"What are some genuine insights, tips, or hacks to get ahead of the competition when starting a news YouTube channel ?",How is this about computer science?
382,Computer Science Applied in a Primitive Society,"> So the question is has anyone done work on how to efficiently implement analogs of modern methods by hand, or very simple calculation aid?

How about the entire history of mathematics and computation up to just before the digital computer era?  Logarithm tables, slide rules, algebra, long division and even positional number systems are all examples of finding ways to do computation more efficiently.

With modern knowledge of pen-and-paper computation, you could do AES-256 if you really wanted to.  It might take you several days to encrypt or decrypt a single message, but you _could_ do it.  This is probably not the case for someone who only knows Roman numerals."
383,Just someone interested in Comp Sci,"I am in the US, but I did read the wiki page on Mathematics education in Australia, so hopefully I'm not too far off base.

The answer will somewhat depend on your final goal. Do you just want to get a decent job or are you hoping to enter academia and do research?

In the US, I think many degrees require nothing more advanced than calculus 1, which at a quick glance, appears to fall between Advanced and Ext1.
As opposed to going through all of EXT1, I would maybe look into discrete mathematics as it will be more directly applicable. An intro to Logic wouldn't hurt either if you can swing it."
384,Floating Point to Integer conversion,"Maybe this helps:

[https://stackoverflow.com/a/16444778](https://stackoverflow.com/a/16444778)

 [https://en.wikipedia.org/wiki/IEEE\_754#Binary](https://en.wikipedia.org/wiki/IEEE_754#Binary)"
385,"Feeling Lost, CS or Medicine?","> is there any truth to their claims about computer science being an awful field to pursue?

abso-fucking-lutely none.  computer science is a beautiful field.  there is more to computer science than programming, a LOT more.  software engineering is not even a sub-field of computer science.  it's an engineering discipline that requires knowledge of computer science, in the same way that chemical engineering requires knowledge of chemistry.  reducing computer science (or even software engineering) to programming is like reducing astronomy to using telescopes.

which makes you happiest?  or, is there another discipline entirely that you enjoy more?  it doesn't matter how prestigious or high-paying the job is if you hate doing it.  and, especially for things like medicine and engineering, if you go into it solely for money or prestige, you are making the world worse for everybody, including yourself.

you're only in your first year.  you've got time to explore.  you should."
386,"Can anyone tell me why I have this error, ifelse is highlighted as the error","this language looks like a Frankenstein's monster made out of Python and JavaScript parts got eaten by a TRex, then barfed out again.

you should probably head to r/<whatever this unholy spawn of satan is called> and ask there. or in r/HomeworkHelp"
387,A Prominent Guide on Data Mining Project Ideas to Try in 2023,"/u/Imaginary_learner is a click-farming spam bot.  Please downvote its post and click the `report` button, selecting `Spam` then `Link farming`.  

With enough reports, the reddit algorithm will suspend this spammer."
388,"ELI5: How does programming for AI differ from traditional programming, and why are we only now figuring out how to do it?","In the most basic sense, AI software is just normal software - it has a series of instructions that you apply to the input.

However there are a few important new things:

1. AI uses a **lot** of computer power and data, especially training. These calculations would be really slow without modern hardware like GPUs (and now custom processors). The internet has made it possible to build really big collections of data for training.

2. Machine learning (which is really a somewhat separate field than AI) represents a quite different approach to how you write software. Instead of giving the computer instructions on what to do, you give it examples (usually lots and lots) of what you want, and then you program systems that analyze that data to find patterns and ""learn"" how to solve the problem. This allows you to solve problems that humans don't actually know how to solve with algorithms. This includes a lot of things we do unconsciously, like process images and speech.

3. New algorithms have been developed that improve what we can do with this data. This is a more complicated story - some of these algorithms (e.g. stochastic gradient descent, neural neta) aren't really that new, but people have figured out various tricks that let them work better (batch norm, resnets, Adam optimizer, transformers, and lots of other things). This is mostly driven by two factors I think: point #1 made it a lot quicker to experiment with these things, and early successes have led to a lot more researchers and engineers working on these problems."
389,Any ideas for computer science FYP ?,[deleted]
390,"How ""expensive"" is video hashing (fingerprinting)?","It's definitely a hard problem - you can't use something simple like an MD5 of the video/audio, because the infringer might not play the entire song/movie, or they might use it in the background of their video or twitch stream and talk over it, or worse yet they might have it playing off a speaker in the background (cell phone vid in a movie theater?).

So you'd need to make a separate content hash for every few minutes or perhaps seconds of content, and the content hashes need to be fuzzy enough to match even with moderate distortion, but not so fuzzy as to have an unacceptable false-positive rate. So maybe instead of making a hash for every ten seconds of content, you overlap them, so you have a hash of seconds 0-10, 5-15, 15-25, etc, and only flag the content as infringing if enough fuzzy hashes match to have high confidence. But now you're calculating even _more_ hashes, increasing the time, computation, and storage needs.

Now you need to do this not only for all videos from the copyright holders to generate the positive values, but for all videos from whatever platforms you're monitoring to check them for infringement. That's quite a pipeline."
391,MS in CS at George Mason or Dayton University?,This isn’t really the place for this sort of discussion so you won’t get much of a response or likely reach anyone who has knowledge of these schools. r/csMajors would be a better fit.
392,AP Computer Science Final Project Idea?,You could try Conway’s Game of Life.
393,Object Oriented Programming in Python (OOPs),yes
394,Difference between ( SYNTHETIC INTELLIGENCE && ARTIFICIAL INTELLIGENCE ),With the exception of NP complete (which has a formal definition) I don't think any of the terms you're using are rigorously defined. It's unlikely you'll get a satisfying answer to this question.
395,Can you interest me in computer science? Looking for someone well versed in the subject for college.,[deleted]
396,Udemy,"it's as safe as any other marketplace or online store... I mean, it's a legit company, if that's what you are asking.

my company pays thousands to them for licensing so employees have access to free trainings if they want/need them"
397,Do IO writes complicate a function’s contract more than IO reads?,[deleted]
398,Partial Maj-SAT and its power?,"For the complexity of determining the satisfaction probability of a formula, a trichotomy was recently proven: https://arxiv.org/abs/2201.08895

For the second question: you likely mean „solve it in deterministic polynomial time“? Most likely no, because of the potential useless information the oracle could give you (always 2) but you could query the oracle multiple times, similar to the error reduction technique for BPP."
399,Often confusing terminology in the concept of reductions (complexity theory),"What you've said is (mostly) accurate but it's a bit like saying ""You're bigger than me because you're taller than me; but I'm older than you, so isn't that confusing?"" - essentially you are conflating comparison via reductions and comparison via asymptotic analysis - two quite different concepts of comparison. 

For a start, ""comparison via reductions"" is a means of comparing **problems**, whereas ""comparison via asymptotic analysis"" is usually reserved for comparing **algorithms** i.e. ""solutions"" - but usually solutions to the same problem.  It is possible extend the latter notion to a comparison of problems (e.g. ""we can [currently] solve the Eulerian path problem more efficiently than we can solve the Hamiltonian path problem""), but that's not really giving us much that we can work with.

As you've observed, all a polynomial reduction does is say these problems are comparable *up to polynomial changes in the input size*.  This is certainly appropriate when dealing with ""intractable"" problems - ultimately we don't care if we input a graph as an adjacency list or as an adjacency matrix if our algorithm is going to be exponential in the number of vertices.  But if we are looking at algorithms where it matters whether it runs in O(n^(2)) or O(n log n), then comparison via polynomial-time reductions is, indeed, somewhat meaningless.

However, there is one small point where you have some confusion, and although it is minor, it is something that I have a major issue with, so for my own sanity it warrants a

#Public service announcement: Polynomial-time reductions

> If a problem A reduces to problem B, that means problem A can be solved using the solution of problem B.

This is the definition of a **Turing reduction**.  While this concept of reduction is useful when examining the (un)decidability of a problem, it is not a sensible notion of reduction when talking about resource-bounded computation (e.g. polynomial-time reductions).

When we are talking about polynomial-time reductions (and NP-hardness/completeness) the *default* notion of a reduction (these days) is a **[many-one reduction](https://en.wikipedia.org/wiki/Many-one_reduction)** (also known as a Karp reduction).  That is, problem A reduces to problem B if we can transform (in polynomial time) inputs of problem A into inputs of problem B such that Yes-inputs map to Yes-inputs and No-inputs map to No-inputs.  [This is a strictly weaker notion of reduction than polynomial-time Turing reductions (aka Cook reductions), but it is more useful: e.g. NP is closed under Karp reductions but not under Cook reductions].

In other words, the observation that a polynomial-time algorithm for B yields a polynomial-time algorithm for A should be taken as **consequence** of there being a reduction from A to B, *not* as a definition.

Note: there is a place for Cook reductions in computational complexity, but they  arise in more advanced topics such as oracle machines and the [polynomial-time hierarchy](https://en.wikipedia.org/wiki/Polynomial_hierarchy).

**Edit** To add to this, I don't think there is much confusion with terminology, because ""hardness"" (and sometimes ""easiness"") is a technical term, it is almost always exclusively used in the context of ""comparison via reductions"".  When comparing algorithms asymptotically, we tend to use terminology such as ""more/less *efficient*"""
400,career help please?,You may get more feedback in r/cscareerquestions
401,6 Advantages of Access Request Management for IT Teams,"/u/Imaginary_learner is a click-farming spam bot.  Please downvote its post and click the `report` button, selecting `Spam` then `Link farming`.  

With enough reports, the reddit algorithm will suspend this spammer."
402,Computer Science or Software Engineering?,"Its late and I'm tired so I'll expound later 

Go for Comp Sci"
403,"What is definition of a ""microservice""?","the cynic in me wants to say that there is nothing new under the sun. it's not like Unix's small compact pipelining concept with programs is exactly new either. every approach breaks down under real world considerations with maybe a few outliers. the separate data storage part in particularly bothers me because there is a cost of maintaining different stores surrounding maintenance and general clue. ditto different languages if you're the one having to pay the salaries.

there is a limit to what is decomposable. it is rather pointless to make a general purpose library for exactly one consumer. it's fine to abstract things to a degree, but not ok to cop attitude that you've achieved anything special in that case.

architecture is always about tradeoffs first and foremost. some shiny new religion is asking you to be blind to that is not ok."
404,How different is AWS lambda from Microsoft Power Automate?,The main difference is that power automate is intended for single user automation while AWS Lambda (and other serverless architectures like Azure functions) are intended for scalable workloads of thousands of events per second
405,What is the best way to incorporate external sources to explain what your code is doing when comments wouldn't be able to adequately document your code efficiently?,"Depends on the work context.

If it's just a personal project, I would go with a README.md file with an embedded image.

If it's for a company, they often have a set of reference documents or even an internal wiki that would be useful. Maybe even API documentation if it's client facing.

> How do you reference the document from your code

Usually just a comment saying, ""see section X of the documentation"".

> how do you keep the code and reference document synchronized so an update in one leads to the corresponding update in the other? 

If you figure this out, patent it and make a fortune.

Seriously, this is one of the most infamous problems in software engineering.

> Are these types of documents generally checked into the same version control repository as the actual program source code?

Depends on the size. Small README files tend to be in VC. Larger wikis and documentation tends to be kept separately."
406,"What is definition of an ""object"" in ""object-oriented""?","I see a lot of problems with this.

Let me start with the biggest problem first witch is your question in general. It seems to me like what you do here is just pedantry (I base it on the way you wrote the post + some post history). You seem to want some formal definition of the term ""object"" as used in ""object-oriented programming"" given as a set of necessary and sufficient conditions. I can tell you right now that you won't find one. However it's not a problem at all as it's just how language works. If I asked you to give necessary and sufficient conditions of being a table (no, not SQL one, the dinner table one) such that it would correctly classify all objects that most people would agree are a table - you would fail, but it's not a problem.

However even if that in mind there are problems with what you wrote. Here are some of them:

>OOP languages are usually defined as having 4 following properties: abstraction, encapsulation, inheritance and polymorphism

Being OOP (same with functional/procedural) is not a feature of a language. We use that term colloquially. OOP-ness is a feature of how you structure your code. Typically we say that language is OOP if it supports and/or helps to structure code in a given way. I can program in OOP style in C, but we don't typically call it OOP language, because it's cumbersome.

&#x200B;

>But encapsulation is found in non-OOP modular languages like Modula-2

That doesn't show that encapsulation is not a necessary condition. Being even is a necessary condition for a number to be divisible by 4. Saying that 22 is even, but not divisible by 4 is not a counterexample showing that it's not a necessary condition. That is what you did here.

&#x200B;

>But System F<: also extends polymorphic lambda calculus with subtyping relation  
>  
>But System F with existential types also allows information hiding

Same problem as above. Those are simply not counterexamples to polymorphism or abstraction being necessary conditions of being OOP.

&#x200B;

>purely functional languages like Haskell

I have no idea what could that even means for a language to be purely functional.

&#x200B;

>\[...\] 4 following properties: abstraction, encapsulation, inheritance and polymorphism. I argue that none of them is necessary neither jointly sufficient by providing counterexamples

As shown above you didn't provide counterexamples for 3/4 of the properties for necessity condition and I don't see where is a counterexample to show that jointly they are not sufficient."
407,How do we trace the output of F¹ here?,"So your question is how to simplify `(A+B'C)+(A'B⊕D)`?  Assuming you know the normal rules for simplification without xor, just consider that `X⊕Y≡XY'+X'Y`."
408,"How will quantum computers change hacking, cybersecurity, and similar aspects of digital security? Asking as a kid who is considering a career in cybersecurity/white hat hacking.","TLDR: Cryptography hinges on large numbers that are hard to find their prime factors. If you have a working, powerful quantum computer, then this becomes easy.

&#x200B;

&#x200B;

Basically, the biggest problem emerges in the world of cryptography. Cryptography is the backbone of cybersecurity because it is basically the way we secure information in such a way that only those who should have access to it do.

Currently, one of our most potent cryptographic techniques is public key cryptography (RSA is a good example of this, widely still in use today).

I won't bore you with all the exact technical stuff, but basically the way it works is that a user's private key is a secret large number that only they're supposed to know, and it's used to decrypt messages sent to them (or for digital certificates, it's something they use to prove their identity).

So the mathematical ""hacker"" would be somebody who wants to find out what your private key is.

&#x200B;

So here's where the strength of RSA comes into play. Basically, to find somebody's private key, it is equivalent to being able to factor a *very large number* into it's prime factors. This is a problem in computing typically referred to as ""factoring"" just for shorthand.

Factoring is a *hard* problem, by which I mean the larger the number, the way way way harder it is to factor it. For example, 21 is 3 \* 7 and that's easy. But what are the factors of 243345233423421233234645746?

RSA and other public key techniques rely on the fact that these large numbers are difficult to factor. They're not *impossible* to factor, but if the number is so big, it could take a computer say thousands of years to factor it, then that's good enough for our purposes, since we'll all be dead and our cryptography will be irrelevant long before then.

&#x200B;

Now, enter quantum computing. The main bottleneck here is actually building a real quantum computer that really *works*. There has been progress made in this direction, but nothing quite yet that's a quick, out-of-the-box functional quantum computer that really does the job with a lot of resources. (Short story version, the *principles* of quantum computing are understood, but the ""I can actually physically build a nice big one and prove that it works"" remains a white rabbit).

However, this doesn't stop mathematicians and scientists from considering what would happen *if there was a functioning, highly capable, accurate quantum computer*. 

For the problem of *factoring* specifically, i.e. if you have a large number, finding its prime factors, this is normally very difficult, but there's an algorithm that has been developed (Shor's Algorithm if memory serves), which would use a quantum computer to be able to factor large numbers much more quickly. If this is actually doable (i.e. if you really have a working quantum computer) then this means public key cryptography systems could be rendered useless, as it would be quick and simple to determine user's private keys if you know their public keys (which are, of course, public).

So this is one of those current ""hits the news stories once in a while"" fear-mongering going on nowadays. Of course there's really not much to fear because at the moment, developing a working quantum computer is something that's still likely very far off into the future.

&#x200B;

Allow me to share another anecdote that may help put this issue in perspective:

In the 1920s and 30s, cryptography was obviously done without computing devices. In many cases, it was done by mechanical processes. The German Naval Enigma was a technique employed by the Nazis in World War II. It involved having a rotating ""key"" that was typically 3 letters long, and the key would be changed daily. With three alphabetic characters, the number of possible keys was about 17,000. So this meant if you're trying to break the code, you'd have to physically try that many possible keys *in less than a day,* because of course the next day they'd be using a different key.

This was of course, rather difficult for what was available at the time in terms of technology (they really just had some people working on it with pencil and paper).

You may know the story of how Alan Turing enters into this situation, and as he was developing the notion of computing machinery, eventually the process of finding the Enigma key was automated by the use of computing technology (we owe our current digital computing discoveries primarily to this specific application) it made the process much easier.

&#x200B;

So what happened? Well obviously now that everyone has fancy digital computers, a coding technique like the Enigma is a non-starter.

The same thing will likely happen to cryptography once quantum computing becomes a reality. The new technology will make the old-fashioned approach unworkable and people will move on to something new. Maybe through the use of quantum computing, a brand-new, fancier ""quantum cryptography"" will be developed and used instead of RSA and other public key crypto that's currently in use today. Who knows?

That's the exciting part about technology, it's always changing and there's always more to learn!"
409,"How do I host a single static HTML site in the cheapest, lightest way possible with a mail server?","I'm not sure what you're looking for here. Are you asking for software suggestions? Hardware? Hosting providers?

Yes, nginx hosting a static site, on the same server that runs email, should have low resource requirements. I pay about 5 USD/month for a digital ocean droplet running nginx + postfix/dovecot for email. It has dynamic site content, too, but a low user count. You could probably go cheaper if you hunted for a bottom-of-the-barrel hosting provider, or perhaps even cheaper if you go for managed web/mail hosting instead of a VM."
410,In need of a comp sci website for class,"There are sites like Wix that'll help you build a website without writing any code - but if this is for a class, using such tools is probably forbidden and academically dishonest, and it'll _look_ machine generated rather than handwritten. If you'd like to learn how to make websites yourself, r/learnprogramming may have some resources. There are [a few in their wiki](https://www.reddit.com/r/learnprogramming/wiki/online#wiki_web) at a glance"
411,C language coding,In what circumstances does it return wrong values?
412,Recommend lectures for PCP Theorem,"Hey there! As someone who has struggled through learning the PCP Theorem myself, I totally get where you're coming from. A lot of the resources out there can be really dense and difficult to follow. 

I would highly recommend checking out the lecture series by Professor Ryan O'Donnell from Carnegie Mellon University, available on YouTube. He explains the PCP Theorem in a way that's easy to understand, and breaks down both the strong and weak PCP Theorems step-by-step. Plus, he throws in a few jokes and puns to keep things light and entertaining (which is always appreciated in computer science lectures, let's be real). 

Hope this helps and happy learning!"
413,"What do you all think of graphical languages, such as LabVIEW?","I've worked with both LabVIEW and Talend. They're great for straightforward things but suffer from an ""event-horizon"" effect where a slightly more complex problem will send you spiralling into ever more messy solutions. Generally, anything with a fixpoint lurking somewhere.

They're not unique in having that sort of feature. Perl is another example for different reasons."
414,What programming language or languages should I learn for this? Am I learning the wrong language?,"You can learn the basics of programming - loops, control structures, etc - in any language, and Python is a perfectly good place to start.  If you then want to know in depth about web applications, you'll need to learn JavaScript, because that's the language of client-side.  And if you want to know about electronics, you should learn at least the basics of at least one CPU's assembly language, and probably C as well.  And if you want to be seasoned enough to do OSINT across all types of projects, you'll also need basic knowledge of at least Java, C#, Golang and Rust.

Sorry if you thought you were climbing a hill and I've pointed to a mountain range, but there's no single language you can learn that will be applicable to all this different stuff."
415,What languages do I learn for a subset of this goal?,C and Python are good starting points for most of these.
416,Linear Algebra book for Machine Learning,Can you please post one chapter just for us to take a taste?
417,Final year project suggestions,You going to want to include parameters in a question like this so we can be helpful. What are the requirements for the project?
418,"I have a 10 hour recording from a camera. I need a program, that will show me a graph, which will answer this question: at what time did the camera record high volume audio?","Not really a computer science question

Not sure what program specifically, but what I would do is isolate the audio track from the video track and then open the audio in an editor that shows the waveform. Then it'll be really easy to see which parts are louder"
419,"Goldam Sachs vs Intuit Mailchimp: SWE Intern, please help!","You might get better feedback from /r/cscareerquestions - this isn't really a question about computer science

(imo, work-life balance is key, and working somewhere with a bad balance and culture sounds like hell)"
420,Can we use ratios for data compression?,"Doing this wouldn’t actually compress anything, because you would need sufficient precision in the ratio to encode all of the information of the data you are trying to store.

Files are already stored in an ultimately binary format, and this can be directly converted into a number. That means all our data are already technically ratios (with respect to 1)! But this doesn’t result in compression as it doesn’t change the data at all!"
421,definition of a PDA's transition relation?,"They are equivalent because you can use ε steps (where you do not read the input word further) to emulate adding/removing several symbols to the stack. 

In particular, you omitted that Sipser uses Γ_ε in his definition of the PDA transition function, meaning that you do not have to remove/add a symbol. Otherwise, the notion would not be equivalent."
422,CYCLIC ORDERING IS NP-COMPLETE,"If skimmed over the first two pages and can see how the proof is going. I've not read the proof details but I guess I could follow it, it seems to mostly define and exploit various cyclic orderings which seem fairly intuitive. I guess the hard part is figuring out the orders you need to build for each literal, and once you have them (which is of course what the paper contributes them) the verification is comparatively easy.

But I might be wrong, since again I only read page 1&2 and didn't know about this problem (and the background litrerature) before."
423,"A reference for the concept of ""dependent elimination""","Dependent elimination is (I think) when you have some index-inductive type (think the inductively defined vectors you mentioned) and match on an instance of this type. This case elimination will also give you information about the index arguments. For example, when matching on a `vec T n` where `n` is the length, you know that if the overall vector is `nil_vec`, then also `n=0`. Formally, the induction statement proves a property `P : forall (n:nat) (v:vec T n), Prop` for all possible `n` and `v`. It's called dependent elimination because `v` had a dependent type (depending on `n`) and by matching on `v` you also gain information about `n`. In Coq, the `depelim` tactic of the Equations package library is often used to do this since Coq's normal tactics are notoriously bad at this.


What you describe as dependent elimination is actually called large elimination. Perhaps you should look under this term."
424,I don't get it .10^24 - 10^23 comes from? Please and thanks in advance,"My thoughts are that this solution is ridiculous. 10^24 is so much bigger than 2, that subtracting them would do nothing to the 10^24. If we think in terms of order of magnitude, answer should be at least 10^24 iterations and at most 10^25."
425,Invalid BST help,"Suppose you have the tree:

      5
     / \
    4   6

Now you want to insert 3.  Where does it go?"
426,Does anyone have tips/guides/sources that touch on maximizing per CPU generation performance and DDR4 vs DDR5?,"I think such a guide would be difficult because of the high variability of workloads on CPUs, vs. the relative sameness of GPU/CUDA workloads."
427,I’m worried that the Computer Science classes for a BS degree are too advanced for my current level of understanding. Should I switch gears or stay the course and learn more foundational information on my own time.,"Part of the issue here isn't so much the level of advancement of the courses, but the focus of their content.  The IT courses you list are mostly focused on how to use tools that exist in the world - ie, it is computer-related vocational training.  Academic computer science, on the other hand, focuses on the theoretical foundations of computing.  The theory is math-heavy, but the vocational training is much less so.

So the question isn't really whether one or the other is more or less advanced for you.  The real question is, what do you want to do with this?  Which subject matter are you more interested in and why?"
428,How would you explain the terms Neural Network and Deep Learning to elementary school kids?,"Elementary kids…? I probably wouldn’t.

They have plenty of time later in life to learn. I would focus on human learning, pattern recognition, and then kind of just wave it all away saying, machines can do that too. Like, show them a bunch of blots, and ask them to categorize these into “cat” vs “not cat”. And then show them how you can do the same with a computer, and “teach” the computer this way to identify what a cat is.

Then I’d reinforce (hehe…) that that’s why it’s called machine LEARNING, and call it a day.

Be nice, playful, create the spark. The rest will come naturally later."
429,What are some recommended beginner Cloud Projects to Polish Ones Resume?,[deleted]
430,What is the step by step advice to learn spring framework. Also please suggest any good online course or tutorial tonleatn spring framework.,"This has nothing to do with Computer Science as a science. But here’s some links that may be of use.

https://spring.io/quickstart

https://lmgtfy.app/?q=java+spring+framework+tutorial

https://lmgtfy.app/?q=how+to+learn+how+to+learn"
431,does a math of comp major still have a good chance of becoming a swe?,[deleted]
432,Best way to host portfolio project,"Alright, I went with AWS and have it all up and running. Thanks for the info guys."
433,BFS approach to calculating sizes of connected components,"Two things come to mind:

First, it looks like you're creating a new component per point, which may not be the behavior you're looking for, if I understood the version of the problem you're solving.

Second, I suspect your use of data structures in the marking of visited points is dragging things down. If you have a list of input points, why use a set or dictionary of visited with the `in` operator? That's quite a bit more expensive than a list of bools of the same size as the input points. Anything that's doing dynamic allocation or lookups inside the loop is more expensive than preallocation or indexing. Even with a queue, and without taking advantage of the other cores (because I see no indication you are), this should definitely be faster than 4.5 seconds with a little modification.

Edit: I would also suggest recomputing square distances as an array and never touching square root. Also, if raw performance is what you need, many operations are vectorized in libraries like numpy (unless this is an exercise you're doing)"
434,Can my school see web downloads?,[deleted]
435,Does someone have an example of converting a number from base 64 to denary(base10)?,"Using the number, say, [33][12][55][8] in base 64, we can convert to base 10 as follows:

= 33×64^(3) + 12×64^(2) + 55×64^(1) + 8×64^(0)

= 8650752 + 49152 + 3520 + 8

= **8703432**."
436,Advice,yes
437,is math of computation a good major related to computer science if i want to be a software engineer?,">i noticed that cs majors are excluded from transfer programs for ucs

There are 9 UC campuses. According to the following page, transfers into the CS major have a pathway at all 9 campuses:

[https://admission.universityofcalifornia.edu/admission-requirements/transfer-requirements/uc-transfer-programs/transfer-pathways/computer-science.html](https://admission.universityofcalifornia.edu/admission-requirements/transfer-requirements/uc-transfer-programs/transfer-pathways/computer-science.html)

CS majors are excluded from most *Transfer Admission Guarantees* (TAGs), but they are certainly not excluded from applying as regular non-guaranteed transfers. About two thirds of transfers are *not* through the TAG program. If you do well at your community college and keep your grades up, then you can certainly apply for a transfer into the CS major. As you know though, UCLA and UCI are very competitive; you should have a backup plan.

BTW, UC schools are not the be-all end-all of higher education. I know plenty of smart people in the industry who went to CSU. In fact, I went to a CSU. I also went to a UC. I actually had a better experience at the CSU."
438,"I've written for years in Python, but, I've realize that a person can't produce software that can be run by normal people, because it has to be loaded in the Python Shell, is it a better idea to write it in C++, so that then people can just load it with a .exe?","You can absolutely write software for ""normal people"" in Python. Most of the Dropbox client is written in Python. You do need to wrap it to make a .exe or .app, but it's clearly possible, and abstracted from the end user"
439,Understanding integer to Floating point conversion,Why is your sign bit zero
440,should i be a psych major or computer science?,Imagine asking the internet what your future should look like
441,"Are the newest ipads good enough for software engineering, university beginner level?","An iPad is not a general purpose computer. The hardware is plenty fast enough, but you're going to have a very hard time finding the software to let you write and test code on one. There's no way to, for example, write Python scripts or compile C or Java and run that code. There's no command-line, no way to run anything except iOS apps, which can't be developed on an iPad."
442,Are all Operating systems that aren’t Windows or Mac “Flavors of Linux”?,There's a whole gaggle of operating systems that are none of the above. See e.g. [here](https://eylenburg.github.io/os_familytree.htm).
443,Which tasks would you prefer to automate with AI in the mobile development and DevOps process?,Nice try.
444,What CPU is suited for curve fitting?,"Quantum ML here: an i7 8700 isn’t *that* old. You can stretch your CPU resources by using vectorized algorithms and/or multi-threading. You may be able to run your code in half the time by modifying your implementation and save a lot of money.

Personally, I would add an Nvidia card so you can make use of CUDA acceleration. I’m not to sure how MATLAB handles GPU acceleration, but Python supports it through PyTorch, TensorFlow, and other packages. For computer vision, an 8GB RTX 2080 could barely keep up with my dark-field spectroscopy project (2 images / batch.)

Also, desktops will provide you better overall performance than laptops at the trade of convenience and portability."
445,what is a programming language and is GPT a kind of compiler for a new weird language?,"Fun game!

This feels like a ""is a hot dog a sandwich"" question, but I'll try to take it seriously.

Generally it's assumed that programming languages are well-specified, deterministic, and predictable. While languages might have some areas of undefined behavior, they're clearly documented so that programmers can avoid them at all costs.

So that's the first thing that comes to mind when I think about ChatGPT. Even with a temperature of 0 it doesn't always generate the same output for the same input. If it did, I think it'd be slightly more viable to consider it this way.

If it was deterministic, it still doesn't feel like a programming language to me. But it does feel a little bit like a (de)compression algorithm.

You could use it as a code comment, for example. Like instead of a long comment explaining why something works or a link to a url, you could give it a tiny compressed prompt that gets ChatGPT to output the explanation you want."
446,Looking for machine learning book recommendations,"you can check the Machine learning and Deep Learning related books in the following link

www.ijsmi.com/book.php"
447,Could this be how we consume our news media in the future?,"I don't think so, for the same reason we won't see AIs take over art:

People care about the fact that these things are made by humans. Even if you couldn't tell the difference when watching the video alone. A piece of art will have a different subjective value if it made by an AI. It's not dependent on the end result, but on the process. We are social animals and as long as we know there is not a person there we won't feel the same."
448,"If you save a file with a certain extension, sometimes it works and sometimes it doesn't. What happens when you save a file with an extension? What's the default behaviour?",[removed]
449,What to do after creating a new data structure?,"Put it through the ringer. Do something with it and show it off. Use this data structure in the most optimal way to do something that you can't do with other data structures.

What are its advantages and disadvantages? What is the complexity of this DS? Why would I use this over something that is simply a prefix+suffix tree that is separate under the hood? What is the best-case scenario of using this data structure?

Just brainstorming some questions for you to answer. I'm sure there are more considerations, but these are important in order to think about first in my opinion."
450,What are the books you wished you had read before you started CS?,"had it been available then, Where Wizards Stay Up Late would have been a useful way to understanding what was happening in networking."
451,Is the chinese company Netdragon AI CEO real or just a PR stunt?,"It's almost certainly a stunt, for many reasons. First, there's no suitable general artificial intelligence that could perform the leadership role of a CEO. If you used something like ChatGPT, you'd need humans both feeding information into the AI and engaging in prompt engineering to try to get it to produce useful output, and interpreting that output to direct the operations of the company. Additionally, AI can't enter into legal contracts. An ""AI CEO"" could have no legal, ethical, or fiduciary responsibilities - a government is unlikely to recognize a machine as an officer of a corporation for legal filing or taxation purposes."
452,What types of applications are you using the ChatGPT API to build?,"None. ChatGPT is an impressive chat bot, but it's extremely unreliable in almost any domain. Ask it to summarize a book, it often gets it kinda right, but sometimes it inserts nonexistent characters and imagines plot points. Ask it for a lit review, it cites non-existent papers. Ask it to categorize sentences into list of predefined categories, and sometimes it'll skip sentences, or make up its own categories and ignore the ones you've provided. Ask it for anything involving math, chemistry, or something more definitively correct or wrong, and it frequently falls flat on its face.

It's fun to play with, and maybe there's utility in using it for brainstorming or creative exercises, but ChatGPT doesn't ""understand"" anything, it's generating text responses that kind of seem right given prior similar text. Trying to wrap ChatGPT into an application and expecting any kind of reliable output seems like a recipe for failure."
453,efficient data structure for finding supersets,"Assuming you have dict and set types, use a `dict<int,set<*k>>`.

To do an `insert({1,3},ABC)`, store ABC somewhere you can get a pointer or reference to, or just append it as the last element in a data array and use the index, and add the pointer/reference/index to both of the sets `data[1]` and `data[3]`.  To do a `query({1,3})`, do a set intersection of `data[1]` and `data[3]` to get a set of pointers to elements whose key is a superset of `{1,3}`."
454,Can natural language be regularized to formalized meanings?,"Possible from a C.S. perspective, I guess theoretically with a comprehensive enough set of primitives to cover everything that a person might ever want to describe.  But I am skeptical that such a set exists, or if it does that it's not just as long and complicated as already existing languages.

Linguistically?  Hell no.  That's just straight up not how language works at all.  If such a thing existed, it would be a conlang that's used exclusively for philosophy and academics and nothing more.  Even if you somehow compelled every person in the world to speak in this way, it would take less than a week for the core principle to break down and dialects to start emerging."
455,What is your favourite definition of what an algorithm is?,"An algorithm is a set of well-defined instructions or steps that a computer or machine can follow to perform a specific task. It is essentially a recipe for solving a problem or completing a task, expressed in a way that a computer or machine can understand and execute.

Algorithms are used in a wide variety of applications, including computer programming, data analysis, machine learning, and artificial intelligence. They are used to solve problems such as sorting, searching, and optimization, and are often used to automate repetitive tasks.

Algorithms can be expressed in many different ways, including pseudocode, flowcharts, and programming languages. They can range from simple and straightforward to highly complex, depending on the problem they are designed to solve."
456,"Is searching files in a file system such a difficult task, or is windows just really bad at it? I remember that I never had trouble finding files years ago in older window versions, and now it often struggles to find file and just gives me web search results..","XP search was great, yeah. Windows file search has very much gone downhill. It's basically useless now. Try Everything from https://www.voidtools.com/

It works great and it's fast."
457,How would you design a reddit clone that is auditable against vote manipulation and empowers users to remove power tripping mods?,Did you just ask a question so you could answer it yourself? Lol
458,Any recommendation for Parallel programming course/book?,An Introduction to Parallel Programming - Peter Pacheco
459,Should I use polymorphism / Strategy pattern in my VMTranslator program? Request for advice on design.,"Polymorphism has fallen out of fashion, but yes, it can be a good option - _if_ you design your class structure cleanly, which is a bit of an art form."
460,Handwritten character identification,"You can do a fairly simple mediocre implementation with like a Naive Bayes classifier.

Implementing something like that to do character recognition for the numbers 0-9 is a fairly common school project, it may be harder/perform worse on Kanji or more complicated classification tasks"
461,Bypass school's proxy,"If your school's sysadmins are competent, they will have set up their network so that the router blocks all outgoing traffic *except* to the proxy server's address. From your perspective, that normally manifests as a ""timeout"" error, because your computer sends a ""connection request"" packet and never receives a response from the server at the other end, because the packet was dropped.

So ""bypassing"" the proxy, as you're trying to do, won't accomplish anything other than making your internet connection stop working.

(Obligatory reminder: ChatGPT is quite good at coming up with plausible-sounding answers that might be true, or might be complete bullshit. In particular, port 3128 is *commonly* used as a default by some HTTP proxy software, but that does not guarantee that 192.168.0.254 is actually the *correct* address for your network's proxy server.)"
462,"The concept of abstraction seems to be one of the most important aspects of CS. I know what it is and how to use it, but I can't manage to really pin it down and define it for myself. How would you define abstraction in the context of Computer Science?","I don't really need to worry about that shit, that's the system below me's problem.

I just got to keep on top of my own shit so it doesn't make problems for the system above me."
463,Access to sensitive data via guest account,"> With a guest account on the laptop, can a person knowledgable about computers find out, for example, any passwords saved in Google Chrome on the main account on the computer? 

Not unless you messed with filesystem permissions or your OS has some exploit that allows the guest account to escalate its priviliges. Browsers (and most software, for that matter) store their profile data in a directory that can usually only be accessed by the account owning it.

> A knowledgable person could probably get/copy all the data/files simply through the access to the hard drive, right?

Unless your hard disk is encrypted, anyone in physical possession of the laptop can get all the data on it. Either by removing the hard drive and putting it into another computer or by booting another OS from a USB drive."
464,"Making object instance variables public instead of having getters or setters is valid, but bad practice. What are major reasons and examples of said reasons?","It's a bad practice in languages like Java and C++ because whether a conceptual property is stored as a field or computed as a method then becomes visible at the callsite and part of the class's public API. That means that if you ever need to *change* that choice (like wrapping a field in a layer of caching), you'll have to update every single place in the program that's accessing the property.

It's less of a problem in C# because properties and fields have the same syntax but not the same compiled result, so it's a binary breaking change, but not a syntax-level breaking API change.

It's not a problem at all in languages like Dart, Python, Ruby, etc. where getters and fields are completely indistinguishable at the callsite."
465,How does Superhuman optimise for speed?,"Sending along [an article](https://blog.superhuman.com/superhuman-is-built-for-speed/#:~:text=While%20it%20uses%20the%20same,even%20when%20you're%20offline) from Superhuman that helps answer that question. Here's a snippet from what they say:   


""While it uses the same APIs, it also stores information locally and relies on caching to make sure it can display things quickly. For example, Superhuman keeps a database of your emails stored in your app or browser that can be displayed extremely quickly — even when you're offline."" 

And if you're looking for a fast email client, check out [Tatem](https://tatem.com/?utm_source=chelsea1&utm_medium=referral) \- I switched from Superhuman and have been loving the experience. It's equally fast with even more productivity tools"
466,How to determine if a number is closer to one of two peaks in a circular histogram from 0 to pi?,"One possibility would be to convert the angle representations to 2D unit vector representations and then use the dot product to judge similarity instead. The result that is closest to 1 gives your your answer.  
 
The conversion to 2D unit vectors would just be `<cos(theta), sin(theta)>` so it should be straightforward to implement."
467,What Should I do next after downloading Vscode?,You should really be looking at educational materials that teach the kind of programming you're looking to learn.
468,Merkle Tree Blockchain Question - How do we know Merkle Proof contains legit hashes?,"\> Wouldn't it be simple to just create a bunch of fake hashes that hash to the same root hash?

In short, no. Well structured hashing algorithms provide, among other things, these two properties.

1. Given only a particular hash, it is impossible to determine an input that creates that hash any quicker than just trying random inputs until one of them matches the hash output (called a ""hash collision"")
2. Given two different inputs of any kind, the output of the hash function for each of them will be indistinguishable from a random selection of the possible hash outputs. (So if you have 2\^256 possible hash outputs, a good hash algorithm will hash ""A"" and ""B"" to functionally random numbers between 1 and 2\^256)

This means that in chained hashes, you can't go from an end product to the initial values that created that end product, even if you have all intermediate hashes. You also can't construct a set of parallel inputs that match all of the hashes without bruteforcing inputs until you got ones that hashed to the values you were targeting and also (in this case) were ""better"" inputs for the attacker than the ones that initially went into this hash chain.

Hope this helps."
469,AI search algorithms,">How are AI search algorithms (for example, Breadth First Search) different from the standard ‘data structure’ algorithms?

I think you might be confused. Breadth-first search *is* a standard algorithm, there's nothing especially 'AI' about it.

That's not say AI techniques might not be leveraged to assist in search algorithms or improve the functionality of traditional data structures in some way, but I'm not really sure what you're getting at with your post."
470,How do I go from mathematical to realistic regular expressions?,"You need to be careful to distinguish between a couple of different kinds of ""extensions"" that you can make to regular expressions.

Some extensions do not actually increase the theoretical ""power"" of the class of languages, but merely make them more convenient to work with. For instance, inserting ""fake"" characters at word boundaries doesn't actually let you do anything you couldn't do otherwise. Example: in PCRE or JS syntax, a regex using word boundaries such as `\bfoo\b` could be translated to the equivalent expression `(^|\W)foo($|\W)`.

Similarly, extracting the positions of matching substrings or groups can be done merely by adding a little bit of bookkeeping to keep track of the character positions at which certain state transitions occur during the matching process.

On the other hand, some other features of regex engines like PCRE -- such as backreferences -- make the engine *strictly more powerful* than a true regular expression. That is, you can write a ""regex"" which does not actually correspond to a regular language, and can't be represented as a finite automaton. One simple example is the regex `(.*)\1`, which matches any string that contains two copies of the same substring concatenated together. This language is not regular, and in fact it's not even context-free.

So features like these can't necessarily be ""added on"" after the fact, because they constrain the kinds of algorithms you can use from the beginning. If you want to support features that allow non-regular or non-context-free languages, then you can't use an implementation that compiles to an NFA or CFG.

Instead, regex engines like PCRE typically use a backtracking approach. But this has its own downside, namely that the cost of finding a match can be *exponential* in the size of the input string. See: https://en.wikipedia.org/wiki/ReDoS

----

> What realistic regular expressions do not provide is the negation, even though negation is mathematically well defined for regular languages. I wonder why.

Well, PCRE *does* provide something very similar, namely ""negative lookahead assertions"". I'm not 100% sure whether these are *exactly* equivalent in power, i.e. whether it's possible to use them to negate arbitrary subexpressions of a regex.

On the other hand, the reason NFA-based regex implementations don't allow negation is probably that it can't (reliably) be done efficiently, because computing the complement of an NFA requires an exponential number of states in the worst case. That is, it's possible to write down a regex of size O(n) size such that the *minimal* possible NFA (EDIT: of its complement) has 2^n different states."
471,I am You when you were first starting out...,"I started before computers were a significant part of ordinary people's lives.  My dad was a computer programmer and decided to start building a hobbyist machine.  He somehow acquired a surplus RS-232 video display terminal.  We didn't have a computer yet, but the terminal had a local mode where you could use cursor keys to move around, and type letters that would stay on the screen.  I spent days just drawing pictures on the screen, knowing they would disappear when it was powered off.  Seeing my interest, he brought home a TI Silent 700 printing terminal, and taught me how to write and run simple programs in BASIC.  I've been hooked ever since.

When the early home computers arrived, it was not only possible but necessary to know everything about them - what every single wire or byte did, throughout the whole machine.  There were none of these distinctions between front-end and back-end, and barely even between hardware and software, really.  You just learned the machine.

I went to college and learned the theory behind the machines, got a job programming the machines, and I've been doing it ever since.  Essentially all the technologies we now use popped up after I was already working in the field.  So I don't really have a good perspective on what it's like for someone new trying to enter the field today.

As to what you're trying to do, it sounds like 90% of the complexity is with how you display the information to the user.  So you should probably focus mostly on front-end - HTML/CSS/JS and probably React.  The database sounds like a single table with a record per timeline event.  So you don't really need to know a lot of database theory or algorithms to achieve this."
472,What are some things I can do with spare processing power that isn’t crypto mining?,.
473,Job outlook for someone with an associate’s degree in Computer Science,"> Are there any companies that hire those with only an associate’s degree? Any information is helpful!

Sadly, the job market is definitely going through a rough patch right now. Your boyfriend will have a tough time landing his first role, that's normal and not a reflection on him at all.

That said, employers *do* hire Associate's degree grads for junior positions. The listed requirements for various jobs in tech are... often optional. They're usually less concerned with the specifics that they've actually listed, and more concerned with your problem-solving skills that aren't easy to measure.

Your boyfriend will want to build a portfolio showcasing his development skills. He would also do well to learn a modern language/framework that he wants to work in (and that companies are hiring for) instead of just using whatever he's learned in college. Modern devs need to use multiple languages on a regular basis.

Consider setting up a personal website (basically a pretty resume) built on something like React JS. Have it hosted on a cloud provider like AWS. Find an excuse to use a SQL-based database (I'd recommend MySQL or PostgreSQL for maximum employability with minimal cost). Host the source code on GitHub.

Why? Being able to put these keywords on his resume will improve the odds that his resume will actually get considered.

I can give better advice if I know more about your boyfriend's experience and goals. What kinds of languages and frameworks has he used? What kind of software engineering is he interested in pursuing (e.g. Front-End Web Dev, Back-End Web Dev, Mobile Dev, Game Dev, Embedded systems engineer, Data engineer, DevOps/SRE, Test Automation Engineer (SDET), Cloud architect, Database admin (DBA), cybersecurity specialist)?

Lastly: have him make a free account on leetcode.com and do the problem of the day every day. If he can get good at that, he'll be well-prepared for job interviews."
474,I have some questions on what are called windows in Windows.,"1. I think the term you are looking for is a WIMP interface (Windows, Icons, Menus, Pointer)
2. No, the Xerox Alto was the first computer with a WIMP interface in 1973, and then Apple released the Lisa in 1983 and the Macintosh in 1984 before Windows 1.0 was released in 1985.
3. A WIMP interface generally requires multitasking (although there have been a few without - if I remember right, the early Acorn Archimedes in 1988 had a WIMP interface but no multitasking. A process in a window would freeze when focus switched to another window.)  
The computer is running several processes and dividing its time between them. It's not really virtualization, though - a process is not a full virtual machine.
4. All distributions of Linux can be used just through a text interface without a graphical windows manager (and often are on servers, for example)."
475,"I don't quite get 2-step compilation and the role of a VM in it. The VM serves like an adapter so that it can run on different hardware configurations, but how does it work?","Think of Java bytecode as if it was a Python script. You can run Python scripts (more or less) on any machine that has Python installed. The JVM does something along the same lines, but with a binary representation of the program instead of a text representation. The difference is that by compiling the text representation into bytecode before executing it, you have less work to do at runtime, so you generally get better performance.

And same as Python, the JVM ""knows"" how to turn bytecode into instructions for the underlying hardware because it is written in a compiled language and then compiled for the architecture and OS it runs on, like any other program compiled directly into machine code.

It is called virtual machine, because it provides an instruction set like a CPU would have, but it's implemented in software."
476,How much storage space would you need to write out every number 0 to 1 trillion?,"Is this a homework problem?

Hint: in your sequence, there are 10 1-digit numbers, 90 2-digit numbers, 900 3-digit numbers, 9000 4-digit numbers, and so on. Do you see the pattern?"
477,Does anybody else find AI content detectors to be really sketchy and misleading?,"These ""AI detectors"" work by looking for high ""perplexity,"" which is the presence of relative randomness in the text, in some relevant sense.  What I've found is that ""perplexity"" is strongly negatively correlated with clarity.  If you feed in some typical freshman English crap, they'll say it likely wasn't written by an AI, because it's confused rambling nonsense.  If you feed in an Isaac Asimov science article, it's going to say an AI wrote it, because Asimov is (famously) able to write clear, coherent articles based on the organized thoughts of a powerful mind.

The ability to write well is less common than it used to be, but I certainly hope we aren't headed for a future where we not only tolerate, but actually _require_ students to write badly, in order to get past the AI detector. 

There's also a difference between using AI as a super-advanced version of the Microsoft Word grammar checker, and using it to actually provide the content of the assignment.  The latter is plagiarism (or at least some form of cheating); the former is not.  But the AI detector tools seem to be mostly targeting the former."
478,My Questions about the hex table,"\>Why do you want to see the ASCII version of each hex row?

If it's an image file, you probably don't. You just happen to be using a tool that shows you ASCII characters.

\>You noticed this hex file is corrupted. How did you detect it? 

Perhaps you tried to load it into an image viewer? Otherwise, you performed some calculation on some of the values in the file and you got an unexpected result. What calculations and what values in the file you looked at are specific to the file format you have."
479,Should I pursue Computer Science even though my problem-solving skills are terrible?,"I would look at alternatives.   

I have known good programmers who are bad at math.   I have never met a good programmer who was bad at problem solving.  In my opinion, it is a defining characteristic of a good programmer.    I have met programmers who are bad problem solvers, and they wash out quick, because they constantly feel overwhelmed because everything is a mountain they can't climb, instead of a new mountain to climb."
480,What are some evergreen articles on programming languages and computing in general?,The Dangers Of Computer-Science paper mentioned at the beginning can be found here: https://gwern.net/doc/math/1973-knuth.pdf
481,"Any suggestions for detailed reading, tutorials, or good documentation on filesystem design in general?",Check out [Practical File System Design](http://www.nobius.org/dbg/practical-file-system-design.pdf)
482,"Why are there only 3 main computing platforms (Windows-PC, Mac and Linux-PC?)","I would guess that the main reason is software. Nowadays, there's a lot of different software, and most software only exists for the major operating systems.

If you launch a new OS, existing software won't run on it. Nobody will buy your OS because it doesn't support the software people want to use. No company will release software for your OS because nobody uses it, so nobody will buy that software.

New platforms only emerge if there's a specific niche (gaming consoles) or a new kind of device for which existing OS's aren't optimised (smart phones, tablet PCs). In both cases your hardware has some features which normal PCs don't have. Gaming consoles are optimised for gaming where you would otherwise need a fairly high-end PC. Smart phones are small and portable and rely on a battery.

If you have any special requirements, a standard PC with a standard OS does the job just fine. If you need to use a lot of different special software, a standard OS will be the only one supporting all of that software."
483,"Novice to research, how to find if the work has previously been done ?","This is a common way to find out. It would also help if you know other people in the field with more experience who might know. You can also explicitly look for survey papers in your domain - these are papers written to summarize existing work, so a good survey published by someone like IEEE should identify if your idea has been done before.

That said, even if something similar has been done, your particular take may be new."
484,Any recommendations for learning compiler efficient programming?,"[Godbolt is your friend.](https://godbolt.org/)

The biggest place that humans can make an impact is in terms of memory layout. If your data access isn’t efficient, it’s hard for a compiler to clean it up for you. This sort of thinking extends even more to so disk access and networking. If you are querying the other side of the planet in a loop, batching the request might speed things up a lot. 

Depending on what sort of problems you are trying to solve, taking advantage of SIMD hardware can make a huge difference. Compilers can definitely generate SIMD instructions by unrolling loops (Godbolt is great for inspecting this), but there are often strategies that are available to the human programmer that the compiler can’t know about. For example, the loop is written for any size of data, but you know that the loop only handles two sizes 90% of the time, so you hardcode a super-efficient implementation of those sizes and branch to one of those or the general case at run time."
485,Would proving that an NP problem can't be solved in polynomial time also prove that P=/=NP?,"Yes, this would be a sufficient proof.  The difficulty is that the proof would require you to say that for a given problem, no future researcher can ever possibly find a better algorithm.  This is more difficult than just showing the complexity bounds of a given algorithm, or that one algorithm reduces to another."
486,Why is DNS called DNS and not HNS?,"DNS has many resource records (RR's), not just A records. One very pertinent one is the SOA record (Start of Authority) which is where a higher level in the DNS tree delegates that subtree. Typically (but not exclusively), that is at what we think of as a domain\*. That is com. delegates authority to [example.com](https://example.com) to be the authority of that subdomain. it gives it complete control of what the resource records, subdomains, etc are comprised of. DNS is about structuring who has the authority so that it can be distributed. A records (ipv4 addresses) are just one of many things that can be served up including MX records for mail, TXT records which are also used for authentication technology like SPF and DKIM, CNAME records to make aliases, and importantly NS records which says what the name of the authoritative name server is.

\[\*\] i think technically any SOA is a domain cut, but am not positive"
487,A star algorithm with negative weights,"Here is a discussion of this exact question: https://stackoverflow.com/questions/5197523/does-a-work-with-negative-weights-as-long-that-the-heuristic-is-admissible

A* will work *if* your heuristic function is admissible, which may mean that your heuristic needs to take negative values.

For example, A* reduces to Dijkstra's algorithm if you use the trivial heuristic that always returns zero, but if your graph has negative costs, this heuristic isn't admissible."
488,Why do social media apps load the first 3 seconds of the 10+ next videos instead of loading the current video in it’s entirety?,"They're probably doing whatever A/B testing has told them maximizes viewer engagement and ad revenue. And it *still* might be the case that even for lower-bandwidth users, or they potentially have decided that investing developers' time isn't worthwhile to heavily consider lower-bandwidth users.

The app is also probably taking advantage of the fact that they can know what videos you will receive in your feed ahead of time, and pre-loading them while you're either higher-up in the feed or doing something else, whereas they might not know with any amount of certainty which video you might want to watch *in full*, so they need to start loading it from scratch when you choose it, but not before."
489,definition of parse tree of a CFG,"It does not say that ""a valid parse tree is any terminal."" It says that ""any terminal is a valid parse tree."" Those are very different things, and the latter simply forms the base for the inductive definition. It doesn't make sense without the induction part though!

For the derivation the '\*"" means the derivation can be zero or more steps.  Including zero."
490,EHTERNET FRAME question,"When a router receives an Ethernet frame, it will remove the original Ethernet header and replace it with its own Ethernet header, which includes its own MAC address as the source address. This process is called ""MAC address rewriting,"" and it is necessary for the router to forward the frame to the next hop in the network.

  
However, the original IP packet inside the Ethernet frame remains intact. The router examines the IP packet's destination address and performs a lookup in its routing table to determine the next hop for the packet. If the next hop is a directly connected network, the router will update the destination MAC address in the new Ethernet header to the MAC address of the next hop and forward the frame out of the appropriate interface.

  
When the packet reaches its final destination, the receiving device will examine the IP header's source address to determine where the packet originated from. The receiving device will then use the source IP address to send a reply message back to the original sender. The Ethernet header will be updated again by the router as the reply packet is forwarded back to the original sender, with the router's MAC address as the source address and the next hop's MAC address as the destination address. This process repeats until the reply packet reaches the original sender."
491,Are there any language implementations on a Universal Turing Machine?,"Are you talking about something like this?
https://github.com/felko/bfpy"
492,"Analog computing growing popularity, how do I get into it?","They really were popular in the predigital era. All of the gunnery targeting systems in WW2 were analog.  Vannevar Bush did a lot of work with them. 

They are not commonly used these days. 

Maybe you might be interested in “Numerical Methods” which is how it’s done now for the most part.

If you’re more interested in their applications, you might study control systems."
493,"Total beginner in CompSci: How does Bitcoin work, and why do so many sites on the dark web use it?","It's not anonymous, it's *pseudo*nymous.  There are private blockchains but they rely on fairly advanced cryptography like zero-knowledge proofs that assert the validity of a transaction without revealing anything about it."
494,Python vs R for data-science whats the difference?,https://www.dataquest.io/blog/python-vs-r/ Really depends.
495,Why is it so difficult for compilers to implement static collection declarations?,"I don't believe there's any particular difficulty to static initializers in general.  But the more syntax you try to cram into a language, the harder it is to avoid parser ambiguities and undefined corner cases.  So languages tend not to do things unless they feel they really need to, and complex static initializers aren't generally seen as a crucial feature for a language."
496,Math in Computer Science,"For your first computer science class or two, algebra will be fine. Advanced computer science topics often use more advanced math - but that's why you'll be taking math classes alongside your CS courses."
497,Is there a reason why volatile computer memories are faster and more expensive?,"there isn't a reason per se. it's just that DRAM uses capacitors which leak and need to be refreshed. they are using caps because of density and most likely speed too. if they didn't leak that would have been great too, but they do."
498,Any ideas for a Computer Science Bachelor Thesis?,"You can't think of _anything_ in games that'd make a good thesis topic? Procedural generation of levels and environments, any aspect of AI, anything about graphics, adaptation to player behavior, new interface design in augmented or virtual reality, network programming techniques for rollback, anti-cheat approaches? Pick a sub-area in games that interests you, pick a sub-problem in that area to study, you'll have a thesis topic pretty quick. Or pick something in electronics or machine learning - just as wide a vein of topics there."
499,Is it the processor or the RAM that is more important for a lagless user experience on a PC?,yes. but if you're gaming online it's the latency that's probably the biggest deal.
500,Git/Github tutorial focused with Visual Studio??,"Git and GitHub don't really have anything to do with Visual Studio. I know VS has git integration, but I'd recommend you learn about version control and software repositories independently from your specific IDE"
501,Tech Company in Canada,You want /r/cscareerquestions.  This subreddit is for theoretical computer science.
502,Is it okay to use chat GPT to my project?,"If it was a homework assignment, I'd say, check your school's policy on AI assistance. If not, then the main thing is to make sure you still learn from what it suggests. To me, as long as it's a personal project, it's essentially like googling a problem and pasting an answer from stackoverflow. 

You just have to remember that it's doing next word prediction rather than solving your problem directly so the response may not be correct or the best way to do it. But if it helps you then I think the main thing is to make sure you understand how its answer solves your issue."
503,Goldman Sachs vs. JPMC as a SWE,">The pay offered is 60% more than what I am getting at Goldman

Then it 100% makes sense to take it. Getting a 60% pay bump early in your career is the difference between retiring at 45 vs. 60. Bank the money into investments, and then leverage the high salary for even higher salaries later in your career."
504,This website is hard to search. What can I use to search it easier?,Google search for `site:company-information.service.gov.uk harrods`
505,Application of Divide & Conquer Approach?,"Interesting question!

Am I correct in assuming that the problem is to find a partition satisfying those requirements *if one exists*? For instance, it's easy to construct a set of points that are all comparable to each other, and therefore no such partitioning exists if r < n.

Anyway, I think the answer to your question is yes. This is basically a graph coloring problem, where you have r colors, and two points are connected by an edge iff they're comparable. Apparently, there's a theorem that [any comparability graph is can be optimally colored by a greedy algorithm that considers vertices in topological order.](https://en.wikipedia.org/wiki/Comparability_graph) And I think you can construct such a topological ordering using divide-and-conquer. 

(Hint: in the 2D case, choose a point and use it to divide the plane into four quadrants. What can you say about the relative ordering of points in those quadrants?)"
506,Me and my friends wrote the data base for our college Moodle where professors can post materials for students to study. The students were given ID's to login. is this vulnerable to SQL injection? if yes how can we prevent it?,"Any user-supplied text that is going to be used in an SQL statement needs to be ""sanitized"". This means that it should be run through an algorithm designed to replace any SQL control characters (such as quotation marks) with ""escaped"" versions that get interpreted as part of the data rather than as part of the rest of the query.

The two main approaches to that are to either use an ORM (such as ActiveRecord in Rails) to construct your query, or to use a sanitization function on the data that you include in a SQL string.

- [Explanation for Python](https://realpython.com/prevent-python-sql-injection/)
- [Explanation for node](https://planetscale.com/blog/how-to-prevent-sql-injection-attacks-in-node-js)"
507,Looking for advice. Going back to school and have it narrowed down to 2 different programs. Full Stack engineer or Network security. Which field do you think has the most opportunity in your opinion.,"> Which field do you think has the most opportunity

You are asking the wrong question.

Both fields have plenty of opportunity -- in either one you won't find yourself unable to find a job because there are no jobs to be had.

But the experience of working in these two fields is quite a bit different. As a full stack engineer you will be expected to BUILD things. You will be given tight deadlines and insufficient documentation and will be expected to make rapid progress. You will feel a sense of ownership in the things you create.

In Network Security you will become a cop. You will learn a huge amount about a particular arcane topic, then you will spend your time defining policies, checking systems for compliance with those policies, and trying over and over to get people who don't care about security to follow some really important rules. Your days will be more about people than code. (At least for most roles.)

I bring this up because it is likely you will be better suited for one of these roles than the other. You will enjoy one more and thus be better at it. And while I claimed you won't find yourself unable to find a job because there are no jobs to be had, you WILL find it hard to get the job you want because you aren't good enough at it. Select the career you will enjoy and you will be better off for it."
508,Linear regression,"If your data is noisy, or you want to exclude outliers or you just want speed, try RANSAC.  
https://en.wikipedia.org/wiki/Random\_sample\_consensus"
509,Advice needed: pursuing CS research or taking a data handling opportunity at a prestigious lab for grad school?,"It's not really clear what your goals are. You mention CS research, applying for SWE internships, and looking to pursue a Masters. Those are three different paths that don't necessarily have a common end state.

Research is both the easy and the hard answer. The easy part is that you need a PhD. That requirement is a pretty hard line, so if that's the goal, your path is to figure out how to get into a PhD program. A Masters can be a stepping stone to a PhD, but most people are better off going directly to the PhD admissions step, and then getting a Masters along the way if that's something they want to do. And that's the hard part of the answer. Admission into a top ML program today is unbelievably competitive. If you don't have NeurIPS papers from your undergrad, you're behind, and behind far enough you probably have no chance. You can aim lower in the rankings, or you can start with a Masters and try to beef up your research presence, but really, it's a bit like telling someone they should be an NBA basketball player. It's a fantastic career for the very small number of people who can get it, but Lebron James was on the cover of Sports Illustrated when he was like 14, and the rest of us who weren't probably aren't getting the job over him.

The Masters itself is probably pretty attainable. Masters programs tend to be money makers for universities. Students generally pay full tuition, so if you're on paper able to succeed, they'll probably admit you. You'll probably learn a lot, and you'll have the opportunity to specialize a bit more in a topic like ML. Both of those things are good, and they can make you more marketable on the other side. However, skipping the Masters and just getting a job will let you spend those couple of years getting professional experience, and in general, the experience is more valuable than the Masters. If you got a job making $75k with a BS, in two years, you've made $150k, gotten a raise or two and maybe a promotion, started a 401k, and added valuable content to your resume. If you get a Masters instead, you might start at a higher salary than $75k, but you'll likely never make up the two years of income you skipped to get it.

And the Masters still doesn't get you a research job. It might get you a job working adjacent to research as something like a Machine Learning Engineer where you're helping to build production-ready implementations of models that came from the scientists on the team you're working with. though That's the kind of job where it's not uncommon to see a MS as a requirement. The lab job may also have some benefits here though in that it's directly relevant experience working in a support setting for a research organization.

Most jobs aren't that though. If you're aiming for a future as a software engineer, the lab job is probably the most direct path to getting there. Experience generally trumps education for most hiring managers. If you're passionate about machine learning though, I don't think the MS is so much worse that I'd worry about it. If you can fund the MS without too much hardship and that's what you want to do, it's not like that's a bad decision. It's probably slightly financially worse than just starting a job somewhere, but it can be a good decision to do something slightly financially worse if it has other benefits like your enjoyment. Only you can really weigh those options well."
510,What is the difference between downloading and installing a file?,"*Downloading* means transfering a file from some server out there to your own device. Once you've downloaded a file, you have a copy of it.

*Installing* an app means setting it up so that your system can run it. It needs to be stored in the right location. Your system needs to know where it is and what it is, it needs to have the proper access permissions, and if there is some list of runnable apps, then it needs to be added to that list. Any required auxiliary data files also need to be in the proper locations. Once you've installed an app, you can run it."
511,I am a little confused. What is new about edge computing?,"Nothing.

The pendulum swings back and forth between centralized vs decentralized computing every few years."
512,ChatGPT ?,Mostly hype.
513,Battleship AI without knowing about sunk ships?,"Just spitballing here but I think Battleship is probably a good candidate for move evaluation like Chess. If your battleship board is small and the number of ships is small as well, you wouldn’t even need alpha beta pruning. You could just write an evaluation function, process all possible game states and eliminate game states accordingly. With games where the number of possible states are relatively low it should be trivial enough (for calculation not necessarily implementing the actual AI). I don’t think there’s any way to “know” beyond eliminating impossible configurations based on current game states

Edit: one thing you could maybe exploit is if your opponents choose which ships have been sunk based on length. If they do something rudimentary like assume a 7 length battleship is downed due to 7 consecutive squares being hit, they might miss that it was actually a 5 and 3 on a single row or column."
514,Theory of Computation vs Design and Analysis of Algo,"I'm not really sure what design and analysis of algo is, but if it's an algorithms class that covers topics such as dynamic programming, greedy algorithms, network flow, etc, I'd expect it to be a prereq for theory of computation. If it isn't officially, I'd highly recommend you take it before theory of computation. Both classes are on MIT OCW, and I'd suggest you take a look at both. I'd say both classes aren't super useful in day to day software engineering, especially if you're dealing with embedded stuff."
515,MS in Computer Science or Software Engineering,"To my knowledge, there's no standard curriculum required for accreditation of a software engineering degree.  It could be CS but with less math, or it could be genuinely about software engineering, i.e. design patterns and how to get high performance out of software development teams.  You'll need to look closely at the specific degree you're considering.

Also note that software engineering and computer engineering are very different.  Computer engineering is basically electrical engineering with a focus on computing devices.  It prepares you to design and build computer hardware."
516,WHAT MACHINE SUBNETS?,"At a high level, the subnet configuration goes into the same device that provides the DHCP service, since there is obviously a lot of overlap between assigning IP addresses to devices and splitting devices into different subnets. Practically, this means a router, managed switch or dedicated DHCP server.

But subnetting is also more than DHCP, in fact if you think about it it's also ingrained in the physical network topology. So it could be true to say the subnetting is also implemented in which devices are connected to which ports on a gateway.

Then you have details like, multiple routers and managed switches on the network enforcing subnets, eg. with VLAN IDs.

Typically the point of a subnet is to isolate networks at the gateway level based on MAC address and/or Ethernet interface, you shouldn't be able to specify the subnet in the client device and let it connect to any subnet it likes."
517,Quick question in regards to open data formats,"> However I can’t find any disadvantage a business, school or other operation, would have for open file formats rather than the (albeit) proprietary Microsoft ones, so why do we still flock to Microsoft and their monopoly on open file formats?

Market saturation. Enough people already have Microsoft Office and such that if you want to exchange documents with them, you have to use Microsoft Office yourself or they tell you to get stuffed/you can't read the files they send you. So now that you have Microsoft Office to work with other people, using a second solution for other stuff would just make things more complicated, so you keep using MS Office."
518,HOW O CONNECT .NET(C#) APP TO MONGODB USING PYTHON FOR .NET,PS( AM USING LINUX
519,Would augmenting the human brain with computers accomplish anything?,"Your question is poorly formed. Augmenting in what way?

Are there theoretically ways to augment the human brain with computerized systems that can provide new functionality or enhance existing capabilities? Yes. And some of them are shockingly pedestrian: https://www.wired.com/2007/04/esp/

In these cases, you can augment the brain (or mind if you're a dualist freak like me) with computerized systems without even tampering with it directly."
520,What are the best AI tools like ChatGPT to improve English speaking skills?,"Im not sure if this is the best sub reddit to find an answer for your question. If you don’t receive it here, try asking at r/nostupidquestions"
521,What's the best way to identify the number of rooms in a house from pictures?,"You can use Meshroom to stitch multiple images into a three-dimensional model of the space. Then, you can count the rooms in that model."
522,How will we continue to get high quality datasets to train language models as their results enter the public domain?,"This is well beyond me and I am completely talking out my rear, but your question makes me wonder if we may see human language drift towards whatever biases exist in AI language models if the general public consumes enough AI generated content. Almost like picking up new slang."
523,Does mrROUTER do the subnetting?,"I don't know what you mean by ""mrROUTER"".

> Like- where PHYSICALLY are the 1's and 0's when, lets say, i add a subnet digit and /16 becomes /17? Where do they live? The router?

The subnet is a property of the *configuration* of the router and all other devices on the same local network. You can think of it kind of like a wildcard. If your home network is configured to use the 192.168.0.0/24 subnet, all that means is that it treats addresses like 192.168.0.* as internal addresses, and others as external.

(And in turn, the router passes this configuration to other devices on the network when they use the DHCP protocol to request IP addresses.)

The subnet is not actually included in packets, because it's assumed that all of the routers that are handling packets ""on behalf of"" a particular subnet are properly configured with the correct subnet mask.

> The router gets your ipADDRESS from the ISP, then presumably it would subnet it, and I could go in there and create further subnets and eat more host bits.

Unless you have an expensive business connection, typically all you get with IPv4 is a *single* publicly-routable IP address, i.e. a /32. You can't subdivide this any further.

Your internal network is not a subnet of your public address. Instead, it's a separate *private* network whose addresses are never used in internet traffic. One of the router's jobs is to perform [network address translation](https://en.wikipedia.org/wiki/Network_address_translation), so that outgoing packets get translated from an internal address to the public address, and vice versa for incoming packets.

(With IPv6, this gets a bit messier. Many consumer ISPs provide customers with a /64 subnet, which has 2^64 publicly-routable addresses. This makes NAT unnecessary, but since a /64 is the smallest valid IPv6 network size, you can't subnet it any further. I've heard that some ISPs will give out larger subnets if you ask nicely.)

> why would it need it's own ipADDRESS to identify it to the router when it's already physically part of the router?

The router's internal IP address doesn't ""identify it to the router"". It's used by *other* devices on the same local network segment to send packets to the router.

If your internal network is 192.168.0.0/24, and your router's internal address is 192.168.0.1, then every device on your network needs to be set up to use 192.168.0.1 as a *gateway* to access other IP addresses somewhere on the internet. And this gateway address is reachable because it's on the same network segment.

Therefore, the router needs to have an internal IP address which it ""recognizes"" as its own, and which other devices on the local network can use to communicate with it.

If you tried to use an external address as a gateway, then this wouldn't work: every externally-addressed packet would be forwarded to the gateway, but since the gateway is also an external address, the system wouldn't know where to forward it (unless you manually override the routing table)."
524,Additional Material to CLRS Book on Algorithms?,Abdul Bari on YouTube got me through my school’s Algorithms (based on CLRS) course
525,How do you go about putting content on and programming an HDMI stick?,"[If you want to install a custom ROM on your anycast device, you might need to find a compatible zip file for your device model and follow some steps similar to installing a custom ROM on an Android phone](https://www.xda-developers.com/how-to-install-custom-rom-android/) - Bing chat"
526,Looking for resources on one-way hash functions,"Strictly speaking, we don't *know* that hash functions are difficult to reverse, in the sense of having a rigorous mathematical proof. What we have are hash functions which are *believed* to be strong, in the sense that they're believed to be resistant to all of the publicly-known attack methods. 

For instance, they're designed to exhibit an [avalanche effect](https://en.wikipedia.org/wiki/Avalanche_effect), which means a very small change to the input should result in a completely different output. And they're designed to be highly non-linear, so that the same kind of change to different inputs has very different results. (Non-cryptographically-secure hash functions, such as CRC32, typically don't have these properties and are much easier to invert.)

The specific properties that are desirable for a cryptographic hash function are [mentioned here](https://en.wikipedia.org/wiki/Cryptographic_hash_function): ""pre-image resistance"", ""second pre-image resistance"", and ""collision resistance"". But those are just descriptions, not proofs. Many other cryptographic security properties are derived from these, e.g. ""protocol X is secure under the assumption that the underlying hash function is collision resistant"".

In fact, this is a deeper question than you might realize, because it's related to the famous [P vs. NP problem.](https://en.wikipedia.org/wiki/P_versus_NP_problem) If P=NP, then in a certain sense, strong hash functions *can't exist*, because any polynomial-time function would be invertible in polynomial time. So conversely, if you could formally prove that a particular family of hash functions is pre-image resistant, then you would have proven P!=NP."
527,why so much RAM?,"This isn't a computer science question.

You'll need to dig into how that memory is being used. (`free -m`) Unused memory doesn't do you any good, so many operating systems, filesystems and applications will cache data in memory and release it when other applications need memory."
528,Lang based on Computability Logic? What might this look like?,See also: Universal Turing Machine
529,How do I programmatically cause a hard drive to make read/write noises?,"You could get a real drive to do a bunch of access noises by traversing the filesystem. Just `os.walk`, traversing down into all the directories, maybe grabbing the attributes of files along the way, or something."
530,In a cache memory is the dirty bit set after a cache write hit?,If the block is hit but it is modified in the cache then the dirty bit is set.
531,Undecidable problems,"Try adapting the problem to a simple, straight forward version of it (sort of a template problem), then try reducing that"
532,In a cache memory is the valid bit ever reset or is it only set when the cache block is accessed for the first time then never reset until a reboot?,"The bit will often reset to invalid during the normal course of write operations, which change the data and require updating caching layers.

Reusing some cache space to target a different block of data would also involve invalidating the cache portion targeting another block of data. (Not knowledgeable about caches in deep enough detail to say whether the brief invalid state is witnessable versus part of a larger atomic operation.)

Cleaning up resources, such as terminating a program, may trigger cache invalidation. The CPU cache(s) track RAM data, and the program may or may not no continue to be cached in RAM at that point. The program instructions are themselves data, and involve the (I-)cache, with similar semantics. Eventually, the program leaves the RAM cache, and may or may not reside in disk cache."
533,What writes the EtherType field?,Please add context.
534,How exactly does machine learning software generate images?,"A typical example of the kind of machine learning model used to generate images would be a form of neural network called a Generative Adversarial Network (GAN). The GAN consists of a Generator, a Discriminator, and a set of training images. The Generator generates randomized output that can be tuned to follow a learned set of patterns.

To train a GAN you can assemble a set of training images that you want it to learn from (say, a bunch of cat pictures). The Generator then generates a randomized image, but because it hasn't been tuned yet, the image is basically white noise. The Discriminator compares the white noise image from the generator to the first training image and aims to distinguish which is the generated image and which is the training image. The Discriminator will give feedback to the Generator on its accuracy, which is then used to update the neural network parameters. Then you generate another image, this one should be a bit better than random noise, and the Discriminator compares it to the next training image, aims to discern which is which, and gives more feedback to the Generator on its accuracy, which further tunes the Generator network. This is repeated over and over for the training image set with the goal that the Discriminator will eventually be unable to determine which is the training image and which came from the Generator.

When training is complete, the Generator neural network has been tuned so that it has essentially learned the common patterns that go into images of cats and can produce a randomly sampled version of those patterns, which when you look at them, look like pictures of cats. So it's not just mashing together existing images, but learning the patterns that make those images what they are, and then generates new images that follow those patterns (e.g. four legs, a tail, fur, 2 ears etc). It's the probabilistic element of the generation that allows it to produce images that are new, and the learning of the patterns that would allow it to learn patterns for more than one type of image and combine them."
535,Help me,You tell me. Where'd you get the name from? I haven't heard of an OS by that name.
536,SLACK,"Consider setting up a public Slack team for networking.

Seeking Scrum Master roles."
537,"Is your computer science job fun? If so, what is it that you do? Why do you like it?","Currently I’m a web dev at a fairly large engineering company. I really do love it, I’ve learned SQL, C#, Asp Net and so much more!"
538,time complexity question,"You have a few misconceptions here. The function you described is actually just O(1), as it being bounded by a constant for an infinite amount of values, while being O(n) for a finite amount of values (this doesn't actually make much sense, because asymptotic notation is about functions, not values) means it has a maximum value, and is thus bounded by a constant: the maximum value. 

Second, theta does NOT mean average case, or average anything for that matter. f(n) = \Theta (g(n)) means f is bounded both above and below by g."
539,How hard is lsa cs program for a incoming freshman with no coding experience?,Read computer science books from your local library and practice the exercises.
540,"how do I get an open source projects? and i only have knowledge of C/C++, SQLite, socket programming, java(core), Layer programming, MySQL",What are you asking?
541,Relational Algebra,Do. Your. Own. Homework.
542,Do you really need math to be able to code?,"Like always, depends....

No. You may not need it at all like ever.

But the experimental/research level stuff you definitely need it. It will be required.

you may need it for problem solving in occasions.

But what I realized is when you need it, you really need it. And despite what people say, lot of math is hard to just pick up unless you have a good foundation or mathematical maturity. 

But also you may never use it in your life time. Depends on the field."
543,Which of the following properties must be true of a Minimum Spanning Tree (MST) of a connected graph G with at least 3 edges?,"You are just misunderstanding what is meant by 'the second shortest edge.' You are interpreting it to mean ""The second shortest *unique* edge length"" but that is not correct. The second shortest edge in your example has the same length as the shortest edge (1)."
544,Job prospects and opportunities after PhD in CS focusing on HCI topic,"I have a friend who studied human factors and mechanical engineering and controls systems and psychology. 

Since there is no such major she submitted a study plan and got a “Bachelor of Science in Engineering Unspecified”.   She eventually got her PhD and now designs cockpits for Boeing."
545,SUBNETTING CHEAT SHEET,"\> Why are we counting up by increments of groupsize,  


If you have N balls numbered 0 to N-1, that have to be put into bins of size M, in sequence of their number, then you will have N/M bins and each ball B^(n) would be in bin (n + (M -1))/M. Now if you were given the number on a ball you knew the value of N and M, you would be able to tell what bin that ball is in. Same principle applies here.  


If the size of a subnet is 16, and we are only dealing with subnets of size <= 255, then there can only be 16 subnets. So if you are given an IP address, your subnet is the closest multiple of 16 smaller than or equal to that IP in the last octet. You can accomplish the same thing by counting up from 0 in steps of 16 too.  


\>  each increment is part of a network above the network it's in  


Each the IP address of the subnet itself will precede the addresses of IPs belonging to that subnet yes.  


Not sure if that made sense, but r/HomeNetworking could also be a place to ask."
546,Feasibility of a project idea,"It is ambitious to do a functioning web application with limited programming background, but it seems like this is an optional program for ambitious students, which is fine.

Once there, a task management app is one of the very most common ""learn web development"" problems and there are a gazillion tutorials and examples online. A lot of people do this as a project to stick on a resume, where I think it does more harm than good. But for a learning project early in undergrad it is a good choice."
547,Will Amazon Warehouse work experience help me to get a Software Engineering or IT job at Amazon in the future?,"No. When you're applying for internships they will generally be asking you about the things you have learned in your CS courses. Other than that it won't matter beyond ""I held a job before"", but that matters very minimally.

After the first internship they're really not going to care much about anything before that point.

At least this was my experience."
548,Tool to crack all Leetcode style interviews?,"This sounds both immoral, and like a good way to get fired if the company learns they hired you under false pretenses. Leetcode-style interviews are also pretty trash if they're not used as a pretense for you to discuss your thought process with an interviewer, and making ChatGPT write code for you won't help much with discussing design principles."
549,Was there ever an external storage format / data-transfer solution that just consisted of DRAM + a rechargeable battery?,"The thing to remember is that while early digital cameras had to live with slow media, they also had tiny relatively low-resolution sensors that didn't produce a ton of data that needed to be shuttled off to storage. 

And if the only technology available to you meant that a photo took a couple of seconds to store and the camera be ready for the next shot, then that was what you had. It's not like you were sitting there going, ""I wish this piece of crap could do 54 megapixel HDR photos at 20 exposures per second."" It was just amazing to have your 1.3 megapixel camera that spit out a jpg ready for you look at.

Basically, media of the day wasn't so slow compared to the demands of the day that there was any demand for ""can you make the camera way faster but much more likely to lose my pictures""."
550,"If we're willing to sacrifice read-speed, can we store large data like this instead?","Correct me if I'm misunderstanding, but this sounds very similar to simple text compression. To keep things simple, would run-length encoding do what you are describing?"
551,"In encryption, to my understanding the key is just a string of data that serves as a code which can be put into an encryption/decryption algorithm. How does this work exactly? Is it like a required input in the algorithm I.e if key holds value 2 then this tells the alg. how many places to move it.","That depends on the encryption algorithm.

E.g. with a [one-time pad](https://en.wikipedia.org/wiki/One-time_pad), you treat the key as a bitmask and just XOR it with your clear text.

With [RSA](https://en.wikipedia.org/wiki/RSA_(cryptosystem\)#Encryption) you turn your clear text into one or more integers, depending on key and message length, and use modular arithmetic for de- and encryption.

And stuff like [AES](https://en.wikipedia.org/wiki/Advanced_Encryption_Standard) is a little more complicated."
552,"Participants Needed for Evaluation of JSONTalk - A Summarising Tool for JSON Files (15 mins, Ages 16+, Some CS knowledge required, remote)",Hey there! It seems like your study link does not work - you should probably look into updating it
553,chatgpt and Turing test,"I believe it is very easy to “tick” ChatGPT - for example, if asked the same thing, it often answers the same way. 

The only way I know of, that a machine has beaten the Turing test - which is more of a heuristic, really - is by “tricking” the test, such as acting as an 8 year old eastern european boy, who does not know English very well."
554,Hexadecimal Applications,"So if I understand it correctly, you propose to have 15 colors + off to encode the 16 possible states of a hexadecimal digit by having one color on at a time and ignoring each colors ""off"" state? If so, that would actually lose a hell of a lot of efficiency.

If you'd consider the 15 colors as a bit each (on/off for each color), you could encode 2^15 states instead of just 16. It's called [wavelength-division multiplexing](https://en.wikipedia.org/wiki/Wavelength-division_multiplexing) and uses multiple colors to send multiple signals through the same fiber at the same time."
555,What protects the integrity of AI image generation engines as more AI-generated images are included training datasets?,"I think the main misconception is that the dataset needs to be high quality. Don’t get me wrong, the dataset should ideally be tagged correctly, but often the most valuable training samples are the ones that force generalizations. For example awkward, poorly lit, skewed, or otherwise imperfect data is much more valuable than just “perfect” looking data. Some strategies to expand limited datasets include screwing around with the training data, add noise, crop it, rotate, shift and skew it just to help encourage generalizations.

You don’t really want all perfect professionally captured headshots, or high resolution near perfect AI reproductions. The world just isn’t like that so if you want to do face recognition for example, you need the messy data because messy data is what you’ll likely get in practice after training."
556,What is your preferred version control software and what additional features do you wish it had?,"git hands down

no more features

just wish people in tech would learn rudimentary git skills:

* using version control (at all)
* tracking all infrastructure as code
* using feature branches
* both sides need to learn to compromise in code reviews
* tagging releases
* using gitignore.io patterns
* storing OS, IDE and other crap in per-user global gitignore files rather than polluting the project git repo
* a project without a short, meaningful readme (WHAT the purpose of the project is, HOW to build the project) is useless
* there should be a branch for each distinct deployment environment, and the merger of a new commit should automatically trigger deployment there
* now that we have version control, don't leave junk code snippets lying around in the codebase. that's what the version control history and backlog tickets are for
* don't disable the Issues tab on GitHub repos
* don't waste time self hosting a git service
* pin the runtime dependencies and the buildtime dependencies
* regularly prune stale branches. a feature branch left unfinished for multiple sprints is a symptom of the team's lack of focus and failure to limit scope creep
* assign clear ownership of a repo to a set of people, or else delete the repo
* don't let CVE's accumulate
* don't create a repo or project without genuinely asking yourself, am i seriously going to invest the time and energy inventing yet another wheel, when there are surely plenty of acceptable wheels already?
* don't merge halfass changes until they're ready
* update feature branches often so peers can follow along and assist with troubleshooting and early review
* default to open source. closed source projects have more bugs and more security bugs. reward foss contributors by *hiring* foss contributors.
* clarify whether the artifacts, such as binaries, installation packages, docker images, etc. are considered part of the repo's responsibility or not
* clarify tier 1 (tested), and tier 2 (untested) target environments such as macos, windows, linux (glibc, musl, etc), freebsd, etc.
* don't do monolithic repos
* structure CI jobs as simply a short `make` style command which runs the rest of the build steps, so that the entire CI process can be reproduced locally in an emergency
* learn to manage pushing and pulling with multiple remotes
* clone onto a local directory structure that preserves the git host, org, and repo name in the folder hierarchy
* learn to use ASDF and direnv to quickly activate the right stack on a per repo, per ref basis
* don't make the mistake of writing automation for bumping version numbers. the result will be cumbersome and fragile.
* don't waste time updating screenshots or diagrams or videos, just write good text docs
* if the doc is very long, offer an ePUB for convenient reading
* feature branches enable incremental refactoring. perform incremental refactoring
* version database migrations
* lint at the beginning of a project, in order to quash thousands of warnings before they snowball
* use git natively, and don't mirror
* *talking* to your team is a more effective way to get them to use meaningful commit messages, rather than a fascist required git hook policy
* use repos to experiment with different linter configurations. let the best ones organically bubble up to other repos. don't *centralize* style or linter policy.
* for the love of turing, *respond to dependabot alerts*"
557,Help finding the right graduate program for me,"Out of curiosity, why do you want to do a CS master's?

You might look into a Master's of Data Science or similar. I know UBC in Canada has one, other places might.

To be honest, I think you'd really struggle with just a bit of Python in a Master's program. Most MSc programs will assume you're competent at programming in multiple languages and can pick up new languages quickly. They're also going to assume at least basic knowledge of algorithms, data structures, proofs, software engineering, systems/threads, etc.

You probably want to look for a post-baccelauriate program in CS or a Master's that is specifically designed for Non-CS undergrad backgrounds. Or you'll need to do a ton of self study before you start."
558,TCP Connection Handshake,"probably Magellan which is a big GPS vendor. you probably need to read their documentation. 

but i'm not sure what ""MGLNDD\_IP\_PORT"" means. is that string in it? if it's TCP the first thing it should be sending is a SYN packet if it's connecting to you. also: them initiating the connection seems rather weird. how do they know which IP address and which port to send to? maybe that's what that packet is -- is it a broadcast? if so it may be saying that somebody needs to tell it where to send. again, you'll need to see their documentation as that's obviously custom if that's what's going on."
559,Question for high school CS teachers- what are the big hurdles?,"I have some teaching experience in this area but I'm not a high school teacher. Be  cognizant of the difference between CS and programming. When I taught high school kids we were teaching to the AP exam which was called CS but was actually programming. I taught high-functioning kids who wanted to be there, so it was fun and easy for me. I suggest lots of hands-on activities such as writing code, if that's applicable. If the class is pure CS, then find some kinetic activities to engage the kids and illustrate abstract concepts. There are many such activities online.

The ACM Special Interest Group for teaching CS is SIGCSE, [https://sigcse.org/programs/](https://sigcse.org/programs/). You could join the email list and interact with other CS teachers. There are HS teachers on the list."
560,Why are binary numbers written with leading zeros in CS?,"Not yet mentioned, in Two's complement the value is negative if the most significant bit is 1 -- so you need to know the word length to know whether 10000000 is negative (8-bit) or positive (e.g. 16-bit 0000000010000000)."
561,How do you decide if a feature should be added to a software application or if it warrants writing a new application?,"that unix philosophy has long since left the barn. i think the more interesting question is when you should stop adding features. popular apps start taking a life unto themselves adding features just to add features. kitchen sink applications can be nice (love you emacs), but at some point the bloat isn't worth it. i really could care less what Excel v478 does that's new and exciting.

but a typical way the decision is made to add something in reality is whether somebody is willing to pay for it."
562,Tag yourthelf with your favorite RFC,"Mine is 2119, ""Key words for use in RFCs to Indicate Requirement Levels"""
563,I would like ti know why It Is so damn hard to erase a 8GB USB Key?,"This is more of a tech support questionable, but running with 6gb of ram is going to limit you depending on what else is running."
564,Databases,"If other people visit your website, they’ll be using the database and code on the web server. Is that what you mean?"
565,Help,"Not really a CompSci question. You might get an answer here, but it's probably worth trying r/mysql if you haven't done so already."
566,"In http requests is the request sent directly to the web server or is it sent to the DNS server, which provides the IP of the web server which then provides the web page ?","The DNS server receives the domain name, not the HTTP(S) request. DNS doesn't know or care about HTTP(S). It just resolves addresses."
567,"If you push your smartphone around in a cart, does the accelerometer in your pedometer app still count the steps?","You might be able too, however some of these programs (at least the one that I was involved with) that reward you for step activity also track fraud and create a type of fingerprint for your gate and cadence. A six or nine axis movement sensor can get a pretty good fingerprint of a person and we can algorithmically determine if you're the one getting steps or alert if the pattern changes significantly.


To add on yes, the waveforms/signal can look very different depending on if a phone is in your pocket, in a cart, in a bag, etc."
568,3NF synthesis algorithm,"The same online tool I recommended to you last time can also take you through 3NF synthesis step-by-step: http://www.ict.griffith.edu.au/normalization_tools/normalization/ind.php

You add all your FDs on the first page, then click on one of the two 3NF entries and activate “Show Steps” at the bottom."
569,Learning Ullmann's Subgraph Isomorphism and Is It What I Need,"Subgraph isomorphism is not needed here, and you can be thankful for that because it is NP-hard! Subgraph isomorphism is made for situations where the vertices of the graph are not fixed/ordered. However, in your grid graph, the vertices have a fixed order, which means your problem is not NP-hard.  

To solve your problem, I would maintain the state of your board, and whenever the state is updated at some tile, check locally at this tile whether the tile is part of any pattern."
570,candidate keys,"Your solution is correct, ACDF is already a key. You can verify it using this online tool if you want: http://www.ict.griffith.edu.au/normalization_tools/normalization/ind.php"
571,How does a router not know the final destination of a data packet when routing them ?,"routers only keep track of what the next hop needs to be. assuming it's via another router, routing protocols have different means of determining the next hop like SPF (OSPF, IS-IS), or distant vectors (BGP, RIP)."
572,File encryption with compression,"You can compress first, and then encrypt.

It's impossible to significantly compress an already-encrypted file to less than the size of the original data. (Or rather, if it is possible, it means your encryption algorithm is insecure.) I'm hand-waving the mathematical details, but loosely speaking, random data is incompressible. If an encrypted file can be compressed, that means if nothing else, you've leaked the fact that the plaintext was non-random."
573,Dose anyone know why do my browser how this symbol while loading it just happened recently.,Looks like a data leek
574,Is making an online forum a very advanced project for a beginner to web dev (who knows programming)?,"IMO it's a good project to learn a lot of new stuff. 

Since you need a database and therefore a Backend, you will go down the full stack rabbit-hole. 

Just be sure to think about the technologies you will use beforehand. Everything else can be looked up on the way. 

I guess it's best to implement some bare minimum functionality first and then keep expanding. A Forum is a good fit for that style of learning."
575,Question about the Pumping Lemma for CFL's,"Not only are there finite context-free languages, but *every* finite language is context-free (not to mention regular).

And every finite language satisfies the context-free pumping lemma, because all you have to do is choose *p* larger than the length of the longest string in the language, and the implication is trivially true (because no string *s* with length ≥ *p* exists).

Basically, the proof of the pumping lemma is that if you weren't allowed to use the same nonterminal twice in a derivation tree, then you could only generate finitely many strings. In other words, all but finitely many strings in the language (therefore, all strings larger than some particular length) repeat a nonterminal. And any string whose derivation repeats a nonterminal can be pumped.

(This is conceptually similar to the proof of the pumping lemma for regular languages: if you couldn't repeat a state in a FSM, then you could only generate finitely many strings, so any sufficiently long string must repeat a state.)"
576,Is it a good idea to study computer science in college as a beginner ?,"Honestly, objectively and bluntly - no, it's not too late, and I expect you know this instinctively yourself.

If nothing else, computer science is much broader than coding alone. For example - infrastructure, cloud, analytics, databases and cyber security also all fall under the umbrella but are distinct roles/areas of study.

Take some time and learn more about what you like. It's only been a few weeks."
577,PC and Mac Programming,What's your question? This is just an empty post...
578,Getting demotivated by the constant Alt-tabbing when learning from online tutorials. Any advice?,Split screen  or if you have a second screen use that . This helped me at least:D
579,"CS graduates, what's the most intriguing/mindblowing thing you learned about computers during your studies?","Any well-encrypted data is indistinguishable from random noise. If you're presented with a context free collection of bits and you can tell that it's encrypted data, you've also necessarily discovered a weakness in the crypto algorithm."
580,help me,"if you are asking this question, you are probably new to programming, so I will do my best to be kind in this response. 

Either will do. Both have sufficient resources for new programmers and when you’re first learning programming, language doesn’t matter. You need to learn about branches, loops, functions, debugging, reading documentation, along with, potentially, objects, using third party libraries, linking and compiling, and using command line interfaces. Language itself is insignificant, just pick one and start coding. Switching languages won’t make it easier or better, it will just distract you.  Hemming and haw-ing over which language to pick is cutting into the time you could be spending learning to write code. Just flip a coin and go with it.

Eventually you will learn about design patterns, algorithms, and data structures, which differ a bit depending on which language you’ve picked, but it doesn’t matter and won’t matter between the two options in the polls."
581,How the hell do create an Backend,"A backend web service means you have a web server running some code, written in the language of your choice (Python, Ruby, PHP, and JavaScript using Node.js are common choices for small webapps). You configure the web server so that when someone makes an HTTP request it triggers a corresponding function in your back end code. This process will vary depending on what back-end language you pick and what web server you use.

Now your client-side javascript will send requests to your own webserver, using your own API. Your server will turn around around send requests to the Davinci model. This way your API key stays entirely on the server, and the client never sees it. This also gives you an opportunity to implement server-side caching or rate-limiting, to prevent users from exhausting your API key."
582,What is a closed-form solution?,"[The Wikipedia article explains it pretty well.](https://en.wikipedia.org/wiki/Closed-form_expression)

Basically, it's something that can be represented as a mathematical formula that has a fixed structure.

For example, suppose you want to know the sum of the integers between 1 and N. You could find it by writing them all down and adding them up, but the larger N is, the more terms you have to add. Instead you could use the formula 1+2+...+(N-1)+N = (N^(2)+N)/2, which is a closed-form expression that gives the same result."
583,Why is this transaction schedule not serializable?,"In I and III, B can possibly be modified by both transactions at the same time.

For III consider the case that transaction 1 first locks, modifies and then unlocks A. Then transaction 2 can lock A and start modifying B. However at the same time transaction 1 can also modify B."
584,Top of the line laptop recommendation,"r/SuggestALaptop is probably going to be more helpful.

For most programming needs you don't really need anything special or high-end; for the ones you do, you would already know if you're doing them.

The reason MacBooks are popular, btw, is because they are Unix-based and can run a fair amount of the stuff that people are familiar with from Linux, but with good hardware and good hardware support. And because a great deal of programming is done on Linux. If you do Windows programming then that's fine. If you're planning on installing Linux then you probably want to check hardware compatibility."
585,Hello. I’ve just started a graduate masters degree program in computer science. My background is a bachelor’s and masters degree in aerospace engineering.,"Not having a background in computer science may make it more challenging to complete your degree, but when employers see ""masters in computer science"" I doubt they'll care what your bachelors was in, so long as you do well in interviews"
586,Suggestions in which to pick IT or cybersecurity?,"I believe most people will suggest IT as it's more general. 

You need to know everything for cybersecurity that an IT degree would cover anyway. 

And with a general IT degree you can go into cybersecurity anyway. 

Can't promise you'll get a work from home job though."
587,"Which programming languages, if all legacy code written in them was ported to a more modern language, would become extinct?","Well... logically probably any language?   If there was magic to take all of one language and flawlessly and completely port it to a new and better language it becomes a no brainer.

If you're asking what languages have things they do that they do better than other languages which would prevent that... I'd guess you could probably find an advocate for any language which isn't already 'extinct' via that definition.  And probably even some advocates for the extinct languages.

But logically, if you could port all code from x->y and y has a large user base, better learning curve, and long term viability without sacrificing functionality or efficiency... any language would be rendered extinct.  Because why wouldn't you?  The only defendable reason is X will be better than Y soon, and really invalidates the assumption that Y is 'more modern'

The reality is that A) you cannot do this and B) Some languages do do some specific things very well that make them ideal for a particular use case."
588,Is it possible to build a web application with no open source software in 2023?,"Turing completeness, anything's possible.

Write your own OS. Design your own ISA. Fab your own chips.

Mind, it's all academic or stupid to vertically integrate. Default to FOSS."
589,How long should one take to learn HTML and CSS?,Around 45 minutes.
590,How many 0's and 1's are there in the Windows 10 OS?,"But the lines of code aren't really what's ""in"" Windows 10. It's compiled machine instructions and data. The install for Windows 10 is apparently about 20GB. 20GB is approximately 160 billion bits. Each bit is a one or a zero."
591,Understanding how to create a Google map that searches as you move the map,"I'm not a web developer and don't know much of anything about Javascript, but at a quick glance, can you not use the Events API to trigger whatever function you want on the callbacks from `bounds_changed`, `center_changed`, etc.?

https://developers.google.com/maps/documentation/javascript/events"
592,I'm i a bad programmer if I use chatgptr?,yes. the best programmwr I know is char* ptr
593,Grokking Algorithms vs The Algorithm Design Manuel vs A Common-Sense Guide to Data Structures and Algorithms,Thanks OP
594,[Formal language theory and parsing] Could anyone explain a few definitions given in a textbook? (Concepts of Programming Languages [12th Edition] by Robert W. Sebesta),i am going to start with rhe most obvious answer: have you discussed it with chat gpt? asked to clarify the terms? to give examples?
595,Should I stick with java or change learn new language,"languages are fungible. good programmers should be able to pick them up if you understand the fundamentals of them. yes, i get you're still in high school but i'm talking to the larger issue that people (and worst of all companies, sssssss) think that that is some sort of defining characteristic. it isn't. so i'd say yes learn other languages but not for the reasons you're saying but from the perspective of a longitudinal survey."
596,"Hello guys, I’m looking to read the data on this chips. However, I’m not sure what gadgets I would require . Would appreciate greatly if someone could enlighten. Many thanks.","Try /r/AskElectronics , they're good at chip id. Also [in their wiki](https://www.reddit.com/r/AskElectronics/wiki/index#wiki_what_is_this.3F)


Using their info the only thing I could find it being on the various marking code sites, in that package size, is an [R1161D321A](https://www.digchip.com/datasheets/parts/datasheet/404/R1161D321D.php), which is a voltage regulator. But the ""marking"" info in the datasheet doesn't match the layout we see in your photo.

Anyway, anything that small with only 6 pins probably doesn't have ""data"", it's probably just a plain IC. Do you have a photo of the other side of the PCB?"
597,"What is CPU architecture and how is it related to i3, i5, i7?","i3, i5, i7 are just marketing terms that Intel uses for low-tier, mid-tier, and high-tier CPUs. That's basically it. Since it's just a marketing term, it has no meaningful relationship to computer architecture although I guess in practical terms it does imply an x86 CPU.
 
CPU architecture is a much more complex topic, but computer architecture would primarily break down into two different ideas. The first would be the ISA, or instruction set architecture. The second would be the microarchitecture.  
 
A CPU's ISA defines how instructions are encoded, what instructions are offered, what those instructions do, and some details of things that those instructions interact with, such as registers, which are small pieces of memory used to store the inputs and outputs of individual instructions. Essentially the ISA defines the observable behavior of the CPU as far as what computations it can perform.  

Microarchitecture on the other hand refers to the details pertaining to how the ISA is physically implemented. For example, two different CPUs that implement the same ISA could run at different clock rates, so one could run faster than the other. Broadly speaking, microarchitecture determines things like overall performance (at least relative to other CPUs with the same ISA), energy efficiency, cost to manufacture, and other such things.  
 
Edit: Corrected auto-correct"
598,College Club Assignment Help,Talk to club members.
599,"How do social media services prevent people from uploading malware in the files/content they upload be it text, image or video?","Some services, like Gmail and Google Drive, scan files with ordinary anti-virus software, which looks for known patterns and tell-tale signs of malware. Other services don't bother.

Generally speaking, *just* including malicious code as part of a data file isn't enough to cause it to be executed. The CPU only executes what software tells it to, and correctly-designed software will not just take data that it's operating on and start executing it as code.

That said, occasionally it happens due to programming errors, such as [buffer overflows](https://en.wikipedia.org/wiki/Buffer_overflow). Every so often, people find bugs in software (e.g. in web browsers) that can be exploited by carefully crafted data. Whenever that happens, it's treated as a critical security flaw, and patched as soon as possible.

But that just makes it difficult to *accidentally* run malicious code, just by visiting a website or viewing an image. If you deliberately download *and run* a program that turns out to be malware, that doesn't help you. That's why many services either restrict you to uploading images/videos and disallow other file types, or run user-submitted files through virus scanners. But you shouldn't rely on that protection."
600,how do you invert modular addition for the purposes of encryption and decryption?,"You can't recover the original value of P, but you can recover P mod 64.

When you're working with integers modulo N, subtraction is the reverse of addition, just like for normal integers. So by subtracting K from both sides of your equation, we get:

P mod 64 = (C - K) mod 64"
601,What should I focus as a beginner in machine learning?,This is absurdly ambitious for 3 months and that amount of experience. It would be very ambitious for someone with a lot of machine learning experience and an excellent data set already. Pick a more reasonable thesis is my advice.
602,[Formal language theory and parsing] Could someone explain a definition given in a textbook? (Concepts of Programming Languages [12th Edition] by Robert W. Sebesta),"I'm just guessing (don't know that textbook, nor details of bottom-parsing algs), but:

I think the * kinda goes with the ""⇒"" —    `u ⇒* w` means that u derives w in many steps (well, ""~~one~~ EDIT: *zero* or more steps"" — the transitive closure of derives-in-a-single-step, or ""⇒"").

So:   ""… iff S ⇒* aAw ⇒ aβw, using only rightmost derivations""."
603,"In system design, what is the clear difference between Message Queues and Task Queues?","Most definitions I've read suggest they're really very different things. 

A message queue simply receives and sends on messages. It may or may not track whether or not the messages are actually received or processed by the recipients. It will respond to a request to delete a message.

Task queues are tied with performing some kind of task, usually asynchronously. They may even use a message queue to track the task being performed. They have to keep track of things like the task being processed, when it is started and finished, and remove it from the queue when it is completed."
604,How hard is Computer science,It is NP-hard
605,"Which town has more job opportunities for IT guys, or is close to an IT hub?","the Silicon Valley region of California

but most any town with WiFi can conduct remote work"
606,Recommendations on which sources to read to understand torrenting.,"I've written blog posts about this!

* [How torrents, magnet links, trackers, and (abstractly) the Distributed Hash Table work](https://backdrifting.net/post/037_torrents)

* [How DHTs and other distributed data stores work in much more detail](https://backdrifting.net/post/040_dhts)

* [A deeper technical dive into parts of the torrent tracker protocol](https://backdrifting.net/post/060_torrent_health)

This won't directly answer your questions about how ISPs can detect torrenting, or how a VPN works. For the ISP question, the ISP _could_ detect that you're torrenting via packet sniffing - torrent and tracker traffic stands out if you're looking for it - but more likely it's a copyright holder like Disney or WB monitoring torrents for some of their movies, seeing your IP in the peer list, and sending a letter to your ISP.

The VPN is a broader question. In non-technical detail, it's just a server that stands in-between you and what you're doing on the Internet. Your ISP can see that you're connected to a VPN, but nothing else, because the data between you and the VPN is encrypted. People monitoring a torrent can see your VPN's IP in the peer list, but not yours. For more technical detail, you should read about how the Internet, packets, and routing work. Have fun!"
607,Are there data structures for pencil and paper,"Really any data structure you see in programming will work, the only difference is implementation. Just having some sort of sections in a physical folder and there again subsections is a type of tree structure. Also depends on what types of notes. I am sure you can find some old best practices for filing systems, depending on what kind of volume you are looking at."
608,"Is there a good podcast, YouTube channel, or website that specifically explores ethics in computer science?","For podcasts, Tech Won't Save Us frequently has episodes covering ethical issues in computer science. Reimagining the Internet is an academic-run podcast ethical issues, potential solutions, and a positive vision of a future Internet.

Ethics in CS are within the the purview of groups like the Electronic Frontier Foundation and the Berkman Klein Center for Internet & Society, but they're both a bit broader than that.

[Violet Blue's Cybersecurity Roundup](https://www.patreon.com/violetblue) is a weekly newsletter routinely covering cybersecurity of software engineering ethical issues, and both [Bruce Schneier's blog](https://www.schneier.com/) and [everything Cory Doctorow writes](https://pluralistic.net/) tackle CS ethics issues regularly."
609,how AI(particularly GPT) trained by internet data?,"There is a gigantic difference between ""all"" and ""a lot"" off the internet. When people mention that ChatGPT is trained on ""all"" or the ""entirety"" of the internet, they are using hyperbole. The internet archive for instance has the goal of archiving all of the internet. More information is added to the internet each day than they are capable of backing up."
610,Should i bring my Desktop to Uni?,"Honestly, i agree with your brother, having all of your work be accessible at any given time is awesome, just be careful not to fall into all the gaming laptop marketing. If you don't play demanding games or use super intensive applications often, then a ""cheap"" (quality) laptop with a RTX 3060 should suit your purpose quite well."
611,does theory of computation also concerns itself with inputs that are not strings?,"Yes, it can cover anything that can be *encoded* as a string (over some finite alphabet), which includes graphs. For example, you can represent a finite graph as a list of vertices and their adjacency lists.

That's how we can prove that problems such as finding a Hamiltonian path in a graph are NP-complete."
612,Projects to practice algorithmic design?,why not just implement the code and run some data through it?
613,"Can all types of information be stored in a binary form, or are there some exceptions?","There are some exceptions, but they are esoteric and of little practical consequence.

Analog information has to be quantized to be stored in digital form, which necessarily loses some of the information.  But this quantization can be arbitrarily small, and you can't eliminate all the noise from analog systems, so in most cases digital systems can perform analog tasks just as well as analog systems.

You also can't always represent all possible states of a qubit digitally."
614,Does it make sense to say that all of the software on your device is just one big program?,[deleted]
615,Take a Computing for Social Good Class or a Database Systems course?,"My first thought is that the Computing for Social Good class is something you won't likely be able to do after you graduate, because this is the sort of thing that only really exists in the academic environment.  You can learn about databases from Pluralsight, but there probably aren't Pluralsight courses on the intersection between computer science and ethics.

That being said, database _theory_ is an important thing to know.  I imagine the Pluralsight classes will be mostly about specific database products and how to make pragmatic use of them; I doubt they talk about Codd's normal forms, or the way the relational model arises mathematically from the principles of first-order predicate logic.  These are worthwhile things to spend time thinking about, which are likely to be better dealt with in an academic than a commercial setting.

So ... I'm on the fence.  Do you have access to any kind of course ratings that would show whether one of these classes is taught better than the other at your particular institution?"
616,Preparing for the CS GRE subject,"What background DO you have? I’m not sure how much time you have, but learn about Operating Systems, O(n) complexity and Computer Architecture for a start I guess."
617,What are some good introductory computer science textbooks?,"CS is a broad field, and I'm not sure if there's a solid book that would give you the sort of overview you're trying to obtain but from my own research I found a book called Computer Science an overview by Glenn Brookshear, I'd also suggest that you watch Crash Course Computer Science on YouTube too."
618,"Can any mobile device be completely reconfigured? That is, can I get rid of all the preinstalled software and install a new OS for example?","Yes, infact Xiaomi/poco/redmi phones have best custom rom community. 
 Ask this in r/Xiaomi."
619,Why do we not install an antivirus software anymore?,"Operating systems come with anti virus built in. Google Play Protect on Android, Microsoft Defender on Windows, macOS has a bunch of technologies with different names working together...

On mobile operating systems in particular, third party antivirus can't even get the kinds of permissions an anti virus would really need in order to function.   
And even on Windows, I'd argue it's better to not have extra, third party software dig itself that deeply into the very core of your system. There are various cases where malware has exploited anti virus software in order to escalate privileges... I'll just trust that the Windows Defender developer team and the NT Kernel Team agree on what parts of the Kernel the anti virus is allowed to hook into and which one they aren't - I don't think third party anti virus gets that privilege..."
620,How Much Verbal Communication Happens In A Software Developer Role?,"There are some solo roles, but most dev roles today are team oriented.

Do you mean able to sign? A person unable to communicate at all will have difficulty learning the material. But one who can sign, could seek a team with other people who can sign."
621,Youtube programming videos,"Instead of videos I'd recommend exercise based tutorials. It's easier to pick up again, you'll be more focused on doing it yourself rather than waiting for the answer to be displayed.

The only free one I unfortunately can think of is W3schools. It's not a bad start, but I hope someone will add more suggestions like this one. (Baeldung is a very good resource for JAVA devs)

Once you have grasped the syntax, you can move on to exercism.com which has a bunch of coding tests, support and more."
622,What are some good textbooks on automata theory and formal language theory?,isn't the canonical answer here the Dragon Book by Aho and Ulman?
623,"When people refer to distributed system, distributed database, distributed application, what do they actually mean?","it usually means across many different systems, and often across administrative boundaries too. DNS is a good example of a distributed database across administrative boundaries. Same BGP."
624,Looking for an algorithm to minimise the amount of head movement on a CNC saw,"Ah! I see you have stumbled across the traveling salesman problem. [https://en.wikipedia.org/wiki/Travelling\_salesman\_problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem)

Good luck in experimenting and finding the optimal solutions -- depending on the variations of cuts, and how much processing time you have before uploading the geocode, that would determine your search time."
625,Computer Skills that can be used in real life outside of work/business/R&D?,"Shell and Python scripting are very useful. Especially on Mac and Linux.

Make your own Arduino gadgets.

Write things like Discord bots.

And you see all those videos talking about how to get stuff from your Windows PC to your Steam deck? I just sftp it from my Linux PC because I have a Linux PC and I know how to do that."
626,Difference between flushing and spilling data?,"As far as I know, the words ""flush"" and ""spill"" don't have precise definitions, but they're commonly used to describe different types of caching behavior. The type of data you're caching, or the device you're caching it in, could vary.

In general, ""spilling"" is when you have too much data to fit in your cache, but you don't want to lose it (perhaps because it's a writeback cache), so you have to move some of it to a less quickly-accessible location. For example, say you're working with a temporary file. When the file is small it might fit entirely in RAM (in the operating system's disk cache), but if it gets too large, some of its contents (whatever sections were least recently used) might have to spill over to the actual hard disk.

""Flushing"" usually refers to evicting the *entire* contents of the cache. For instance, when the OS switches from one process to another, it has to flush the processor's TLB (which caches mappings from virtual to physical memory addresses), because the old mappings are not applicable to the new process. Or if you're working with files on a removable device, you want to flush the disk cache before unplugging the device, so that you don't get data corruption from partly-written files."
627,How does thread usage relate to overall cpu usage?,"What do you mean by ""putting too much on one thread""?

A single thread is just a single sequence of instructions, or rather, a single flow of program control. A single CPU core will be able to execute that thread at the same speed no matter what other cores are doing, determined mainly by the CPU's architecture and clock speed. (That is, as long as something else like RAM isn't creating a bottleneck.)

Assigning a large amount of work to a single thread will not make the CPU execute more slowly, but it might still take longer to finish than if you divided up the same workload among many threads, and ran them in parallel on separate cores.

When your CPU says it supports ""12 threads"", that just means each core can have two threads that are ""runnable"" at any given amount of time, and depending on exactly what they're doing, they may be able to share the core's resources. (This is also known as ""hyperthreading"".) Running two threads like this is generally somewhat faster than having them take turns on a non-hyperthreaded processor, but slower than running them on entirely separate cores where each thread has full use of the core's hardware."
628,Hamming distance,[deleted]
629,Need practice resources! (PLEASE),"If you want to practice, do programming go to leetcode, and search the array list exercises, 

I hope I answered your question"
630,"how do i create a file , save a viual studio document , and or run a visual studio document?","I've taught quite a few first time programmers by now (I'm a teaching assistant for the intro to programming courses at my university) and the first thing to learn is that the editor (visual studio) is separate from your code (file). Most people are taught that certain file types must be run with certain programs but this isn't really true. You can use your code file in many different editors or even notepad and you can compile and run it without an editor. Exactly how to run your code will depend on the language. So you can create your file anywhere and open it with visual studio, make your changes, and save your work as you would with any other file. I hope this helps :)"
631,CS50,"naked access to memory gives lots of ways to shoot yourself in the foot. classic foibles are things like dangling pointers where you have freed the memory but still have a pointer to it. memory corruption is something that bedevils even the best of us. Heisenbugs are even worse and often caused by it. 

but assuming competence is by far the fastest runtime option. that can make a huge difference in speed of execution, but there are still a lot of situations with mundane non-critical code that you wish you had better code safety. i think that Rust has been trying to thread that needle. but honestly a 21st century libc that doesn't try to wring out every byte and cpu cycle would also go a long way toward that."
632,.jpegs lose information but .mp3s don't?,"That's not what lossy means and your premise is wrong.  Looking at jpegs does not cause them to degrade.  Taking an existing jpeg and saving it again would potentially cause it to degrade.


Lossy means the quality of the file is less than that of the original, which is the case for jpegs and mp3s.  It has nothing to do with playback or viewing."
633,Close way to get qualutative CS degree knowledge,CS50 on Coursera to start.
634,Struggling sophomore can't find a summer job,Try r/cscareerquestions or r/csmajors.
635,VS Code vs cmd Terminal Results Different. Any possible reasons?,"Those are address values you are printing on the left. The values on the right should be the same on all platforms. You cannot depend on the OS to put your pointers at the same address, even between runs. You might not get the same result if you run on the same platform twice.

As to why this is happening, see https://en.m.wikipedia.org/wiki/Address_space_layout_randomization"
636,Can logic be used to model information in information theory?,You'll have to expand on your question.
637,Confused as to what the time complexity of my algorithm is.,Can you give a breakdown that leads you n!?
638,"Which is better for modeling artificial intelligence, “default logic” or “autoepistemic logic”?","""It depends on the specific application. Default logic is better suited for reasoning with incomplete information, while autoepistemic logic is better for modeling self-referential beliefs."" - ChatGPT"
639,How to become a Computer Scientist?,"Find a discrete maths course. That is the foundational theory for computer science. If you like it, keep going by studying algorithms, data structures, computer theory and architecture. Coding is a tool used by computer scientists. It isn’t the actual subject."
640,Hi all! I’m asking for a bit of direction for something I don’t completely have the capacity to do.,"I hope I'm misunderstanding but it sounds like you're trying to write a virus.

""Undo"" normally means to undo something the computer has done, not to incapacitate a device."
641,Is formal/mathematical logic used in information theory?,"> I’m talking about things like first-order logic and set theory.

Strictly speaking, all math, including information theory, is built upon the basis of first-order logic and set theory. Now, if you take a course in information theory, you probably won't see too many base set theory axioms or formal methods of deduction.

Instead, you'll mostly be working in the domain of simple finite sets of natural numbers, logarithms, infinite sums, the occasional limit, some group/ring theory (especially in coding theory), and Fourier transforms. You might see some probability theory in there, but one could argue that it's probability that's based on information theory, not the other way around.

However, you can use information theory as an alternative foundation of mathematics. This is not common, but it can be done. In this case, you won't see any set theory axioms, except when you derive them *from* information theory axioms. Using this method, however, you will definitely see a ton of first-order logic."
642,What tech is used to make software like Figma or Canva? Is it WebGL or 3JS? And what can be used to build a video editor on web.,"I believe wasm, Web assembly. A compiled language like Rust or C++ converted into wasm so your browser can run it."
643,Is my solution for Unisex Bathroom Problem correct? (No starvation is a requirement),"I'm not trying to be rude, but maybe write some driver code and some test cases and see for yourself?"
644,How does a processor know where instructions for a program are stored in secondary memory?,"The operating system is, in a sense, a program for running programs. So when you double-click a program file, you are telling the OS ""hey, please execute the file located at `/home/me/Desktop/program.bin`."" That bin file is nothing but a sequence of executable instructions, ready for a CPU. Then the OS loads that file into memory (RAM), then loads the RAM address of the first instruction from the program into the *Program Counter* register on the CPU (and sets a couple other special registers). Once that's done, in the very next clock cycle the CPU will be executing your program.

EDIT: a word"
645,What does it mean when they say protobuffers are in a binary format,"\> are they simply saying they use a different encoding than a plain text encoding like UTF-8

Pretty much yes. Nearly every computer has a text editor which understands ASCII / UTF-8.

But the only way to read protobufs is have program which knows the protobufs format."
646,How does a load balancer work at entry in practise?,"For most even moderately-sized websites, you can get away with one big, powerful load balancer, and maybe a backup in case the first one fails. A moderately powerful server can easily handle hundreds of thousands of requests per second, or enough raw throughput to saturate a 10Gbps network connection.

For larger, geographically-distributed sites, you can use round-robin DNS to split the traffic among multiple load balancers, or geographically-aware DNS to send traffic to a load balancer that's physically close to the user.

Google additionally has their own clever approach: within each datacenter, they have many physical load balancer machines all sharing a single ""virtual"" external IP address. The load balancer instances all coordinate to act like one big load balancer, using consistent hashing to ensure that each incoming connection gets routed to a single back-end server, even if no single balancer instance sees the entire connection. (For details, see their paper: [""Maglev: A Fast and Reliable Software Network Load Balancer""](https://research.google/pubs/pub44824/))"
647,[ARCHITECTURE] Why do some programs generate more heat than others?,"Consider two programs. The first is a floating point heavy code, maybe doing a well-blocked matrix multiplication at the peak throughout of the machine, lighting up all the FP multipliers and adders on every cycle. The second is a pointer chasing code that misses a lot in the last-level cache, causing it to frequently stall. The first program causes much more switching per cycle than the second one, consuming more power and dissipating more heat."
648,sql to machine code,"it's possible but extremely improbably that SQL would be compiled. SQL is much higher level than Java or Python and is focused on very IO intensive operations. programming in SQL is also relatively rare. you can write code in SQL, but is almost always used to do some database operation, and not anything general."
649,"I asked ChatGPT to write a transformer model for language modeling from scratch using only standard Python libraries (no 3rd party, not even Numpy) and then asked it to write the code to train it using Huggingfaces Wiki dataset. Can anyone rate how well it did? I dont have the RAM to train it.","Don't ask it to program stuff you don't know about, for you will not know how to fix it."
650,What are some Independent Study topics for Computer Science?,"i think it's really helpful to understand machine architecture. that is, what is going on under the hood. it really demystifies what computer languages are doing as they all have to target the underlying processor and other hardware. i get the impression that that has sort of fallen out of favor in the mad rush to get programmers out the door. but understanding the basics of how a processor gets data in, processes it and writes it back out. what registers are, what the ALU does. how memory (ram) works. 

one of the first things they threw at me when i was in school was to write an assembler. i didn't really want to, but it gave me a feel for what was actually going on at the gate and transistor level."
651,Book with a compiler for a language and including all steps from DFA to Final Code Generation?,"Crafting interpreters has a full practical example, but it doesn't go to the academic depths of the dragon book. I don't know one that does both."
652,What are some good textbooks on the lambda calculus?,"Barendregts ""The Lambda Calculus, its Syntax and Semantics"" is an absolute classic. (But very math-oriented)"
653,Would setting your password to a hashed password be the safest password?,"What you’re sort of saying is “is a long random password of letters and digits better than a bunch of words”. Yes it is. Always. That’s why password managers are a thing. 

As a general rule though, the best thing you can do to make a password more secure is to make it longer. 

For example:
- “Tr0ub4dor&3” looks like (what we’ve been taught is) a strong password, it has all the things in it: upper case, letters, numbers, special characters. But it’s pretty short and hard to remember and most importantly, easy for a machine to guess. 
- “correct-battery-horse-staple” looks like a bad password, but it’s easy for a human to remember, and way harder for a machine to guess. It’s a much stronger password. 

[sauce](https://xkcd.com/936/)"
654,How can a proof for p vs np exist ?,">Lets imagine that algorithm 1 can solve Battleship grid A but the same algorithm cant solve an Battleship grid B

If an algorithm can solve some instances of a problem, but not all, then it's a heuristic, not a correct algorithm for the problem.

When talking about the normal complexity class of a problem, we only take into account algorithms that correctly solve every instance of the problem, not heuristics."
655,Is formal/mathematical logic used in artificial intelligence research?,"One area it is being used is in the formal verification of DNNs. There are several research groups working on this and there are papers, but I am not aware of any textbooks. I think having a look at the papers (especially the introduction / background) is a good idea, the methods are mostly from the program verification / constraint programming domain, so one could study utilized methods after that if it is interesting."
656,Median of Median algorithm,"Median of medians gives you an *approximate* median. You can mathematically analyze it and show that the result is within certain bounds, compared to the true median.

I don't see why you couldn't change the algorithm to compute different quantiles, and then do the same kind of analysis, but the resulting bounds will be different.

If you want an *exact* quantile, you can use [quickselect.](https://en.wikipedia.org/wiki/Quickselect)"
657,where to start learning databases and APIs?,probably start with a web framework with an object-relational mapping module like Ruby on Rails or DJango. there are ways you can see what it's actually sending to the database which is also a useful skill because ORM's used badly do bad things.
658,Why are we training computers to solve image CAPTCHA...,[deleted]
659,"Does anyone know of a program to map 18k images by color (similar to the image but with no empty spaces ) + a program to create an HD texture map to be mapped seamlessly on a 3d sphere (with the poles closer to the center like earth), to be printed on a huge behemoth beach ball in real life.","[https://youtu.be/uBRTcYwKouw?t=118](https://youtu.be/uBRTcYwKouw?t=118) the behemoth beach ball in question. If anyone wants to help me on this big art installation, please PM me.

**I can pay you or do marketing with your name/website will be on the project and I can print your contact or website on the inflatable pool holding the behemoth beach ball.**

The texture map should have no distorted image on the poles and be seamlessly stitched.

It's to put my art portfolio images printed on the behemoth beach ball, it will be browsable by hand in a local big museum, it will stand rotating on a small inflatable circular pool."
660,Jobs for undergrads,"internships

gigs making websites for random people

talk to people at a college campus about tech work

barista, grocer, whatever. any professional experience helps indirectly

publish websites of your own. there's a lot of work for people who can do frontend coding with javascript, html, and css"
661,Definition of Distributed Systems,"First of all, I'm going to say right up front that if you're looking for a clear-cut, unambiguous, precise definition that separates ""distributed"" and ""non-distributed"" systems, you're likely to be disappointed.

----

I think that talking about ""messages"" is a *particularly* poor definition of a ""distributed system"". For one thing, it conveys almost no information, because you can use ""message"" to describe just about *any* kind of communication. Whether or not you call something a message has more to do with your point of view than with the system itself.

What I think the term ""message"" is trying to *suggest* is the idea of *asynchronous* communication. That is, the sender of the message sends a discrete packet of information, and then doesn't have to care about the details of how or when the receiver deals with it later. But not all asynchronous systems are distributed, and not all distributed systems are asynchronous.

----

In my opinion, if there's one thing that most significantly distinguishes distributed systems from other fields of study, it's the way they deal with failures, and especially *partial* failures.

In a centralized, non-distributed system, we sometimes say that every component of the system ""shares a fate"". For instance, software developers normally don't try to plan for scenarios where the multiplier circuitry of the CPU fails, or a single RAM chip on a module stops responding. In those scenarios, we assume that if one hardware component fails, the whole computer is defective, and we're just going to assume it crashes and there's nothing we can do about it.

Distributed systems are ones in which we don't make this assumption: we model the system as being made up of multiple components, and we want to allow for the possibility that they *don't* share a fate, i.e. a single component might fail (or operate unreliably) but the system as a whole keeps running. This change in assumptions has far-reaching impacts on the way we actually design the systems, because it puts limits on what is possible to achieve. 

For instance, there are lots of formal theorems which say (to loosely paraphrase) that various problems are *impossible* to solve in a distributed system if communications between nodes are imperfect. In this situation, we can say that each node has perfect knowledge of its own internal state, but it may have incomplete or stale knowledge about the ""global"" state of the system, which is what we as designers care more about. 

(""Messages"" enter this picture because they're a useful abstraction for talking about partial communications failures. You can describe a node's communications as a set of discrete incoming and outgoing messages, and then formally analyze what happens if some subset of those messages are lost or delayed.)

It turns out that in this model, there are certain kinds of uncertainty about global state that are impossible to completely eliminate. So distributed systems are ones that are designed to deal with this uncertainty -- hopefully in a rigorous, provably-correct way."
662,Observer Pattern: How to?,"There is ""generally"" only one way to implement the observer pattern, otherwise it wouldn't be a pattern.

The pattern is exactly defined and you can look up the UML diagram.
They were initially ""described"" by the authors known as gang of four(Enrich Gamma, Richard Helm, Ralph Johnson and John Vlissidles) in a book called Design Patterns: Elements of Reusable Object-Oriented Software.
I recommend you obtain a copy and read it if you are interested in patterns.

The observer is a very commonly used pattern that is made up of two interfaces. 
The Subject and the Subscriber.

The subject contains three methods, AddObserver(observer: Observer), RemoveObserver(observer: Observer) and NotifyOnAction(params : ... params)

Most frameworks usually also add a src param which is generic in the NotifyOnAction

The Observer contains an OnAction(params : ... Params).

Whenever Notify is called on the subject, the subject notifies all the observers which react by executing their own logic


This is the general implementation. What changes are the params and the number of possible notifications per interface.

I also used / saw a version of the implementation that omitted the Subject interface. 
Commonly used if you know there is going to be one and only one subject of that type in your entire application."
663,How are file types stored in memory?,"There are two ways your computer can determine the file type of a given file. Most modern operating systems just use the file extension. If it's labeled `.txt`, we'll assume it's a text document and interpret each byte as a character. If it's labeled `.jpg`, we'll assume it's an image until your image viewer complains otherwise.

Alternatively, computers can use [magic bytes](https://en.wikipedia.org/wiki/List_of_file_signatures). Most file formats have a special byte sequence signature. For example, all jpegs start with the bytes `0xFFD8FFE0`. Your computer has a large table of many such file signatures, and can check whether an unknown file has any of these signatures to guess its identity. This is what the `file` command does on the command line."
664,Should I be more passionate?,"I think something that gets lost is there are really two aspects to CS education. 

First, you have the actual Computer Science. The math behind computing, how we define algorithms and languages, that sort of thing. 

The second is the Engineering. Many CS students don't go on to become Computer Scientists, but more akin to Software Engineers. They like to build things, solve practical problems, that sort of thing. For them, CS is just the knowledge base and/or tool to solve those problems. 

Find something that you are interested in, and see if you can apply your education to helping that. Interested in gardening? Build a garden planning app, automate some sprinklers. Video games? Try to build a mod or tool to help. Active in Discord? Build a bot. 

If you're interested in cyber security, maybe find a few books in your university's library to read. Find a professor that lectures on cyber security and ask if there are any beginner projects they may recommend. 

It's good you have an idea for what comes next after your undergrad. Grad school is a common next step, but if its something you're unsure of, maybe consider some industry experience first. 

For most people, remember that education leads to careers, which are just the basis for allowing us to live our lives. You'll have a lot of interests and hobbies that are completely unrelated, such as cooking, skateboarding, board games, etc, as well as other life responsibilities like family. Everything put together is how you live a fulfilled life."
665,How do you quickly search databases that are hundreds of millions of records?,"To do fast DB searches you need indexes. If you want to do full text searches, you need full-text indexes."
666,What do I need to learn more about Cyber Security?,"The thing about cyber security is it's in absolutely *everything*.

Web pages? Lousy with attack surfaces.

Operating systems? Half the point is to enforce access controls.

Microcontrollers? IoT is just another way of saying, ""botnets"".

If there's a software engineer working on a product, that product has attack surfaces. It might be good to start by picking some software and researching ways to attack it and potential counters.

Also, look up cryptography. Crypto (real crypto, not Blockchain) is the backbone of conversation security. You should absolutely be familiar with the different algorithms and what they're used for.

As a starting point, here's some research questions for you:

* What is the difference between symmetric encryption versus asymmetric?
* When can you not use one or the other?
* If both are viable, which one should you use and why?
* What happens if you reverse the asymmetric keys?
* Find a real world example of both and why are they used there? (This can also springboard into further topics)
* What is a cryptographic hash and how is it different from encryption?
* Why would you use a cryptographic hash?
* How might someone attack a cryptographic hash used incorrectly?
* (Advanced) What specific threat does quantum computing pose to cryptography?"
667,File allocation table confusion,"> Is the FAT stored on the first sector of the volume rather than the first sector of the disk

Yes, a FAT file system is almost always stored in a disk *partition* (a.k.a. volume), which means you count sectors from the start of the partition rather than the start of the disk.

In principle, there's nothing stopping you from treating an entire physical disk as a single volume, and omitting the MBR and partition table. Linux, for instance, will happily mount such a volume. But without the MBR and partition table, the BIOS (probably) won't be able to boot from it.

> I’ve read everywhere that the file allocation table is stored in the first sector of the disk.

Where are you reading this? All the resources I can find say that the FAT is stored *after* the boot sector. See, for instance: https://en.wikipedia.org/wiki/Design_of_the_FAT_file_system

More specifically, the boot sector contains the BIOS Parameter Block (BPB), and one of the BPB's fields is the number of ""reserved"" sectors at the beginning of the volume (including the boot sector). The FAT starts after the last reserved sector.

Also, be careful not to confuse the boot sector (which is the first sector of a *partition*) with the MBR (which is the first sector of a *disk* and which is stored before the partition table)."
668,What theories are related to Quantum Computing?,Computational complexity
669,Need help with some movie recommendations for my senior project!,The Matrix Reloaded has Trinity using nmap to do a real hack.
670,Should I choose Python or Java if I want to become highly proficient in just one?,"Learn to be flexible. Master a language every time you have to use it for more than a few months. They're all the same with caveats for syntax (and LISP/SCALA/RPG II which are just whack).

Which is to say that you want to master 'programming' in general. The languages are just a means to an end, and one language is never going to meet all of your needs."
671,Is this a reasonable exam task for a first semester computer science class based on Python?,"The mathematical language might go over some people's heads depending on their level of education, but the actual code should be more than doable after learning the basics of programming in Python."
672,Want to switch into IT and designing.,"The usual way is, use your computer poorly to try new things you don't understand, let it break, and learn to fix it.  Other than that, programming tutorials and eventually certifications"
673,"if you made a program which, upon running it, would begin deleting its own code, would it crash after the remaining code no longer functioned as it’s supposed to or would it continue to run until all code was deleted?","This depends what you mean by ""deleting its own code.""

If you mean something like ""a python script that deletes itself off the hard drive,"" it should be unaffected until the script exits - the Python interpreter almost certainly caches the entire script in memory.

If you mean a program erasing its own machine instructions from memory, most executables will crash as soon as they change the first instruction. This is because modern software is typically compiled with Data Execution Prevention (DEP, goes by a few other names like W\^X) - basically the portions of memory containing machine instructions cannot be modified without crashing the program, and the portions of memory containing rewritable variables cannot be executed as instructions without crashing the program. This is to protect against certain kinds of binary exploitation attacks that involve injecting instructions into a program to get it to run whatever the attacker wants.

But! If we intentionally disable DEP at compilation time, allowing us to overwrite our own instructions in memory, we can do what you're talking about. You can overwrite instructions in memory with gibberish, and everything will be okay until the executable actually tries to _run_ any of those corrupted instructions. Then it'll probably crash with SIGILL (illegal instruction).

That's if you're _only_ overwriting the program's code. If you go overwriting memory at random, you could step on a variety of other important data structures like the stack, Global Offset Table, etc, and crash the program much more quickly.

Hope this helps!"
674,"I will ne going university soon to study game development over games design and have seen that there is a unit about ""maths for computing"" maths is my weakness subject and I just wanted to know exactly how hard is this to learn I plan to do it anyway but just want some insight thanks.",[deleted]
675,Codecademy Pro,"Learn some different programming languages, maybe do data structures and algorithms, and whatever else is interesting to you.  Or maybe take this opportunity to learn JavaScript and HTML/CSS, because a CS degree typically doesn't cover much of that.  Or really, just do whatever interests you."
676,Thread safe solution for the problem of finding median for a datastream,"Interesting question!

As you say, the simplest approach is to just use a single lock for the entire data structure. This is thread-safe, but you don't really gain any benefit whatsoever from parallelism. (Even if you use a reader-writer lock, you have to hold a write lock to implement `add_num`, so you can only get parallelism if `find_median` is being called many times concurrently without any changes to the data structure.)

It's possible that you could do better by storing the data in something like a concurrent (lock-based or lock-free) balanced tree, augmented with an extra field on each node which stores the total size of its subtree. This is a [well-known implementation trick](https://tildesites.bowdoin.edu/~ltoma/teaching/cs231/fall09/Lectures/10-augmentedTrees/augtrees.pdf) that allows you to select the i'th element in O(log n) time. (Finding the median is just the special case where i=n/2.)

The difficult part: every time you insert an element, you have to increment the count at a leaf node and then propagate that update all the way up the tree. So if you do it naively, every update will have to update the root node, and the resulting contention will probably kill your algorithm's efficiency.

A simple trick to get around this would be to only store the counts for a subset of nodes, e.g. the ones below level k of the tree. This means (if your data elements appear in random order) that the top-level updates will be distributed across O(2^(k)) nodes instead of concentrated at the root, which reduces contention and improves parallelism. The tradeoff is that `find_median` will have to aggregate the counts for all of those nodes before it can decide which path to look down. So tuning the value of k allows you to trade off the overhead between `add_num` and `find_median`."
677,Need to learn math to properly understand algorithm and data structures textbooks. Any good resources or playlists you would suggest?,"Hey hope you’re having a fantastic day, I’m not an expert at all but if i look back at some of the courses that we had about the basics of computers in general, the usual approach was to first learn about Boolean algebra then some base arithmetics(you know like calculating a number in for example base 7 then converting it to another base) and some logic gates and logic circuits. It would be a common approach that books about computer architecture like the one that Mano wrote, takes towards digital design but as far as basic maths, I think first couple of chapters of these books would suffice. These kind of books with this approach (i mean from digital architecture viewpoint ) will then continue to explain the fundamentals of memories, processing units, how actual codes execute base on clocks and things like that and i think it would give you some sort of practical understanding of how things work, really. But again I’m definitely not an expert. That was just what we learned as an eletrical engineers back in university. Hope you find the best resources and start your amazing journey."
678,"Are there encryption standards for Ethernet links, similar to WPA(2)?","Yes, there is the [MACsec standard](https://developers.redhat.com/blog/2016/10/14/macsec-a-different-solution-to-encrypt-network-traffic). It even has both a PSK and EAP mode, like WPA2."
679,ml processing over multiple computers,"You might be looking for a distributed data processing or machine learning framework such as Apache Spark.

More generally, you're looking into using those computers as some kind of a computing cluster. But you probably don't want to start building some kind of an elaborate cluster infrastructure, so that's more of a theoretical note."
680,Why don't we have more protocol beyond just TCP and UDP?,"There are tons of protocols like that.

Most of them are a subset of the two. UDP isn't optimized for anything, really. It is just a ""dumb"" protocol that allows you to send packets over IP.

That is why most of the specialized protocols are built on top of UDP.

One such example is RTP‐‐‐Which is used in multimedia transmission and radio communication.

It is a compromise between latency and guarantees.

If you look at the UDP header, you will notice that compared to the TCP header, it is very small. It only contains the src and dst port and optional checksum field (which does nothing on its own)

Most custom protocols need to have this kind of information if you want to work over IP, which is why they come from UDP.

If you know you don't need any of these fields and want to build your own custom protocol (That is not UDP or TCP), you can build it on top of the IP header. Again, there are a lot of protocols like that, one that I recall is RDP (You can look them up on wikipedia). This is usually implemented through raw sockets.  
The router has no issues forwarding such protocols.

Hope I answered the question. If you have anything else, feel free to ask.

Sorry for the typos. I wrote it on the phone."
681,Can't decide on what degree i should go for,"* CS is the most general degree. It can lead to any position in tech, really. It's always in demand, and offers tons of flexibility. From here you can easily go into security or data science if you want.
* A Software Development degree is likely a CS degree minus the theory. Just the practical bits. This is less desirable to employers, although 95% of the time in industry it's every bit as good as a CS degree. It's a great option if you deeply hate math. If you can stomach a little algebra, go for CS: the theory will teach you how to avoid exponential slowdowns of code, among other things.
* You didn't mention it, but a Software Engineering degree can be one of many things. It can be a CS degree with some computer engineering thrown in, or it can be a Software Development degree with a focus on development methodologies and best practices. It varies greatly from one institution to the next.
* Cyber security will always be in demand, because there are never enough security experts who are actually good *and* have the patience to stick with it. If this is of interest to you, it's an amazing option. To me, though, it sounds like torture.
* Data Science is really a statistics degree with some programming thrown in. It's very helpful if you want to build big AI models, but you actually don't want to do that, even if you think you do. Trust me. DS mostly involves cleaning data and designing statistical models, but it changes often. Heck, it only became a commonly-used term ten years ago. The programming is *much* simpler than general software development, but the statistical analysis can be very tricky. There's been an influx of people rushing into this field lately, then flushing back out because they wanted to build AI, not organize Excel spreadsheets. Good data scientists will always be in demand because every big company/bank/government has tons of data that they want insights from."
682,Does anybody know what PCI Express version the PS3 slim or super slim used?,"[1.0 with 4 lanes](https://www.psdevwiki.com/ps3/PCIe)

Why tf does the PS3 have PCIe"
683,Introduction to Algorithms: A Creative Approach Question,"Okay, so to clear this up:The point of this exercise is for you to get to know what deadlock means and how to recognize it in the code.

A deadlock happens when the execution comes to a halt due to processes waiting for each other in a cycle.

The numbers you are seeing represent a graph, where each pair defines an edge.A deadlock happens if there is a cycle on the graph. A very simple example:

process A waits for process B and process B waits for process A.In a graph this is represented as

a -> b -> a. This created a cycle:

In your exercise this would be (a, b), (b, a).This process will never finish because A has to wait for B but for B to finish A has to finish too, but since they are waiting on each other, none of them will finish---thus a deadlock.

You are supposed to look for such cycles in the exercise.

NOTE: The cycles in your exercise could be huge. So make sure to analyze them carefully."
684,Computer Science Simple Job Recommendations,"i guess the question is what did you really want to do? software touches almost everything these days so maybe you can take some classes in areas that you are interested in (assuming there is a software angle to it), and work your way into that. going into management might be a good use of your degree since it's useful to understand what your team is doing but not necessary to be actually slinging code. you could also look at the operational side of the house if that interests you."
685,Need a small advice about programming?,"You might want to look up scheduling algorithms:

[https://www.guru99.com/cpu-scheduling-algorithms.html#:\~:text=Six%20types%20of%20process%20scheduling%20algorithms%20are%3A%20First%20Come%20First,%2C%206)%20Multilevel%20Queue%20Scheduling.](https://www.guru99.com/cpu-scheduling-algorithms.html#:~:text=Six%20types%20of%20process%20scheduling%20algorithms%20are%3A%20First%20Come%20First,%2C%206)

Please keep in mind that scheduling is done on a single machine. What you are looking to implement is exactly the same but over the network. 

Once you learn those algorithms and decide which one to use, it shouldn't be a problem and implementing it over the network is just a detail.

Andrew S. Tanenbaum - Modern Operating Systems is also a book I would recommend for you. There is a chapter about scheduling which explains these algorithms extremely well."
686,can Amortized bound be worse then worst case bound?,"The idea behind amortized analysis is that you observe an entire sequence of operations.

For example, Dijkstra's algorithm uses a priority queue. These commonly have O(1) insertion time and O(log n) for delete-min. However, most currently existing implementations of priority queue require amortized analysis to meet this boumd. Since the queue is entirely created and consumed through a run of this algorithm, we can replace the true cost of each invocation with the amortized cost.

The idea behind amortized analysis is that you manage an ""account"", into which operations can put ""time"". Consider for example dynamic arrays, which need to grow. A common implementation grows the vector so that you re-allocate (and copy) roughly every time the number of stored items doubles.

Thus, you consider each insertion to also put two units of time into the account. When you then need to copy, you have doubled the size compared to the last copy, so you have enough time in the bank to pay for copying the entire array to the new location. Thus, the amortized cost of insertion is O(3), since you have O(1) for the actual work plus 2 units of time. The actual complexity is O(1) mostly, but sometimes it's O(n). Now, of course, O(3) = O(1) so we have shown that the copying occurs rarely enough for things to still be O(1) in the long run. Formally, the time account always has ≥ (number of stored elements - capacity/2) units of time.


It should not be too hard to imagine that this accounting trick can easily ascribe more or less arbitrary costs to operations.  You can argue that the above is an example because the cost of insertion turned from O(1) to O(3). Here, it turns out that this does not matter asymtotically. But nothing in principle prevents you from ascribing significantly larger costs to some operations so that others become significantly cheaper.

Unfortunately I could not find an example where that makes sense."
687,Do AI gonna replace Software engineers?,Of course.
688,What degree for UX/UI?,[deleted]
689,Sorting - problem from Skiena Algorithm Design Manual book,See [Solution Wiki](https://www.algorist.com/algowiki/index.php/4.9).
690,"If a third party signs the X.509 certificates for TLS, then how does the server get authenticated to the client?","There are two related issues here:

1. How does Bob know a message came from Alice's keypair

2. How does Bob know that Alice's key belongs to Alice

Your understanding of the first problem is correct. When Alice signs a message, she encrypts with her private key, and Bob decrypts with her public key, and now we can confirm the message really did come from someone holding Alice's private key.

But how did Bob come to possess Alice's public key in the first place, and why do we trust that it really came from Alice, and not a malicious third actor like Mal running a man-in-the-middle attack? To solve _this_ problem, Alice gets her public key signed by a trusted third party like Verisign or Thawte, which we call a Certificate Authority (CA). The CA vouches for Alice, and confirms who she is before signing her public key. Now when Bob receives Alice's signed public key, he knows it's legit because it's signed by a trusted CA.

As to how Bob can trust the CA, Bob's computer came with a list of certificate authority public keys baked into it, so assuming the list of keys that shipped with your operating system is trustworthy, and that every CA is trustworthy and only signs public keys they should, then we're okay."
691,"An engineer told me computer science is dead, that there is no future in it, how true is this?",your friend is a complete moron. find a new one.
692,What viable problems in Distributed Systems could I tackle in my Undergraduate Thesis? Details below,"i posted a question on the NANOG mailing list the other day about Starlink whose new birds are capable of intra-satellite routing. the question is whether they can apply standard routing protocols to the problem since the the satellites are moving around so routing updates would be very frequent. a very interesting discussion ensued and is quite fascinating. there were multiple answer and a lot of pointers to work elsewhere (mainly IETF, i think).

not sure if this is the appropriate level for you thesis, but it would probably impress your prof.  a simple model that tries to navigate the tradeoffs would be pretty neat, imo."
693,Difficulty wrapping my head around Matrix Chain Multiplication,"If you have two matrices, let's call them A and B, and you want to multiply them together, you'll find that's actually quite a lot of work. 

Let's pretend for the moment that A has 3 rows and 4 columns, while B has 4 rows and 5 columns.

To calculate R = A x B, you will need to perform:

* 3 x 4 x 5 = 60 total multiplication operations, plus
* 3 x (4 - 1) x 5 = 45 total addition operations

In other words, it'll take 105 arithmetic operations in total. The resulting matrix R will have 3 rows and 5 columns.

Now.. imagine we have a third matrix C, having 5 rows and 2 columns.

In order to calculate R = A x B x C, we have a couple of options:

1. We could calculate A x B first, and then multiply the resulting matrix with C.

2. We could calculate B x C first, and then multiply the resulting matrix with A.

Let's explore which one would be more efficient. 

Option 1:

We've seen that A x B requires 105 total arithmetic operations, and results in a matrix of size 3 by 5. 

Multiplying this new matrix by C will result in an additional:

* 3 x 5 x 2 = 30 multiplication operations
* 3 x (5 - 1) x 2 = 24 addition operations.

In other words, it'll take **159 arithmetic operations** in total to calculate A x B x C if we start with A x B.

Option 2:

Calculating B x C will require:

* 4 x 5 x 2 = 40 multiplication operations
* 4 x (5 - 1) x 2 = 32 addition operations.

The result of this will be a matrix having 4 rows and 2 columns. Multiplying this new matrix by A will then require an additional:

* 3 x 4 x 2 = 24 multiplication operations
* 3 x (4 - 1) x 2 = 18 addition operations

Thus, calculating A x B x C by starting with (B x C) first will require a grand total of **114 arithmetic operations.** This option saves us some work.

---

Let's say you have a long chain of matrices to multiply:

    R = A x B x C x D x E 

and you're given the different sizes of each of the matrices:

    A is 3 by 4
    B is 4 by 5
    C is 5 by 2 
    D is 2 by 6
    E is 6 by 3 

your job is to find out:

1. Which order of multiplying the matrices will result in the most work - i.e., the largest number of total arithmetic operations needed to get the final result?

2. Which order of multiplying the matrices will result in the least work - i.e., the smallest number of total arithmetic operations needed to get the final result?

3. Are there two distinct ways to multiply the matrices together, such that the number of arithmetic operations is the same either way?

In order to answer these questions, you could ""brute force"" this by trying all different possible combinations of carrying out the multiplications:

* (((A x B) x C) x D) x E
* ((A x B) x C) x (D x E)
* (A x B) x (C x (D x E))
* (A x B) x ((C x D) x E)
* A x (B x ((C x D) x E))
* A x (B x (C x (D x E)))
* and lots **lots** others

This will work, but is rather slow & inefficient. You'll be recalculating the same things over and over again. For example, notice how often (A x B) is grouped together in the above list? There's no need to constantly recalculate the number of arithmetic operations for (A x B) over and over for every combination which uses this.

Dynamic programming is just like brute force, but where you save all the results of your intermediate computations so you don't have to keep repeating them. 

----

>that there's 3 ways to do matrix chain multiplication recursion with memorization, divide and conquer and dynamic programing but i keep looking at the pseudo code for all 3 and they absolutely look the exact same. 

The ""divide and conquer"" algorithm I think you're referring to is for the process of actually carrying out the matrix multiplication. This isn't what your problem asks for. Your job is simply to find the most optimal way of grouping the matrices so as to minimize the total number of arithmetic operations that would be required if you were to multiply them.

Recursion with memoization and dynamic programming are fundamentally the same thing. It's no surprise that the pseudocode would look similar. 

---

I hope this has given you a better overview of what the problem asks for."
694,Looking for original-ish source for L3 and L4 microkernels (crossposted from /r/DHExchange),"if you want a \*really\* obscure OS, you can read about mine. basically it was a multithreaded OS before the term threads was coined :)

[https://rip-van-webble.blogspot.com/2020/12/how-to-build-laser-printer-from-nothing.html](https://rip-van-webble.blogspot.com/2020/12/how-to-build-laser-printer-from-nothing.html)"
695,Looking for ways to teach Windows and other OS features in a school using Chromebooks.,"Good for you for trying to teach actual useful computer-y things!

At my kids' school, they have no idea what they are doing with the tech. Throw 1000 chromebooks at em and everyone thinks it just magically makes them know how to use computers.

My eldest is in a ""computer science"" course and all they do is slowly step through a beginner Java book using Dr Java, and the teacher doesn't have any clue what anything is. He apparently spends most of the class looking over the kids' work via Go Guardian because, ya know, wandering around the class to help all 12 kids in person is too hard. 

Would love if someone was even exposing these kids to stuff like you are asking about.

SOOOOOO aggravating!

I don't have an answer for you though...."
696,"Computer science majors, please help. What are crucial factors in deciding the size of dots that make up computer screens?",This isn't actually in the realm of computer science. It's a question for whoever handles manufacturing displays. Physicists? Chemists? Honestly I don't even know who does that work.
697,Are you afraid of AI replacing us in the workforce?,"If Chat-GPT were actually *correct* and not just a language token continuation machine I'd be more worried, but that's all it is, and programming is something it cannot do for anything beyond the absolute most trivial."
698,Help for frequency count method for algorithms,"To generate the list, range(N) has to do N+1 checks to see if it has reached the end of the list.  N of them return true so it continues producing numbers, and 1 of them returns false so it exits."
699,If anyone knows the answers pls help me out and thank u in advance,You're literally posting your test or homework for us to do for you?
700,Question from CLRS Problem's solution: (Exercise 9.1 - 2),"The first comparison, where a <= b, you can remove an item from both sets. The second comparison will only allow you to eliminate one item from one of the sets. As far as comparisons go, the first one is the best of the options as far as progress towards the end state."
701,"I'm trying to understand the CORDIC algorithm for finding SIN and COS, as laid out in the Cordic for Dummies PDF on eit.lth.se. I got the correct answer for COS, but the result for SIN is way off and I can't figure it out. Can anybody here help?","I don’t know if this is the right subreddit to be posting this in, if it’s not I would greatly appreciate being pointed in the right direction"
702,searching for map data structure with efficient bulk operations,"First let me comment on some of the things you said:

&#x200B;

>hash table which in theory has an amortized efficiency of O(1) \[...\] , but that's just theory and may look different in the real world

Not really as long as you don't use naive hashing algorithm. You need to worry about it if the keys are chosen by outside actor who may maliciously choose them such that you get tons of hash collisions.

&#x200B;

>Also there is a memory cost based on the load factor

Yes, but if you use good implementation of hash table it will be similar (or even better) memory wise than good implementations of tree based structures and in general is not really something you should worry too much about.

&#x200B;

>An efficient sorted traversal would be a nice extra, but I may also keep a sorted array of keys

There is a problem with that statement. If you have hash table with sorted array of keys the time complexity of operations changes. In that case time complexity is the same as if you just kept data in sorted array to begin with so you no longer have amortized `Θ(1)`, unless you don't update that array every operation. If you need fast traversal you likely will be better off using some tree implementation.

&#x200B;

>Expected size of D should be a couple million entries and expected size of K should be a quarter of a million keys for queries and inserts/updates. Removes are most of the time done with fewer keys.

I don't think you will find anything significantly better complexity wise than trees and I don't know of any known specific data structures that specializes in what you want. However I have an idea of data structure that might be fast in practice for what you want depending on how exactly is it used:

Keep the data in sorted array. The operations are implemented as such:

**Insert**: Do it as if you run merge sort on 2 sorted arrays - it means it will run in `Θ(D+K)`.

**Query**: Iterate over whole data array and query array together in order picking out the values you want (similar how you iterate in merge sort). time complexity is `Θ(D)`

**Update**: Same as **Query**, just do the update on wanted elements instead of saving and returning them.

**Remove**: since you say you do it with fewer keys instead of actually removing them and moving all other elements, just mark them as ""removed"" and actually remove them during next **Insert** operation. This way remove is `Θ(K * log D)` for `K` removed elements (`log D` is from binary search). To not degrade complexity of other operations you might keep track of how many ""removed"" items are in list and if it exceeds some threshold then remove them before waiting for next **Insert**.

Time complexity wise **Remove** operation is same as trees and complexity of Insert/Query/Update will be better if  `D < K * log_2(D)`  but also in practice could be much faster (will depend on a lot of factors and would have to measure this).

Still hash tables probably would be faster, but you have this traversal problem I mentioned which degrades complexity if you keep sorted array of keys and then it becomes worse."
703,Should I pursue this project?,Projects are the second best thing to internships for resume builders
704,What was the size of the internet in 1998?,"This question isn't precise enough to give a good answer to.  Suppose you have a web server.  This web server has 10GB of operating system files, 5GB of web server executables, a 20GB database of which only about 2GB is regularly accessed, and 30GB of web server logs (the sysadmin doesn't clean them up).  How much does this web server contribute to the size of the Internet? Is it 65GB, since everything on it ultimately only exists for the purpose of the web?  Is it 20GB, since that's the total size that could possibly be accessed by someone with a web browser?  Is it 2GB, since that's the size that actually does get accessed on a regular basis?

What about a 100GB internal-only software update server whose only purpose is to keep the web servers updated?  Does that count as part of the size of the Internet, or not?  What about an email server with a multi-terabyte mailbox store - are all those received emails still part of the Internet?  Does it matter if each individual email was sent within the company (maybe just within the _building_) or came from outside?

The essential problem here is that the Internet isn't a data storage device, so measuring its size in bytes is like measuring a blanket in miles per hour.  It just isn't the kind of thing that _has_ miles per hour, and while you can say ""well maybe the blanket is in the back of a pickup truck,"" you're inevitably talking more about the pickup truck than the blanket.

The Internet is ultimately a _network_, whose purpose is to transmit data, not to store it.  So if you want to talk about the size of the Internet, you should talk about bytes _per second_.  Once you do this, the numbers are easy to come by: https://en.wikipedia.org/wiki/Internet_traffic.  In 1998 the Internet carried about 400 terabytes a day.

Of course this is unsatisfying, because it doesn't connect to Russell's claim to have downloaded the Internet.  As anyone who's done activities like this can tell you (e.g. setting up an offline Wikipedia, a local cache of PyPI or NPM, etc), it's really hard to separate a web site's local datastore from its broader behavior and interaction with the rest of the world.  What would it mean to download, let's say, Travelocity or Expedia (both founded in 1996)?  Does it mean you have an empty site with no flights searchable, since in the post-apocalyptic world there are no flights?  Did Russell re-implement the backend APIs to serve up empty results to queries?  Or are these web sites - and essentially every web site - just broken and non-functional in Russell's download?  And again, this makes a difference to the size calculation, because a database of all flights _in 1998_ would be many gigabytes, but a database of flights in Russell's era would be near zero size.

All this aside, if you just want to download _the major reference works_ from the Internet - Wikipedia, the important parts of GitHub (let's say the Arctic Code Vault), Stack Overflow, the various programming language and operating system repositories, etc - it's surprisingly tractable.  A few tens of terabytes will do it, and it's well within the capabilities of someone like Russell even today."
705,Key derivation functions - What is the difference between Key stretching and key diversification?,"Key stretching is increasing the attack time on a potentially weak key by using elements that make the attack harder, like salts and high hash iterations.

Key diversification is a process of deriving multiple keys from the same secret. Rather than being used to slow down the attack on a single key, it is a process that allows some redundancy in the case of one of the keys being compromised - you can stop using that key, but not change your master secret. This isn't a property that's very relevant to most KDFs.

They have slightly different security requirements. For key stretching, it should be hard to recovery the derived key from the ciphertext+salt+iterations. For key diversification, it should be hard to derive other keys from the compromised key. It would be mostly useless (or arguably contradictory, depending on how exactly you define it) to have a system with good key diversification and bad key stretching. However, you could invent a toy model that has good key stretching but bad key diversification."
706,Logical adding and subtracting,"Google ""half-adder"""
707,Is it possible that artificial intelligence algorithms are being trained with my personal documents I have stored in a cloud?,"Possible? Absolutely.

When you leave your data on somebody else's computer there's no way to be sure what they do or don't do with that data.

How likely is it? That depends on the cloud. But one concrete data point we have is Gmail. We know that email in Gmail is processed to target advertising, which almost certainly includes ""training AI algorithms""."
708,How does software interact with hardware,"software interacts with hardware in a couple of different ways

1. hardware registers are memory mapped into the address space. this is usually in kernel mode in the OS. these register are often used to control things, set up transfers or transfer data directly (eg, polling). for you #1, there could be registers to turn the motor and probably a lot more to control it.
2. large transfers often make use of DMA which allows the OS to set up a transfer to its choice of actual memory and the device transfers it followed by a...
3. interrupt. interrupts allow a device to say that something has happened and interrupt the flow of execution usually changing to kernel mode and running on the kernel stack (almost all modern processors allow that). this allows the OS to take action on behalf of whoever is requesting it including users in users space. for things like DMA, it can the processor that the transfer is complete and that it can wake the process that is requesting it or whatever else it needs to do. for your motor example, the interface could allow you to setup a speed and duration, where the motor interrupts to tell you it's done.

hardware is often run over well defined busses which the OS can manipulate and gives a more uniform protocol between device and OS, like say PCI.

as for 3, that's the OS's job to keep track of who is asking for what. processes at some level are a software construct from the OS, though it heavily leans on hardware like MMU's to carry that out.

as for 2, kernel mode is typical but not strictly required. you don't have to have an MMU to write an operating system. busses are usually the way that plug and play works. the device will be assigned an id so the OS will know which driver to load for it. but OS's have tons of drivers that they don't load unless they are needed to keep the memory footprint down"
709,What can i do to get into a proper online master of science in computer science program (such as the one from either georgia institute of technology or university of texas) with my credentials? Is it possible for me to make up for what i'm lacking through effort?,"https://omscs.gatech.edu/preparing-yourself-omscs

This link shows for applicants that do not have a degree in CS the bare minimum requirements for entry when you have a degree like yours."
710,Is automata theory essential in a CS degree? Will learning it make me a better programmer?,"For a CS degree? I'd think so. A lot of it ties into parsing, compiler instruction, and talking about different models of computation.

At least some of the ideas can be adapted into design patterns for solving problems in programming."
711,"Looking for form software that will allow different customers to add individual custom pieces to a list, then export that to excel.",This is not the right subreddit. Maybe r/software or r/techsupport? This subreddit is for asking about the academic discipline and theory of computer science.
712,wish of these is considered Theoretic Computer Science and Computer Engineering,"So I dont know why you want, to sort them, and it would probably be better to understood what the topics are since the divide is not so clear cut. also computer engineerting is typically used to refer to computer architecture/electronics type stuff, but I'll assume you mean software engineering as well.

&#x200B;

\*Introduction to Algorithms : Theoretical Computer Science, tends to be about solving algorithmic problems in psuedocode, proving correctness mathematically, and analysing runtime - all very theoretical, nu computers involved.  
  
\*Coding and Representation of Information : this could either be information theory and stuff like error correcting codes, or programming and representing information for programming, the former is more theoretical, but very useful for engineering purposes, the latter would be computer engineering  
  
\*Programming and Data Structure: a bit of both, programming, is more engineering, data structures can be a bit theoretical, but overall I'd say this is engineering  
  
\*Machine Structure: no ide what this is, ill assume its computer architechture, in which case its computer engineering  
  
\*Architecture I: computer engineering  
  
\*Algorithms and data structures: theoretical computer science  
  
\*Graph Théory: theoretical computer science, graph theory is literally maths  
  
\*Operating Systeme: computer engineering  
  
\*Compilation; computer engineering (but it can have a bit of theory)  
  
\*Networks: computer engineering  
  
\*office automation: uhh, what? id say computer engineering, but it really isnt  
  
\*Mathematical Logic: Theoretical computer science  
  
\*programming tools for mathematic: hmm, I'd say more theoretical since its being used for maths, but the tools are engineering  
  
\*Rad TOOLs: damn y'all got rad tools, where can I take this module.I'd assuming engineering because it says tools, but i have no idea  
  
\*software engineering I : its in the name, engineering  
  
\*Data Bases I : engineering, but it might include relational algebra which is theoretical (and Im not sure if its even used for anything :skull:)  
  
\*Object Oriented Programming: engineering  
  
\*Information Systems I : engineering  
  
\*web programming: engineering"
713,What are the name of these ports?,Those are display port and is generally the go to nowadays for higher resolution/refresh rates
714,"Where does the name ""assembler"" come from? I find it a bit confusing since the way I see it it does the opposite of assembling: it breaks mnemonics down into binary","> The term ""assembler"" is generally attributed to Wilkes, Wheeler and Gill in their 1951 book The Preparation of Programs for an Electronic Digital Computer,[9] who, however, used the term to mean ""a program that assembles another program consisting of several sections into a single program"".[10] The conversion process is referred to as assembly, as in assembling the source code. The computational step when an assembler is processing a program is called assembly time. 

[Wikipedia](https://en.wikipedia.org/wiki/Assembly_language)

It's not clear, but I'd suppose that the exact meaning evolved. I wouldn't say that it breaks down mnemonics into binary; I'd say that it assembles the program out of the mnemonics."
715,Signed binary number,Binary numbers usually have a fixed length and the signedness is determined by the leftmost bit.
716,Random Number Table at runtime,"There are purpose-built hardware RNGs that sample atmospheric noise or quantum effects or whatever. Some people have conjectured that high-quality digital cameras actually behave as quantum hardware RNGs in that they are so sensitive that quantum randomness will tend to adjust the color channels by at least 1 bit in at least 1 pixel across the entire image. Even if you don't have a sufficiently sensitive camera for that, you can still point a webcam at something with unpredictable behavior (such as an aquarium full of goldfish), hash the video frames together with their timestamps, and use the hash values as seeds for your PRNG algorithms, which would give you a highly effective hardware RNG."
717,Can GPUs replace CPUs?,"Firstly, let's clear up a misconception: GPUs are not powerful. In fact, one-for-one CPU cores are considerably better than GPUs.

The trick is that a CPU has 4-12 extremely powerful cores. A GPU has 2000-8000 weak cores.

It's like comparing a single rocket scientist to a thousand middle schoolers. If you need to project the movement of solar bodies, the former will be a lot better. If you need to do 1000 addition problems, the children will get it done faster.

That's what a GPU is doing. It does a lot of really simple calculations at the same time. Each one is slower, but collection faster.  This is useful when you need to do a lot of things that don't depend on each other. But as soon as one calculation depends on another, then you can't do them all at the same time anymore. Then there's no point in using the slower cores.

There's other complications too. For example, GPUs have much fewer security features than a CPU and in general motherboards are designed in such a way that a CPU is required."
718,Do CPU manufacturers also provide a assembly language designed for the particular computer they sell? Do OS developers also design assembly languages ?,"I think you need to read up on how a CPU works to fully answer your question. In short: The only way programs can run on a CPU is if their instruction set is known. The instruction set can be represented textually and more abstractly in the form of assembly language.

I have a stock answer for ""how does a CPU or OS work?"" that I'll spam below. The short answer is read [**Code** by **Charles Petzold**](https://www.amazon.co.uk/Code-Language-Computer-Hardware-Software/dp/0735611319). But to focus on a specific point:

>  Also, is this standardized?

Apple and Intel/AMD both have standardized platforms. A short (and probably incorrect) history lessons would be: Back in the olden days (pre-80s) all computers were bespoke platforms with specific motherboards, ram, cpus etc. You could hack mods on if you knew what you were doing (which frankly, the people buying computers then did).  But soon the average lay person and almost all business started to buy computers, and so IBM looked to set out a standard computer. They came up with the ""IBM PC"" that used Intel components (they wanted Motorola but the 68000(?) wasn't ready in time) and Microsoft was meant to make the O/S for that (O/S 2). 

But, as is life, this all changed, and eventually DOS and Windows came out running in the same environment, and everyone copied it and simply claimed their PC was ""IBM"" compatible, and then soon everyone was selling PCs that ran Intel chips (or clones like AM) on Intel spec motherboards using a wide variety of components that all used the same protocol and that's what became today's ""Windows PC"".

Apple took their own route, but no-one bothered to clone their architecture, which is interesting.

But today Windows 10 will run on a few specific CPUs: All mainline Intel after a certain generation, ARM for certain generations (but possibly only from Qualcomm?), and a few of the weirder Intel ones. They're compiled separately for Intel and ARM. Don't be too confused about there being a lot of different Intel chips with different names. They can all run the same code that the 486 originally did (hence the name x86). Each new [generation](https://en.wikipedia.org/wiki/List_of_Intel_CPU_microarchitectures) simple adds in more features to the instruction set. Microsoft simply pick a line in the sand for [Windows 10](https://learn.microsoft.com/en-us/windows-hardware/design/minimum/windows-processor-requirements) and [11](https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-supported-intel-processors) and say ""this is the oldest thing we'll run on"", and so use the features present from then onwards. (They might also optimise and include features on your later core, but I'm not sure on that).


---- 

As for [my stock answer](https://old.reddit.com/r/computerscience/comments/zv4klo/how_to_study_computer_architecture/j1n25nj/) for question about ""how does a CPU work?"":

Can you answer the questions

* What *is* a computer?
* How do we build an electronic one?
* What is an operating system, and how are they made?

They look simple, but it's surprisingly difficult to give something more than a very trivial answer. From your post it sounds like that's what you're asking, basically. You want to know what the physical machine is doing, how it's controlled, and how the compiled executables that you write is somehow executed on it via an operating system.

If you want to learn about CPUs, computer architecture, computer engineering, or digital logic, then:

1. Read [**Code** by **Charles Petzold**](https://www.charlespetzold.com/blog/2022/08/Code-2nd-Edition-Now-Available.html).
2. Watch [Sebastian Lague's How Computers Work playlist](https://www.youtube.com/playlist?list=PLFt_AvWsXl0dPhqVsKt1Ni_46ARyiCGSq)
2. Watch [Crash Course: CS](https://youtube.com/playlist?list=PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo) (from 1 - 10 for your specific answer, 10+ for general knowledge) 
3. Watch Ben Eater's [playlist](https://www.youtube.com/playlist?list=PLowKtXNTBypETld5oX1ZMI-LYoA2LWi8D) about transistors or [building a cpu from discrete TTL chips](https://www.youtube.com/playlist?list=PLowKtXNTBypGqImE405J2565dvjafglHU). (Infact just watch every one of Ben's videos on his channel, from oldest to newest. You'll learn a lot about computers and networking at the physical level)
3. If you have the time and energy, do https://www.nand2tetris.org/, but note that this is intended as a capstone course at university, and it's intended that students already know a lot of this but then use that knowledge in a practical application and spend a few months building all of the hardware/software involved. You can do it on coursera, and it's all free. It's a lot of effort, but also a lot of reward. Reading Code and watching all the videos is much quicker and might give you want you wanted in a quicker timeframe.

There's a lot of overlap in those resources, but they get progressively more technical. Start at the top and work your way down. The Petzold book alone is worth its weight in gold for the general reader trying to understand computation. **Most people can read that and will be completely satisfied when it comes to learning about computers**. A second edition has *just* been released after 20 years. You can get digital copies of it easily, but it's not yet in stock in many places. The [first edition](https://www.amazon.co.uk/Code-Language-Computer-Hardware-Software/dp/0735611319) is absolutely fine to read as well. Assuming you don't wish to buy it from those links above, it's easy to find via google :)

For specifics about operating systems, do what [teachyourselfcs](https://teachyourselfcs.com/#operating-systems) says and read any of these:

1. Andrew S. Tanenbaum - Modern Operating Systems
2. Silberschatz et al - Operating System Concepts
3. Operating Systems: Three Easy Pieces  (it's free!)

All of these resources will let you understand *what* a computer is and how a CPU, GPU, RAM, etc works. It will also give you the foundational knowledge required to understand how a OS/Kernel works, how software in general works etc. Arguably it will also give you the tools to design all of how hardware and software components, though actually implementing this stuff will be a bit more involved, but easily achievable if you've got the time. nand2tetris, for example, is specifically about that design journey. (And if you follow Ben Eater's stuff and have $400 to spare, then you too can join the club of ""I built a flimsy 1970's blinkenlight computer on plastic prototyping board""). For os you can also hit up /r/osdev and the osdev wiki to learn more if you want to get involved in that. However all of these resources are aim at technical people who are looking for deep knowledge of OSs. Reading *Code* and watching the *Crash Course: CS* youtube videos above might be enough to satisfy your curiosity, so start with those first.

Learning this stuff will make you much better programmer and computer scientist than if you didn't learn it, and you'll be better at debugging and solving problems you have whilst writing software, but fundamentally it'll also make programming much more satisfying as you'll understand every single part of the stack from electron to e.g. python.

(It's also all stuff that was on the syllabus on my Computer Science course 15 years ago, and I'm disappointed to see it's not taught as widely these days as the syllabus has shifted towards AI and stuff. At least Computer Engineering courses are more widely available now, as this stuff is the bread and butter of a CE syllabus)"
719,DSA with JavaScript,Yes of course.
720,"Cascading Search - Or, what would you call it?","This is an application of fuzzy logic, and it may be a form of fuzzy string searching. Searching on 8 parameters with results that satisfy all 8 parameters is considered an exact match. If only 7 parameters match, then it's an 87.5% match, and it will be ranked below the 8/8 results. There are ways to detect how near one string is to another with metrics like Levenshtein distance. There are many other metrics for detecting text similarity out there."
721,I Struggle With Organizing My Ideas In Big Projects. What's the Best Way To Do It?,I sometimes like diagraming my ideas. I use draw.ok a lot
722,"[Noobie] Hashing algorithms: Isn't the whole point of non-deterministic algorithms to always produce different outputs, given the same input?","Note that at its core, bcrypt is still deterministic. It's just that the hash you get is not just the hash, but a combination of hash, salt, and some other stuff (like iteration count).

When hashing something with bcrypt, a random salt is generated, which is the used to compute the actual hash and saved with that hash.

When checking a hash against a plaintext, you do not generate a random salt but instead use the one saved with the hash.

The idea is that this is easier to deploy then manually generating a salt.

For BCrypt, the salt is 128 bits, so you have a chance of 1 in 2^(128) that you get identical hashes, which is quite unlikely to occur in practice. And either way, it's better for this to be unlikely then to occur all the time, which is what happens when you do not salt your hashes at all. So it's a security improvement, and not really a weakness."
723,How to get into AI development,"Lookup Fast AI course, it's the best resource I've found on this so far."
724,ELI5 why I can't run 2 Operating Systems at the same time on the same computer with two different display devices and switching from one to the other with a mouse / keyboard?,"Because the two operating systems would be sharing a CPU and memory, and they would therefore need to know how to share it. It is incredibly difficult to design an OS this way.

Instead, we use a lightweight base OS called a *hypervisor* to *virtualize* multiple OSes at the same time without those OSes knowing about it. This is done all the time on servers.

If you want to do it on your home computer, though, it's best to just look at installing some Virtual Machine software like VirtualBox. Run one OS as the *host* and the other as the *guest*, and then set the VM to fullscreen on a second monitor."
725,"May I ask if someone is familiar with that site where once you run a code, it will show/indicate which step it is currently executing?","This is called a symbolic debugger, which is typically part of an IDE (Integrated Development Environment).  Jerbrains PyCharm is probably the most popular one.  It's not open source but is a free download for personal use.  If you're specifically looking for something that's a web site, maybe try Codenvy."
726,"""If you're not paying for a product, you're not the customer. You and your data are the product."" Just how solid is that, exactly?","When software is free, companies *typically* either sell space for advertising, information about user activities within their app, or something related to those. So as far as the business is concerned, your attention and information are the products that they're selling, and their customers are whoever's actually giving them money for it.

Some exceptions:

- If the program is a loss-leader for something else they expect to sell you

- In a lot of cases, open-source software is written and provided for free

> Every app I've ever used has been free, but isn't that normal?

It's really common now, sure."
727,Books Recommendation,For AI I recommend you to read 'Deep Learning' by Ian Goodfellow
728,Books for starting in computer science,"> Before starting to code I would like to understand how everything works

That's going to be almost impossible. But you can learn as you go.

If you want a complete explanation from scratch, I might recommend *The Elements of Computing Systems*, along with its companion course, nand2tetris.

[Book](https://mitpress.mit.edu/9780262539807/the-elements-of-computing-systems/)

[nand2tetris website](https://www.nand2tetris.org/)

[Part 1 lecture videos](https://youtube.com/playlist?list=PLrDd_kMiAuNmSb-CKWQqq9oBFN_KNMTaI)

[Part 2 lecture videos](https://youtube.com/playlist?list=PLrDd_kMiAuNmllp9vuPqCuttC1XL9VyVh)

Starting from basic logic gates, the course has you specify a full computer system to its specification (the ""Hack"" specification) and define a basic high-level language (""Jack"").

Part 2 requires that you write some programs to compile, translate, and assemble high-level Jack programs down to Hack binary code. You would need to start learning at least one language to accomplish this. Python would be my first recommendation since it has straightforward syntax and has several useful text handling utilities. It's also popular enough that you should be able to find answers easily if you get stuck."
729,Why am I getting this output? (Java),"You probably meant to print matrix\[0\]\[0\] , not matrix\[0\]"
730,Moroccan university contains a link to USA university. What is this about?,Is there a missing page-image or link I'm not seeing?
731,What are some newest advances/papers in database technologies worth looking into?,You might be interested in the proceedings of the annual VLDB conference: http://vldb.org/pvldb/volumes/15/
732,Is there a way to make an AI like ChatGPT to believe in a wrong answer?,"Yes, ChatGPT gives false answers to most questions. 

As a simple example, here is its answer to ""What is the square root of the cube of 2?""

""The square root of the cube of 2 is 2. The cube of 2 is 8 and the square root of 8 is 2.""

See also stackoverflow's reasons for banning ChatGPT-generated answers, because ChatGPT can generate wrong answers much faster than human beings can check them:

https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned

Getting an AI to give wrong answers is not difficult. Writing an AI that only gives correct answers would be a much, much harder problem."
733,What is the best monitor layout including an ultrawide. I’ve been debating this for a while now,Smart okay
734,is there anything else stored in computers hardware apart on hard drives ?,"Many components store their own firmware, the bios/efi on the motherboard, and RAM while the computer's running, of course. Those all store smaller amounts of data than a hard drive or SSD usually does."
735,How unsafe is it to store your sensitive personal data on a textfile locally on your pc?,About as safe as printing that file out and laying it on top of your desk.
736,how to get an internship? it is bad to not get one? (computer science),"I’m assuming you have a decent foundation of DS & A going into this, if not focus on that first and leet code is much harder without that prior understanding.


Try and solve the problem first, even suboptimally. Give yourself 30 minutes to try and think about the problem and get some initial code down. After 30 minutes, if you’re stuck look up a solution, but if your timer stops and you’re on a roll, keep going. Either way, implement a solution with or without outside references .  Personally I learn next to nothing by just reading an algorithm, so I need to implement it for it to sink in. Once you’re done, compare what you have to the reference solution. Don’t just memorize their answer, think about why they made the decisions they made vs the ones you made. Leet code is a skill that can be learned with practice. 

Re internship: personally, entering my senior year I hadn’t had an internship and I intentionally took 1 less class per semester my 4th year to extend my graduation date and give me an additional summer for internship. This isn’t necessary for all internship programs (and the company I ended up interning with would have allowed me to intern the summer after I graduated had I graduated on time), but it allowed me to finish a minor I was interested in and have a less hectic senior year. Anecdotally, this worked for me. As an essentially graduated student I was much more competitive and competent in interviews and I got an internship that summer and they ended up offering to extend my internship half time during my last semester and then gave me a full time/permanent position after I graduated. It was a gamble as i was committing to paying for the last 8 units/2 classes in my fifth year, but in my case it worked out.

Being in industry for almost 10 years now, I vastly prefer working with college hires who have had an internship over those without (BS with internship > MS without). Many university programs don’t teach skills that are necessary in a professional setting (git, code reviews, etc) and it’s easier to get them up and running if they already have those foundations."
737,Amazon Apps Not Working,"Hi Dave, try posting to r/techsupport. This sub is meant as more of an AskScience style sub for the academic field of computer science rather than a technical assistance forum."
738,Is the main reason why programmers are paid so well because it's not easy to learn?,"there is \*so\* much more to being a software engineer than just writing code, most of which you don't learn in school. senior engineers have to take all of those lumps to get where they are.

i wrote this (incomplete) blog post to underline why it is not easy:

[https://rip-van-webble.blogspot.com/2021/08/some-of-things-you-get-thrown-into-when.html](https://rip-van-webble.blogspot.com/2021/08/some-of-things-you-get-thrown-into-when.html)"
739,Top programming languages used in the AI industry?,"hardly an expert here, but it seems like tons of people are using python as a wrapper to the GPU based stuff which is where the real action happens. if you're just trying to use it as a tool python is probably best, though if you actually want to work on the algorithms powering the neural network emulation, you need to understand what they've written that in (isn't it a C-like language? i forget)."
740,Do classic thermostats with bimetallic strips meet the definition of artificial intelligence?,What definition are you using and why do you think classic thermostats with bimetallic strips would meet that definition?
741,How do modern CPUs handle illegal or undefined operations?,probably the same way that they always have: throws an exception
742,CS domians/careers that intersection with Library & information science,Yes. Many IS schools have CS faculty and technical components to thier programs. Many areas of research intersect.
743,ELI5 -GPT-3 context window.,"When you are talking with someone, you remeber what you talked about 5 minutes, 10 minutes, 2 days ago. Further back in time less details you remeber. Once any meaningful details of the dialog have been lost in the past, this is where your context window ends. So context window is how far back people (or other neural networks) remeber the current context. We, humans, have a quite big context window, that may span years, though only most memorable pieces of information remain far back in time. Bigger context window allows for better conversation flow, and allows model to not forget what was said in the past. Imagine talking to someone who remebers only last minute of your conversation!

Digging a bit deeper, bigger context window allows for better conditioning: if you say to gpt3, for example ""translate into french"", and then give some examples, the more examples fit into its context window, the better it can understand what you want. Imagine if context window was very small: by the time it will read the examples, it may forget the task itself!"
744,How to prove a code is uniquely decodable?,"What does uniquely decodable mean? I realize I could google that, but explaining it here might help you (and, more importantly, help me)"
745,I would like to be able to solve Competitive Programming problems. What are the resources for this?,I suggest you look at this very comprehensive and *awesome* list: https://codeforces.com/blog/entry/23054
746,Are there any CS careers that blend with a law background?,"IP lawyers immediately come to mind, and especially patent lawyers. they require the lawyer to translate from geek to patentese which geeks are pretty incapable of. good ones know how to broaden the claims as much as possible too. 

but being on staff as a tech company lawyer it certainly doesn't hurt to have clue about CS and hardware if they make it."
747,Best way to build experience as a freshman w/ FAANG intentions?,"Honestly, as a freshman, you don't need to worry too much about this just yet. Try to get an internship or 2 under your belt over the course of your education. 

Also, network network network. Make lots of friends in the computer science department - classmates, upper classmen, Professors, TAs, etc. Add them on social media and LinkedIn

Why? When you graduate, at least *some* of those people will get into big tech. You can then reach out to them for referrals. Big tech typically has a good referral system where employees get bonuses for successful hires. 

A referral for a technical position usually results in an interview, so it bypasses a lot of the barriers usually present when trying to get an interview

Then just practice leetcode style problems until you can pass the interview"
748,Is there a genetic algorithm where chromosomes compete against eachother?,"Maybe overkill, but this sounds like a good candidate for a [random forest](https://en.m.wikipedia.org/wiki/Random_forest). You may also look at gradient descent.

This all roughly sounds like a statistics problem, where you're trying to find the optimal coefficients for a linear equation."
749,"At what point does the code I write actually ""turn into"" electrical current in the transistors ?",The moment you press a key on your keyboard you have fired countless transistors.
750,Why do as-you-type search suggestions change while I keep typing the exact suggested term?,"It might also take into account that it offered you that completion but you didn’t take it. 

That might be a good choice for users who pay close attention to the suggestions and a worse choice for those of us who keep typing until we get stuck."
751,Languages & Resources for a Random Generator?,"Efficient or inefficient will depend on a lot of aspects about how you use it. If you're list of options is reasonably small (and I mean something like less than 10MB, which is a huge amount of text), you're probably not going to care what format it's in. You can read the whole thing into a list of strings and pick one. Also, it really depends on your application. If you're running an app evertime you want to generate, the startup overhead could easily be larger than the actual work.

A database definitely could be faster (although there are tradeoffs since you have to link in all of the database code you use, which could be pretty large). You could try something like sqlite."
752,How does a service let me know the strength of my password without looking at it?,"The hash cannot be used to judge the strength of the password, except in the limited case of verifying against a small set of common passwords.

They are typically doing it directly in the browser, using javascript to examine the plaintext password."
753,I'm taking a course on penetration testing (legal hacking) and I'm trying to understand how buffer overflow vulnerabilities work,"The only question I got from your text is why is it 40 and not 64.
40 is in hex. 4*16 ==> 64
The hint is in the line numbering. It count 4 items at a time, so 0,4,8 and C."
754,Can neural networks be used to power optimization algorithms?,"Not sure what you mean by this. 

Typically NNs are actually pretty slow. A traditional implementation of whatever the NN is solving (when viable) will almost always be faster and more accurate. 

NNs are great for solving problems where traditional algorithms would be extremely complicated and difficult to write, such as image classifiers."
755,What common optimizations speed up GPUs?,"I'm not quite sure I'm parsing the phrasing correctly. Are you asking what makes GPUs fast? Or about specific optimizations in the graphics pipeline? Or about optimizations in GPU hardware? Or optimizations in the software/driver stack? There's a lot of optimizations across the entire GPU ecosystem, and there's no particular reason changing an individual value of a pixel in memory would be particularly expensive (beyond regular cache access or sync issues), besides the complexity of a given shading model or some programming mistake. What level of background knowledge do you have?"
756,Beginner in Research need help !!,"You could take some NP-complete problem (e.g. traveling salesperson, or matching, or …), and then read up on how people attack it in real-life, what constrained-variants *can* be feasibly solved (or can't), etc.  And if the ""research"" requires original work you can code up your own heuristics plus a known heuristic, and compare performance on large inputs."
757,I can't understand and or xor things in hexadecimal?,One of the key benefits to hexadecimal is that a single hexadecimal digit directly corresponds to a fixed number of bits. Go ahead and write down the conversion table of one hex digit <-> binary.
758,What is wrong with my transition table in my negamax implementation?,"I don't know TypeScript so I may be confused. I think your looking up the wrong board in the transposition lookup. It looks like you're looking up the same initial board every time. You want to lookup *after* you make the move, not before you make the move. Be sure to compute the lookup key after each move.

Unless I'm confused about your depthRemaining variable, I also think your depth check is backwards. 

    if (tableResult.depthRemaining <= depthRemaining) 

You should only use a transposition table entry if the table entry is for an *equal or deeper* depth, and I think this may be checking for *equal or shallower*."
759,Tool to compare Windows 10 VS Windows 11 performance,"Benchmarking software, although a drop is guaranteed if you install windows 11"
760,"What ""discrete mathematics"" do I need for this type theory/programming book?","With respect to the traditional fields of discrete mathematics, you only need knowledge of first-order logic, naive set theory, and fundamental proof theory, in particular, inductive proof.

I think it's reasonable to approach the mathematics requirement bottom-up if you have a suitable discrete mathematics resource to go to. However, I recommend using [Software Foundations](https://softwarefoundations.cis.upenn.edu) instead of TAPL. Volume 1 introduces you to the necessary logical background in the context of the Coq proof assistant, so you get the benefits of machine-checked proof in your learning. Regarding content, SF starts getting to the TAPL content proper around Volume 2 but does not go into as much depth. But at that point, you should be ready to jump into the later chapters of TAPL!"
761,"Can I adapt this script to ""lock"" a string instead of two primes?","See the link to the puzzle on top of the python script. That already describes how to use the result as a one time pad to encrypt a secret. The secret can be anything, including a string. Obviously doesn't work if your string is too long, tho."
762,Does an Arduino or Raspberry Pi make a good gift for a CS major?,Yes. 100%.
763,Question about threading,"In general you must acquire the mutex before accessing the value.  The mutex isn't just preventing obvious race conditions, it also implements the appropriate memory barriers for the architecture to ensure coherent reads and writes.  It will prevent the compiler and the CPU from reordering instructions across the mutex calls that could compromise the operations in strange and unpredictable ways.

There are circumstances where you don't need to acquire the mutex to read the value, but knowing when that situation applies is not exactly simple and requires knowledge of the hardware."
764,is my project too complex for a CS bachelor?,Building _an_ ABM with those components in that amount of time seems feasible. Rigorously defining all the actor parameters and exhaustively exploring the parameter space to describe the system behavior under different conditions would be more challenging. This mostly depends on the specifics of your curriculum and how much detail or analysis they want from you.
765,Floyd Cycle detection- tortoise and hare in linked list,"They might meet if you simply check for equivalence after each increment of the fast pointer, instead of only after advancing it by 2 or 3.
(Robert W Floyd is/was my father.  He taught this algorithm to me when I was 12 and we actually talked about the fast pointer jumping by other increments larger than 2.  I was getting started in C programming at the time and had trouble with pointers.  His loop detection algorithm was exactly what I needed to learn about pointers and linked lists)"
766,What do you use for drawing software architecture diagrams?,Draw.io
767,career advice,"r/cscareerquestions would be a better place to post this.

But also, if you're interested in the medical field, the obvious answer would be to go pre-med and become a doctor. If you don't want to spend that much time/money, then you could become a Physicians Assistant or Nurse Practitioner which require less school and still make over 6 figured in the U.S.

Computer Science is not an easy degree, and if you have no interest in it then you will be absolutely miserable for 4 years.

You also have to stay proactive to advance your career. Youll need to show initiative and be willing to continuously learn in order to get raises and promotions.

If you happen to land a job at a company where they don't require much effort, then you'll be stuck in a cubicle staring at a monitor with zero fulfillment for the rest of your life.

Tldr: If you aren't interested in computer science, then don't dedicate your life to computer science."
768,Unable to understand IRC,"> What actually is an IRC? Protocol or software?

IRC is a protocol. There are also ""IRC clients"" and ""IRC servers"" which are software that communicate using the IRC protocol.

> In eli5 someone comments it's like multi-player notepad. I read that it's like real time messaging.

IRC channels are chat rooms. It's like real-time messaging, but with more people.

> How is it different than whatsapp/reddit chat?

- IRC is not centralized in the same way (anyone can run an IRC server).
- You can connect to an IRC server using any client (or ""app"") that you like.

> Which software/app uses irc protocol?

There are many options. Search engines will help you with this.

> As per my knowledge same real time messaging can be achieved with ftp, isn't it?

Nope. FTP is a protocol for transferring files, hence its name File Transfer Protocol. It's also not even good for that anymore (because it's insecure)."
769,How to have access to people who create software?,"- If you're trying to find computer code to do this, it will almost certainly exist in some form on [GitHub.com](www.github.com). Try searching there. If you have not programmed before, then running whatever code you find will likely be difficult. 
- If you're looking for suggestions on actual computer programs or apps or websites with sports betting software, this is absolutely the wrong place to be asking. Try a sports or gambling forum / subreddit."
770,Alternative names for computer science books,"An obvious one that comes to mind is the ""gang of four"" -> Design patterns : elements of reusable object-oriented software."
771,Help with building calculator on circuit verse,This looks like a homework question. What have you tried so far?
772,It's known to be impossible to create a program that can take in any arbitrary program as input and correctly say whether it will halt or not. But what if we restrict the type of programs allowed as input in some manner?,"Yes.

For example, all [primitive recursive functions](https://en.wikipedia.org/wiki/Primitive_recursive_function) halt, and it's not hard to come up with a set of constraints that guarantee that a function is primitive recursive."
773,HP PA-RISC vs IBM PowerPC,"I worked on PA-RISC machines used as telephone exchange ""IN"" (Intelligent Network) servers in 2002-2003. At the same time I personally owned PowerPC Macs (would have been 1.25 GHz G4 iMac at the time) and also Athlon 1800+ running Linux.

As far as the ISAs are concerned there isn't much to choose between PA-RISC and PowerPC. They both have cool features and weird (non mainstream) features. PA-RISC was I think available in 64 bit a little earlier. Both had SIMD (MAX, Altivec).

The main different was that PA-RISC trailed in MHz, with I think the ones I used being about 200 or 400 MHz, and never exceeding 1 GHz. PowerPC was over 1 GHz already at that time, with dual 2.0 GHz 64 bit G5 Macs coming out.

The PA-RISC machines had only an L1 cache, but it was HUGE .. like 512 MB. This made them good for running software with poor locality of reference, such as database or transaction-processing work.

If you made them using modern µarch and process node then they would of course be much better, but I don't think either has anything to offer over arm64 or riscv64.  In particular, code density sucks on both PA-RISC and PowerPC."
774,"Is it possible, even in principle, to write a program that cannot by deleted by any means short of physically modifying the hardware?","You're not going to find a theoretical CS proof that a program is, in principle, undeleteable (along the lines of the halting problem). The reason is that no matter what abstract model of a computer you're using, with some kind of restrictions on its behavior, it could be emulated by another machine that behaves the same way *except* for being able to change to a different state where the program is absent. 

Instead, this is going to depend on the implementation details of the specific machine you're talking about. It's entirely possible to have a system that is designed to make it impossible for the certain users to perform certain kinds configuration changes.

This could be done at a software level: for instance, if you have a limited (non-administrator) account on a Linux or Windows machine, then it can be effectively impossible to remove software unless you can obtain an administrator password. You could reformat and install a new OS, but the BIOS might be configured to prevent you from doing that without a BIOS password. And so on. (Note that these mechanisms will only prevent changes *if* there are no bugs or security flaws in the permission-checking code.)

You can also prevent changes at a hardware level (although consumer PCs don't normally do this). For instance, microcontrollers have internal flash storage rather than storing the program on a separate disk. And some of them have ""write-protect fuses"" that can be blown after the program is uploaded. Once the fuse is blown, the hardware will irrevocably prevent any further changes from being made."
775,What to do with an old PC,"Aside from just playing around with it to learn stuff, the main thing I can think of in terms of useful function would be to see if you can get the Pi-hole software to run on it.

I know they have versions you can install on a supported Linux distribution. No idea what versions are supported and if you'd be out of luck due to 32-bit issues or something, but it's probably powerful enough to do the job otherwise.

You'd also need a second network interface for that use."
776,Why can we tell when a program will have an infinite loop but a computer can't?,"What do you mean by ""we"" can tell? If I got a unit of currency for every infinite loop I accidentally wrote or mistook longer than usual execution time for an infinite loop, I'd have a comical amount of units of currency"
777,Why not program ML models in assembly?,"There are layers to this question.

1. Python vs Another Language. Python is indeed slower than something like C for a lot of ordinary operations. But ML libraries written for python actually have the core mathematical operations written in C. The python code is just a shell around the mathematical core to make things easier to work with. You aren't spending a lot of time dealing with the actual execution of python code when training a model.

2. Assembly vs Another Language. While it is true that there are cases where you can hand write assembly code that will outperform an executable compiled from C, this is often not the case. Optimizing compilers are quite good and they can take advantage of inferences and transformations that you likely will not be able to do effectively yourself. It is only in some very particular circumstances that hand written assembly will gain you some performance.

3. Where does the training execute? Training is not actually done on a CPU. This would be terribly slow. Instead it is done on a GPU or even on ML specific hardware like a TPU. This is not the sort of thing that can just run x86 assembly code or whatever."
778,Why can't we just look inside a closed source code?,"The source code is not on your machine. The compiled version, the machine code, is what you download and run on your machine.

You can take the machine code and try to work out what the source code was. This is called decompiling. Decompilers exist, but the source code they produce is harder to read than the original source code. As just one example, the variable names and function names are not in the machine code, so the decompiler will invent ones called (say) int$375 and func$27, and we have to work out their purpose by hand."
779,Major Types of Time Series Analytics,Where's the question?
780,Using tablet as a locked out remote device,"Yes, this is called ""Kiosk"" mode. Android and iOS support this

[https://www.bosstab.com/resources/ipad-kiosk-mode/](https://www.bosstab.com/resources/ipad-kiosk-mode/)

[https://www.bosstab.com/resources/android-kiosk-mode/](https://www.bosstab.com/resources/android-kiosk-mode/)"
781,How to add a Session Beans For Entity Classes in Netbeans?,"Hi,

Try r/learnjava for Java programming questions."
782,App Data Collection,"They would likely buy the data, then users would add and update.  Some websites start in one area and build out to new markets, buying smaller blocks or data."
783,"Hey Folks , I am not from science background but I want to learn computer vision and machine learning from basics? How to approach and where to start?","The best way is probably by enrolling in a relevant university course. That way you'll have experts teaching you, answering your questions, and giving you relevant educational materials. At the end you'll have a qualification that will help you get a related job."
784,Best major for good money while also having a social life MIS or CS?,"I can’t address everything but I’m a CS major in my 3rd year and while it’s definitely a grind if you spread out your challenging classes it’s definitely possible to still have a social life, some semesters more than others depending on your current courses but even on my busy semesters usually have free time on the weekends. I’d prioritize the major that seems more interesting to you because if you enjoy your classes they will likely be easier to learn anyways"
785,Rust and C++ For My Project?,"What kind of data analysis are you doing, and why does it need to be done specifically on these isolated devices? is this for users on these devices? where is the data on these devices coming from?

Depending on the details, my first thought would be to abstract the gui away entirely, and perform the visualizations on some sort of front end, like what you might do with a kibana dashboard"
786,rx 570 8gb vs rx 580 4gb,No
787,Are those LinkedIn assessments really easy?,"Yes, they're a joke. Many are also rife with mistakes or typos, exceptionally low quality assessments."
788,Academic sources on AI/ML theory?,"There are several great texts that introduce ML from a more theoretical/foundational perspective.  Hopefully someone else can chime in with resources for the non-ML aspects of AI.

1. Foundations of Machine Learning - Mohri, Rostamizadeh, and Talwalkar

2. An Introduction to Computational Learning Theory - Kearns and Vazirani

3. Understanding Machine Learning: From Theory to Algorithms - Ben-David and Shalev-Shwartz

4. Patterns, Predictions, and Actions - Hardt and Recht

5. Learning from Data - Abu-Mostafa, Magdon-Ismail, and Lin 

The last one is probably the shortest/most approachable, while the others may be more comprehensive.  There are definitely other texts as well, but if you're interested in a more foundational/theoretical perspective then these are pretty good choices IMO.

Edit: this list is in no particular order"
789,"I need help with finding out the shortest way to ""chain"" math problems using only the numbers 1-9.","With some assumptions you could just bruteforce it. For chain length k there are 9^(k+1) * 4^k possibilities, which grows exponentially, therefore it is hard to compute it for large chain but due to it being a math learning game I assume that the chain length is limited, e.g. there are around 15 millions posibilities for chains of length 4, but already 544 millions for length 5. Both are computable fast enough.

If the chain length is not fixed, e.g. find a solution for 16 instead of find a solution for 16 with length 1, then all previous chains need to be calculated too."
790,How to understand 16 bit addresses.,"https://imgur.com/a/GQQxX2I

The binary representation on this image should help you.

If not, I will explain it more in-depth."
791,need advice,"The best advice you're gonna get is in the dozens of duplicate questions posted across here and other CS subs.

You can get away with 8gb and probably upgrade with another stick if you're maxing out your ram."
792,Can someone explain the terminology of “sync” and “async”,">  That does not really seem like “happening at the same time”.

In this case, it's used to mean something more like ""happening in a set sequence"". I send a message, I wait for a reply, I receive your reply, I continue on to new work.

Asynchronous would be the opposite (i.e. not happening in a set sequence). I send a message, and continue onto other work. I'll handle your reply whenever it comes in.

In the context of programming, a synchronous function call doesn't return until the function is complete. An asynchronous function call might be executed on a second thread, provided with some method to return results whenever the function is completed."
793,AP Computer Science Principles (Unit 3 Optional Project - Animation studios),"it's hard to tell if you're asking about line drawing itself, or scrolling. but if it's line drawing the general answer is to use the Bressenham algorithm."
794,pubsub pattern using Unix socket API,"Conceptually, a pubsub system with a central broker is pretty simple. You maintain some kind of data structure that stores a mapping from ""topics"" to a list of sockets that are ""subscribed"" to that topic. Whenever a message arrives, you iterate over the subscribed topics, and forward the message to those sockets.

The complexity is in the implementation details. It would take a lot of work to build something comparable to ZeroMQ. *How much* work will depend a lot on your exact problem definition and requirements.

Out of curiosity, what leads you to believe that ZeroMQ is causing your ""latency issues""? Why should a custom pubsub system over Unix sockets be any faster than ZeroMQ over Unix sockets?"
795,Need your advice,"I'm gonna be totally sincere: nobody knows what is most suited for you.

My advice is try some free online courses (Udemy, Youtube...) about all the subjects you are interested in and take a moment to appreciate how it feels. 

On a quick google search you can find all the areas/career path of CS. Then, some big info sources are Khan Academy (website) or Freecodecamp (website, Youtube). 

Whenever you get a solid idea o what you like and hate, I would recommend to come here again and ask something more specific about x or y roles.

Adding people to linkedin with the role you want to know more and talking to them works too.

Good luck! :)"
796,For those who have graduated with a Computer Science degree,"I worked in software development for 20 years as a college dropout with no degree.  I finished the degree much later.  While it's possible to have a software career without a degree, you have to work much harder to get jobs because you get filtered out of many of them by HR.  It gets somewhat easier as you gain more resume experience in desirable technologies.  With the current tech recession and hiring freezes, I imagine it's extremely difficult to get a tech job without a degree right now."
797,Is self teaching computer science and getting a job as a felon realistic?,"100% possible. Don't let people discourage you from you dream. Didn't read your whole post but remembered a previous one I saw. https://www.reddit.com/r/learnprogramming/comments/snqcqf/can_felons_be_programmers/

In it someone mentions underdog devs which is a group  specifically for this. There will be challenges but if it's truly what you want I hope you stick with it. Good luck.

You might get more responses if you post this in cscareerquestions. It's more active for this kind of conversation I think."
798,programming question,App developer (I'm not one)
799,what would be different today if from it's inception the internet was built with today's use in mind?,"Usenet would not be completely unsecured and unmoderated. That stopped working out when it was being abused by the Spam King (edit: Spamford).

And, of course, a bigger namespace for IPV4 addresses."
800,Would you suggest web development to someone willing to self study? Why and why not?,"Take my advice with a grain of salt because I'm doing it professionally but hate web dev in its current form, compared to literally any other platform. 

It *never* ends. The vastness of tools, architectures, and shiny things makes ""study"" a strange verb to me. I wouldn't take notes on anything web in my opinion, but I am also someone who learns by doing. I also think that there's little to study that's unique to web development. Databases, language features, and architecture you could study. But studying some library like React or Webpack is only worth it if you really want to be a domain expert. 

For anything like tools, I think one should learn how to use them properly to build something performant and maintainable. It all changes too much to bother becoming an expert on any one thing unless you really want to.

For the interview side, you definitely want to know enough about web dev to answer when questioned. But they shouldn't ask you about much that's not listed on your resume as a skill. In fact, I'm sure there are subs that will give you better guidance on this, because web dev is software engineering rather than computer science. Unfortunately I don't know which subs would be helpful ATM. 

Perhaps check out https://roadmap.sh/ and https://web.dev as resources for getting started."
801,How does the industry create AI's for machines etc. ?,"> Are there tools to create neuralnetworks etc.

I can answer this by naming 2 tools for you to chose: tensorflow and pytorch."
802,"What could it change for the compagnies using the internet for getting data on the consumers if a ""critical"" mass of people used vpn ?","Nothing.

Companies rely on data that can be hidden through the use of a commercial VPN service because that data is correct for most users. If that data weren't correct for most users, companies would find other data sources to use."
803,What determines how much information can be conveyed via a single bit change?,"One bit conveys one bit of information. The trick is that your bit string is longer than one bit, so _which_ bit you're changing is conveying additional information. Think about a bank of switches that can be in an 'up' or 'down' position. If you have eight switches, or eight bits, then you can send eight different signals by deciding which switch to flip - so even if every individual switch can only be in two states, and conveys little information, increasing the number of switches increases the total state space, and the amount of information conveyed by which switch you select."
804,Which computer scientists do you personally find fascinating?,"John Carmack, Leslie Lamport, Fabrice Bellard, Jeff Dean, Linus Torvalds, and Jon Von Neumann."
805,falsely accused of cheating on hw in level 200 comp sci course,"This is mainly a question for people at your institution. Perhaps there is a faculty member who can give you perspective on the situation and how it is usually handled at your school. 

That said, mips assembly code does not leave much room for a variety of solutions."
806,Sudoku Backtracking Algorithm Question,"Oh dear. It's been four days and nobody has responded to you yet.

I think what's confusing is that it's not clear exactly what this ""backtrack count"" of yours means, but I'm guessing it's the total number of times your depth-first-search reached a dead-end and so had to backtrack to try a different solution?

Whether 16 million is reasonable or not will depend on the original state of the puzzle (i.e, whether it's an ""easy"" sudoku or a ""hard"" one), as well as what pruning strategies you're using to reduce the number of guesses you need to take (e.g., you're never guessing a value which already exists in the same row/column/block). 

16 million does seem a bit high to me but I'm not completely sure. I have written sudoku solvers before, but never counted the number of times they backtracked. 

That said... a depth first search to solve even a ""hard"" a sudoku puzzle really shouldn't take more than a minute or so to run. An efficient implementation should be able to complete within seconds. If your algorithm is taking so long that you feel the need to make it print status reports of its progress, then something is definitely wrong."
807,Dynamic Programming HackerRank Problem,"Here's some hint you can use to think further:

Assume you have fixed two columns of the fence. Now can you find the optimal answer? How would you optimise when you move your columns?"
808,Any good learning apps for non-beginners?,"You could maybe try Sololearn. Less the for the lessons and more for the community and Q&A sections. The Q&A helped me refine my own knowledge when answering others and the community has users that post a lot of great challenges so you can participate in those. I'm like a beginner-intermidiate and I can't do a lot of the challenges they post, so you might really enjoy tackling them. You just have to find the right people to follow."
809,Which complexity does this function have (Java) ? ChatGPT says it's O(n) but I believe it's O(n^2).,"This is a famous snippet introduced when for loop are taught in programming. Although I'm sure you understand this code well, I will explain it for completeness

What's going on here? 

The above function takes an integer input ""size"" and prints ""\*"" in a pattern of a right triangle with base and height as ""size"". 

Finding the complexity is analogous to finding the number of steps to get the work done. In this scenario, the work done is the print statement. As we are printing a right triangle with ""\*"", the number of times the print function will need to be invoked (irrespective of the loop nests) is the area of the triangle which turns out to be an O(n\^2) operation."
810,Can you explain DNS in a few succinct steps?,"There are a few different systems at play here:

* MAC addresses are hardware addresses permanently associated with a network adapter (wifi card, ethernet card, etc)

* DHCP assigns IP addresses to computers, and uses MAC addresses to talk back and forth before an IP address is assigned

* DNS associates a human-readable name with an IP address (but not a MAC address)

To associate hostnames with devices on your network you want to first make sure that each device has a permanent IP address. You can do this by either adding a static rule to the DHCP server (""hey, the device with this MAC address _always_ gets 10.0.0.2"") or by foregoing DHCP altogether and setting a static IP address on each device. Then you'd want to run a DNS server like BIND, and associate a hostname with each constant IP address. Then you'd set the DNS server on the DHCP server, so that every device that joins the network is instructed to query that DNS server.

So you're not missing a piece of the puzzle - bind does _not_ know to associate a name with a dynamic IP address in a typical configuration, you just make the IP addresses... not dynamic.

Alternatively, you could use zeroconf/avahi/bonjour instead of DNS. This allows each device to announce their own name to the LAN rather than using a central server. When a network device tries to connect to ""foo.local"" it sends out a query to the network broadcast address, and if one of the other devices is named ""foo"" it'll respond ""hey that's me! Here's my current IP and MAC address!"""
811,Improving my workflow,"Containers are what you need. Author and test on your home machine, push to github, let your CI pipeline turn your code into a Docker container, push that docker container to the powerful machine and run wild."
812,Is there an image filetype that can store OCR info about the image?,"Lots of image formats have ways to stick semi-arbitrary metadata in them.  I'm not aware of specific fields *for* OCR data but they might exist.

If you wanted to be able to quickly search a library of images you wouldn't have to store it *in* the images, you could store it alongside in a separate index and link matches back to the images."
813,Why is starting a home router so slow.,"A home ""router"" is actually several pieces of network kit integrated into one appliance - a network switch, an actual router, a firewall, a DHCP server, and a bridge or modem. On my home network I run all of these separately, so I have a good idea how each acts on its own. Most of those parts start up in just a few seconds.

The one that takes time, IME, is the bridge or modem, which is making the connection to the outside network. It typically needs to probe the line to assess signal quality and negotiate the highest reliable speed, send authentication info and wait for the host end to acknowledge it, and obtain a network address. Some of this simply takes time because it's physics. Some of it is just waiting for the host end to respond, which depends in a way on how much money your ISP spends on host resources - and business being business, it's a safe bet that they spent as little as possible.

[Here is a sonogram](https://youtu.be/vvr9AMWEU-c) of a dial-up modem negotiating a data connection, and a [labeled sonograph](https://imgur.com/5Dq6K2U) of same. You can get a sense of how it probes the line for responsiveness across different frequency/amplitude domains, and shoots test packets back and forth to negotiate protocol settings and check error rates. Something similar happens with cable modems, satellite, cellular, etc."
814,"Computer science sounds really cool, but I'm not sure if it's for me?","CS is not strictly software development. Software engineering would be more focused on developing software. Computer science does involve a heavy engineering component, but the ""science"" part of it has to do with the theory of computation and analysis of fundamental algorithms and data structures (irrespective of the machines they actually run on).

Now, when I started my CS degree I didn't realize this. I wanted to learn how to use computers as a tool to accomplish a task. However, I don't regret my choice. Learning the theoretical side of things was highly interesting and ultimately useful to the way I approach software design as someone who likes to wear an engineering hat. Particularly learning about graph theory and how to use graph properties to formulate objectives that describe the real world task I'm trying to accomplish has allowed me to solve problems that would have otherwise been impossible without a theoretical background. While I don't study networking specifically, graph theory has many applications in networking and it may be interesting for you to learn about it.

Security is another very interesting aspect of computer science. The mathematics of elliptic curves, modular arithmetic, information theory, and cryptography in general is fascinating, and again has many real world applications. 

Because of these things you've said: 

> Now let me get this straight, ugh.... idc about business courses much. I'm a tech person, I care about tech and that's it tbh.

> I want to be good with technology, I don't want to be a fraud.

I would recommend computer science or software engineering instead of an -IT suffixed degree. However, note that I am biased because I have a CS degree.

What might help you understand this better for yourself is to actively watch lectures from MIT open courseware or other online lectures on subjects in the fields you might be interested in."
815,How do computers do mathematical functions?,"There are whole fields of computational arithmetic and numerical analysis. 

In many cases the algorithms follow similar systems to what you would do by hand. The Multiplication that we learn in fifth grade, shift-and-add, are the same, except that it’s a binary shift. 

Division is a shift and subtract, just like long division. The minor difference is that if you guess the wrong quotient bit, you can make the next one negative and then clean up at the end. 

Things like square root are done with successive approximations, just like Newton did by hand."
816,How would you convince your friend to give coding a try if he thinks it’s difficult?,"Coding is difficult and a lot of people don't enjoy it. Frankly a lot of people can't do it. Otherwise, it wouldn't pay so well.

If you find it easy, consider yourself lucky and have a great, high paying career. But I've seen too many people come into the field chasing that high pay check but hate their job. It's a constant barrage of problem solving. It doesn't stop. 

All you can do is encourage him but you also have to respect his choice."
817,Questions for computer science majors and current computer scientists,"do you mean like an actual computer scientist, ie an academic? most CS majors use their degree to get into software engineering. 

for the stress questions it depends on the job. startups can be pretty stressful because you need to move fast. big companies can be stressful because of shitty management. others you can rest and vest. it varies all over the place.

as for what was it like? for me it was surprising since i didn't intend to be a CS major and only took classes because i thought it would be useful and then enjoyed it. 

having some projects under your belt is probably more useful for getting internships. 

busy is not usually tied to seasons, it's tied to releases. 

there are an unlimited different software engineering directions you can take.

as for age and location: suffice it to say that there were no networking classes when i went to school. location California, so right in the thick of things."
818,"Confusion regarding ""epsilon"" transition in NFAs","Case 1 is correct. You can read an epsilon from the input at any moment, so it doesn't make sense to wait after you've read something other than epsilon. Also, this NFA accepts the empty string, but that wouldn't happen in your second case.

Think of it like this: an epsilon transition works much like normal transitions, as in, whenever an epsilon is available to be read from the input string, the corresponding transitions are taken. Which means, in this case, that those transitions are _always_ taken."
819,"What exactly are these keywords and what do they all fall under? architecture, pipeline, data flow, modeling, etc.",You're going to run across a lot of terms in Computer Science. Google is your friend.
820,Is there an example of a project that uses “real OOP” that’s described by Alan Kay?,[Smalltalk](https://en.m.wikipedia.org/wiki/Smalltalk) is still around.
821,How can I leverage ChatGPT to help me with learning to code / working?,"I really wouldn't recommend it. While it has some capabilities that are very impressive, you can find numerous examples of it doing things like generating bad code or providing extremely confident answers that are completely wrong. If we just look at it as a toy that's not a big deal, but if you're leaning on it for learning you'll have little or no context to understand when it's guiding you down a bad path."
822,What made you start programming?,Dad brainwashed me to “learn computers.”
823,What do you think the current web development courses are missing / suffering from?,"They won't teach you how to organize and develop a large project. If you're doing anything more complex than the example apps they give, you need to have a well organized code-base where the abstractions make sense."
824,Resources required to run a large language model like ChatGPT,"ChatGPT runs GPT-3.5 under the hood. The original full-sized GPT-3 model was on the order of 800GB, and we might expect GPT-3.5 to be at least that large.

Spitballing here, you might figure that to require at least ten 80GB GPUs to run inference on-board, plus a machine for them to run on. That might run very roughly from $150k to 250k USD for V100 and A100 GPUs, respectively."
825,How does a streaming service work? What does it need?,"The frontend apps are the easy part. Those almost don't matter, as all they do is authenticate against the backend and then request it to start sending over the video stream.

And from very basic technical view, the backend part is easy too. You have a bunch of video files on file servers and let the paying, authenticated customers download them, more or less.

The hard part is the scaling. Dealing with a lot of requests without running into bottle necks, like saturating your network and all that. Suddenly you're building datacenters in all major regions your customers are from to shorten the path between them and the videos. Then you add content delivery networks that cache the requested videos even closer to the customers to reduce the load on your central datacenter even further. Then you invent better video codecs that shrink down file sizes without sacrificing too much quality, so you have less data to store and transfer.

And so on and so forth.

Streaming is easy. Streaming worldwide to millions of people is hard."
826,"Does anyone have advice on making impressive CS projects/Looking at someone's resume/I can only code school projects, what am I missing?",If you want to impress at a entry level interview research what framework they use most often and do a project with it…when I do a entry level interview candidates able to show me they have used a framework to create something always get huge bonus points.
827,How do laptos produce radio waves?,"Your wifi adapter contains a radio transmitter and receiver.  As does your bluetooth adapter.   Some laptops have cellular radios and GPS radios.     Your cellphone is a computer built around a set of radios.

How radios themselves work really isn't a computer science question.  Things have been emitting radio waves since... literally forever.   Your body emits some radio waves.  What we use in computers and phones is the same principle that allows you to tune into a radio station.  The differences are how we package the information, and where we look for it.   

How radios work https://electronics.howstuffworks.com/radio.htm"
828,"Would it be better to major in CS, AI or both?","You have an independent AI major? AI is usually a component of the CS curriculum, and perhaps a specialization you can get within the major."
829,What to do with old laptop?,"Do you know Linux yet? If not, install Linux on it.  Then maybe Minikube and deploy some app you've written as a Kubernetes pod."
830,"Free Review Copies of ""The C# workshop"" Book.",Does the book talk about using .net core or linux?
831,What can someone do with Phython? (newbie),"Here's a (free online) book that tries to introduce python with concrete examples of stuff you might want to do: https://automatetheboringstuff.com/

It's hard to give good examples for absolute beginners, because most stuff requires some background, but an example of something this book is able to show is writing a script that adds a watermark to each of a whole folder full of images."
832,Project or Course-work for Master with a full-time job in the industry?,you can do a part time masters and should be able to manage
833,What is Lightning Memory Mapped Database (LMDB)?,"> Where can I get a list of these languages? Is it available for Go or JavaScript?

There's a list farther down in the Wikipedia article that you're quoting, and yes, there are bindings for both Go and Node.js. 

Here's the complete list (the URL seems to have changed since Wikipedia was last updated): https://www.symas.com/symas-lmdb-tech-info

> Or is it a library for languages like SQL?

No, LMDB doesn't have a query language like SQL. It's basically just a key-value store, which means it acts like an associative array where the entries can be stored on disk instead of in memory. (Kind of like a hashtable, except that unlike a hashtable, the keys are sorted.)

Here's the ""getting started"" page for the C API, from the official documentation: http://www.lmdb.tech/doc/starting.html

The details of the function signatures will be different in other languages, but the basic usage technique should be quite similar.

As the documentation says, LMDB is modeled on the API of its predecessor, Berkeley DB, so you might want to read a bit about that as well."
834,Why does copying and pasting data seem to be an exact carbon copy but not really? Question detailed further in main body of post.,"How would you be copying the video, and from where to where?

If you take a full video file and make a copy of that entire file on your computer, it gets copied verbatim, as any file with any data would. It does not lose quality in that case.

In some cases, when copying e.g. a clip from a video and putting it somewhere else (such as on YouTube or some other video streaming service), the video often gets decoded when it is read from the original source and encoded again when it is stored in the next place. In case of video, encoding nearly always means a [lossy compression](https://en.wikipedia.org/wiki/Lossy_compression) of the original data in order to save storage space or transmission bandwidth.

In lossy compression some details are always lost, and an exact bit-for-bit replica of the original cannot be retrieved. The difference or the loss of quality compared to the original may not be noticeable, but when lossy compression is repeated over data that had already been previously put through lossy compression, that leads to further degradation of quality."
835,Examples of problems that can not be solved algorithmically?,"Formally these problems are called undecidable. And yes it means there can’t exist an algorithm that can correctly give you yes or no answers to an undecidable problem. the canonical example is the halting problem, which in a general sense is given a program (originally a Turing machine, but can apply to any formal algorithm) does it halt or go into an infinite loop?"
836,Computers - from the ground up,"I think that ""[Code: The Hidden Language of Computer Hardware and Software](https://www.amazon.com/Code-Language-Computer-Hardware-Software/dp/0137909101/)"" might be one such book.

There's also a course called [Nand2Tetris](https://www.nand2tetris.org/) with a book, [The Elements of Computing Systems: Building a Modern Computer from First Principles](https://www.amazon.com/Elements-Computing-Systems-Building-Principles/dp/0262640686/).

I'd look at the two of those and see if either would work for you."
837,Is reactive web programming easy or hard compared to other types of software development?,"a reactive web? yes
a good reactive web? no

there's a rabbit hole in every software you try to develop. it depends on how far down you willing to go."
838,What book should every computer scientist read?,"Most books that are actually about computer science are going to be textbooks. In general, I could recommend textbooks about specific topics, but I would not call them mandatory reading. That said, a ton of people are amazed by [SICP](https://web.mit.edu/6.001/6.037/sicp.pdf) \- it is a book that comes up surprisingly frequently related to CS.

However, there are some books that are not strictly CS, but I would still recommend all Computer Scientists to read them.

First, I would recommend William Rapaport's ""Philosophy of Computer Science"" - it is freely available [here](http://web.archive.org/web/20210227112024/https://cse.buffalo.edu/~rapaport/Papers/phics.pdf). This is an introductory/textbooklike text on the Philosophy of CS - what is CS? is it a science - in general, what is a science? what does CS study? what is a computer? what is computation, what is an algorithm? what questions arise related to computer ethics and AI? It deals with fundamental questions like this. Obviously, these are not questions that arise in the everyday work of a Computer Scientist, and this definitely will not make you a better Software Engineer. But it might help you think about what CS really is.

Second, I think that sci-fi in general is a genre that people interested in technology generally enjoy - and Computer Scientists might profit from it more than others. There are plenty of books, that could be relevant, but the top book I would recommend is Mary Shelley's *Frankenstein - the Modern Prometheus,* which is not directly related to CS in any way, but more generally explores the question whether technological progress is always good."
839,How does my program know where to read a file from when the full file path isn't specified?,"the OS keeps track of your current position in the file system. if the file path is relative, it appends the current position to it."
840,Is Fourier analysis or the FFT useful to a computer scientist?,Amongst other things it's important for Computer vision
841,"Amateur coders, what do you think can help you learn faster?","I think the biggest problem amateur coders (and maybe even professional coders) face is the small error that takes hours to find and fix, but, if you ask a co-worker to look over the code, they will fix it in two seconds or ask 2-3 questions that will let you fix it yourself.

It's particularly frustrating when you're trying to learn a new concept and your code doesn't work because of something totally unrelated to the concept, but, as a new coder, you think it must be because you misunderstand the concept.

Assuming the code isn't proprietary, you can post to stackexchange/reddit, but some (most?) programmers prefer to bang their head and say ""this is easy, I know it's easy, I can fix it myself"".

I'm not sure there's a great solution to this, but, fortunately, AI may soon eliminate the need for coders entirely :)"
842,Having Trouble with understanding time complexity of these problems,How are the for loops arranged? one after the other or one inside the other?
843,Make a graph with json data,"Load the data with the JSON package, then you can access the JSON fields just like a dictionary 

https://www.geeksforgeeks.org/json-load-in-python/"
844,What is business information technology?,"My short answer is that Management Info Tech / Management Info Sys / Business Info Tech / Business Info Sys is going to focus more on business management and how the technology can be used.  There might be some programming or software development, but very minimal.  There might be some courses teaching how a specific software package works.

When I was in school, we used to say that those were the people that couldn't cut it in computer science.  CS is going to cover more theory, and more technical details about how the computer is doing what you want it to do (coding / algorithms / data structures).  There's also probably not going to be any courses designed to teach you how a specific software package works.  You're more likely to learn what a whole genre of software tools are actually doing behind the scenes."
845,Why do Pendrive or SD Cards have the same size but different capacities?,"Chips themselves are very small, external plastic is only for convenience and ease of use. Handling a square 2x2 millimeters is not an easy task. Also, more capacity is harder to put on the chip. More capacity needs more transistors on the die, and more chances some of them will be defective. Instead of throwing out the defective chip, manufacturer disables defective sections, and sells chips for cheaper. Similar thing happens for CPUs and GPUs: your cpu may be a more powerful model but with defective cores physically disabled and sold as a cheaper model. But silicon piece is the same size and is very small"
846,Should I Study Computer Science?,"1) you’re never too old to learn. admissions people care more about your growth, passion, adversities, personal accomplishments, pursuit of education, etc. more than your grades. if you want to dig in go for it! you’ll feel challenged, and sometimes overwhelmed, but you have the luxury of setting your own pace and following what interests you the most

2) community college is a great and undervalued opportunity. you can get a certificate (<2 years), associate’s (~2 years), or transfer to a university for a bachelor’s (~4 years)

3) “CS” has a lot of math. if you’re more interested in making things take a look into software engineering, computer information science, web development, video game development, etc.

4) working more than 40 hours a week is a fast track to burn out. you’re expected to spend about 2-3 hours studying per hour of class. 12 units on top of a full time job is not recommended, but some manage to pull it off

overall I would say to go for it! don’t just learn math and programming concepts. focus on making things. for example, you can learn all the music theory you want but if you never play a note or write a song, what’s the point?"
847,"Taking Operating Systems next semester, any useful resources to get a head start?","I suggest reading [this book.](https://www.amazon.com/Modern-Operating-Systems-Andrew-Tanenbaum/dp/013359162X) Its well written and entertaining, but also one of the best references on the topic. 

Trivia - The author is the inventor of Minix which is a minimal unix like teaching operating system. It was the inspiration for Linus starting the Linux project."
848,Are computer networking skills useless for software developers or cyber security?,more important than ever considering cloud and distributed systems.
849,atmega328p,Try /r/embedded
850,Should I put game-breaking programs & bots on my resume?,No. These can range from illegal to just violating the terms of service. Neither are things companies want to see in an employee.
851,*PLEASE HELP* AP Computer Science A student in DESPERATE need of a hand (java),Homework help is not allowed in this sub.
852,Using synchronized rng to verify messages sent to a server.,"Somewhat unclear what you're trying to describe.

But if you're describing what I think you are then is very doable.  It helps if you model your state transitions as pure functions of the previous state and inputs."
853,Suggestions for Research Project Topic,"Here's a perennial AI database problem: given a list of SQL queries, determine the best indexes for the database. You would need to have a cost-benefit analysis for reads and writes. A note: there are entire products, like PGAnalyze, which literally do this."
854,How would you compare path-planning algorithms (D* Lite vs A*)?,"The truth is that you should utilize as many metrics as you can think of to measure, then plot those metrics on graphs to visualize the differences.

For example, the simplest might be to analyze execution time. You should create 3 or more mazes of varying sizes (i.e., a 4x4 maze, 20x20 maze, 100x100 maze, etc.), then run both algorithms for each of the mazes. Record the execution time for each algorithm for each maze, then plot those values as a line chart.

You'll need to use Matplotlib as well as Pandas/Numpy to accomplish these experiments. Let me know if you need help finding resources but there are countless tutorials online."
855,What does HPQ stand for in the HPQFlash bios updater?,"A bit of googling suggests that ""HPQFlash"" is a program for updating the BIOS of computers made by HP, the company formerly known as Hewlett-Packard. So the ""HP"" probably just stands for... HP.

Maybe the ""Q"" stands for ""quick""?"
856,"Is CIT mostly about ""customer support"" and ""service"" while CS is more about actual technology?","> I think humans are the worst. I whole heartedly believe humans are only selfish, and evil. I do not care about humans at all. 

Any tech job is innately going to be about helping humans to get technology to do stuff for them. Why else would humans pay you to play with tech?"
857,Java Or Python. What would be better recommended in my case?,"You can earn money with both. If you don’t have any experience with object oriented languages,I would recommend learning some Java before the course.

Ideally you would start with C/C++ before you pick up Java."
858,Natural Deduction,"`p→(s→r)` is equivalent to `¬p∨¬s∨r`.  Suppose `s`.  In that case, `¬p∨r`, but we have `¬r`, so `¬p`, and therefore `¬q` by `p∨¬q`.  However, if `¬q` then by `q∨¬s` we have `¬s`, which is a contradiction.  Therefore, `¬s`."
859,"Would radical life extension be possible with a VR brain chip, that alters our perception of time so that every second felt like a year in VR?","I don't think this is a computer science question, more a neuroscience one."
860,Hi! I want to talk to somebody that has studied computer science in college and ask questions about their experience for a character that I'm writing,I'm one of those guys. PM me.
861,I have an important question but ....,You can geolocate to a municipality. But only the ISP has the actual street address.
862,"For indexOf(list, item) methods, is it appropriate to return Integer.MIN_VALUE if the item is not in the list?","If your language supports nullable values, you should use that.  If you must use an integer flag value, then it doesn't really matter what value you use.  Plenty of libraries use -1 for this without experiencing any difficulty."
863,Is random access and direct access the same thing?,"They're the same thing. ""Random"" in this context means ""arbitrary"".

Think of a cassette tape vs a CD.

The CD has direct access to any song. You want track 7, you can play it immediately. Or to put it another way, you can pick any track at random, and immediately play that track.

A cassette tape does not have direct access / random access. If you're on track 1 and you want to listen to the 4th track, you'll have to fast-forward for a while.

Same thing on a computer. RAM is ""random access memory"" because you can access any memory address you want instantly, even a random address.

Hard drives are not considered random access. Reading data sequentially is really fast. Reading data from somewhere else on the disk requires a seek, which takes a while (10 ms, which to a computer is an eternity)."
864,if someone finds my IP address can they find out where i live?,"IP addresses can usually be geolocated to within a few miles of the actual location, but not to the individual address. This information is available on sites like [iplocation.net](https://www.iplocation.net/) - if someone has your IP, this is the geographic information they have access to."
865,What would you do with 100 computers just sitting around?,i would shut them down and save the electricity
866,is this a good ELI5 for Curry-Howard isomorphism? idk anything about it,"No, I don’t think so. 

If we want to use the puzzle analogy, I would rather describe it as a puzzle with two sides. If one side is difficult you could flip it over and use the other one."
867,Egrep: Finding duplicate words,"That seems to work fine for me:

    $ egrep -o ""\b(\w+)\s+\1\b"" << EOF
    > Paris in the the spring.
    > Not that that is related.
    > EOF
    the the
    that that

Maybe you're not quoting it correctly?"
868,struggling to understand mathematical notation for this signal averaging formula (Topic is Intelligent Signal Processing),"Lowercase n is the index of the value you're asking for.  The data points are the x array, and they're using parentheses for array indexing, so x(3) is the third data point.  Similarly, y is an array of moving averages at a point, so y(n) is the moving average at index n.

The notation is just saying to take the N points up to and including point n (ie, x(n), x(n-1), ...), sum them, and divide by N."
